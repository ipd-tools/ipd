[{"path":"https://ipd-tools.github.io/ipd/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 ipd authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (â€œSoftwareâ€), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED â€œâ€, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":[]},{"path":[]},{"path":"https://ipd-tools.github.io/ipd/README-JPN.html","id":null,"dir":"","previous_headings":"","what":"ipd: Inference on Predicted Data","title":"ipd: Inference on Predicted Data","text":"ipdã¯ã€äººå·¥çŸ¥èƒ½ï¼ˆAIï¼‰ã‚„æ©Ÿæ¢°å­¦ç¿’ï¼ˆMLï¼‰ã«ã‚ˆã£ã¦äºˆæ¸¬ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸçµ±è¨ˆçš„æ¨è«–ï¼ˆInference Predicted Data: IPDï¼‰ã‚’æ”¯æ´ã™ã‚‹ã€ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®Rãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã§ã™ã€‚ ç¾ä»£ã®å¤šãã®å¿œç”¨åˆ†é‡ã§ã¯ã€ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ï¼ˆçµæœãŒè¦³æ¸¬ã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ï¼‰ãŒé™ã‚‰ã‚Œã¦ãŠã‚Šã€ä»£ã‚ã‚Šã«AIãƒ¢ãƒ‡ãƒ«ãŒäºˆæ¸¬ã—ãŸãƒ©ãƒ™ãƒ«ã‚’ä½¿ç”¨ã—ã¦è§£æã‚’è¡Œã†å ´é¢ãŒå¢—ãˆã¦ã„ã¾ã™ã€‚ipdãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¯ã€ã“ã†ã—ãŸã€Œäºˆæ¸¬ã•ã‚ŒãŸçµæœï¼ˆoutcomesï¼‰ã€ã‚’ä½¿ã£ã¦ã€å…±å¤‰é‡ï¼ˆèª¬æ˜å¤‰æ•°ï¼‰ã¨çµæœã®é–¢ä¿‚ã‚’æ¨å®šã™ã‚‹éš›ã«ç”Ÿã˜ã‚‹ãƒã‚¤ã‚¢ã‚¹ã‚„ä¸ç¢ºå®Ÿæ€§ã‚’é©åˆ‡ã«è€ƒæ…®ã—ãŸæ¨è«–ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚ æœ¬ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã§ã¯ã€æœ€è¿‘ææ¡ˆã•ã‚ŒãŸè¤‡æ•°ã®æ‰‹æ³•ï¼ˆPostPIã€PPIã€PSPAãªã©ï¼‰ã‚’ã€å…±é€šã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’é€šã˜ã¦ç°¡å˜ã«ä½¿ãˆã‚‹ã‚ˆã†ã«çµ±åˆã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€printã€summaryã€tidyã€glanceã€augmentã¨ã„ã£ãŸãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ã®æ•´å½¢ã‚„ç¢ºèªã«ä¾¿åˆ©ãªãƒ¡ã‚½ãƒƒãƒ‰ã‚‚æä¾›ã—ã¦ã„ã¾ã™ã€‚","code":""},{"path":"https://ipd-tools.github.io/ipd/README-JPN.html","id":"èƒŒæ™¯","dir":"","previous_headings":"","what":"èƒŒæ™¯","title":"ipd: Inference on Predicted Data","text":"AIã‚„æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹äºˆæ¸¬çµæœã¯ã€è¿‘å¹´ã•ã¾ã–ã¾ãªåˆ†é‡ã§æ´»ç”¨ãŒé€²ã‚“ã§ã„ã¾ã™ã€‚ç‰¹ã«ã€åŒ»ç™‚ã‚„ç¤¾ä¼šç§‘å­¦ã€è‡ªç„¶ç§‘å­¦ãªã©ã§ã¯ã€ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ã®åé›†ãŒé«˜ã‚³ã‚¹ãƒˆã¾ãŸã¯å›°é›£ã§ã‚ã‚‹ãŸã‚ã€AIãŒäºˆæ¸¬ã—ãŸçµæœã‚’ãã®ã¾ã¾ä¸‹æµã®çµ±è¨ˆè§£æã«åˆ©ç”¨ã™ã‚‹ã‚±ãƒ¼ã‚¹ãŒå¢—ãˆã¦ã„ã¾ã™ã€‚ ã—ã‹ã—ã€ã“ã®ã‚ˆã†ãªäºˆæ¸¬å€¤ã‚’æœ¬æ¥ã®ã€Œè¦³æ¸¬å€¤ã€ã®ä»£ã‚ã‚Šã«ä½¿ã†ã“ã¨ã§ã€ä»¥ä¸‹ã®ã‚ˆã†ãªçµ±è¨ˆçš„ãªå•é¡ŒãŒç”Ÿã˜ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼š äºˆæ¸¬å€¤ã¨çœŸã®å€¤ã®ã‚ºãƒ¬ï¼šäºˆæ¸¬ã•ã‚ŒãŸçµæœï¼ˆãŸã¨ãˆã°ç–¾æ‚£ã®æœ‰ç„¡ã‚„æ²»ç™‚åŠ¹æœï¼‰ã¯ã€å®Ÿéš›ã«è¦³æ¸¬ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¨ã¯ç•°ãªã‚‹æ€§è³ªã‚’æŒã¡ã¾ã™ã€‚ã“ã®ã‚ºãƒ¬ã‚’è€ƒæ…®ã—ãªã„ã¨ã€æ¨å®šã«åã‚ŠãŒç”Ÿã˜ã¾ã™ã€‚ ä¸ç¢ºå®Ÿæ€§ã®éå°è©•ä¾¡ï¼šäºˆæ¸¬ã«ã¯å¿…ãšèª¤å·®ãŒå«ã¾ã‚Œã¾ã™ãŒã€ãã‚Œã‚’ç„¡è¦–ã—ã¦æ¨è«–ã‚’è¡Œã†ã¨ã€æ¨™æº–èª¤å·®ãŒå°ã•ãè¦‹ç©ã‚‚ã‚‰ã‚Œã€ä¿¡é ¼åŒºé–“ã‚„ä»®èª¬æ¤œå®šãŒæ­£ã—ãæ©Ÿèƒ½ã—ã¾ã›ã‚“ã€‚ AIãƒ¢ãƒ‡ãƒ«è‡ªä½“ã®ãƒã‚¤ã‚¢ã‚¹ï¼šäºˆæ¸¬ã«ä½¿ã‚ã‚Œã‚‹AI/MLãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚„æ‰‹æ³•ã«ã‚ˆã£ã¦ã¯ã€ç‰¹å®šã®ã‚µãƒ³ãƒ—ãƒ«ã«åã£ãŸçµæœã‚’å‡ºã™ã“ã¨ãŒã‚ã‚Šã€ãã®ãƒã‚¤ã‚¢ã‚¹ãŒä¸‹æµã®è§£æçµæœã«å½±éŸ¿ã—ã¾ã™ã€‚ ã“ã†ã—ãŸå•é¡Œã«å¯¾å‡¦ã™ã‚‹ãŸã‚ã€è¿‘å¹´ã•ã¾ã–ã¾ãªæ–¹æ³•è«–ãŒææ¡ˆã•ã‚Œã¦ãã¾ã—ãŸã€‚ãŸã¨ãˆã°ï¼š PostPIï¼ˆäºˆæ¸¬å¾Œæ¨è«–ï¼›Wang et al., 2020ï¼‰ï¼šäºˆæ¸¬ã•ã‚ŒãŸçµæœã¨å®Ÿéš›ã®çµæœã®å·®ã‚’è£œæ­£ã™ã‚‹æ–¹æ³• PPI / PPI++ï¼ˆäºˆæ¸¬é§†å‹•æ¨è«–ï¼›Angelopoulos et al., 2023ï¼‰ï¼šäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’å†åˆ©ç”¨ã—ã¦ä¸ç¢ºå®Ÿæ€§ã‚’ä¼æ¬ã•ã›ã‚‹æ‰‹æ³• PSPAï¼ˆäºˆæ¸¬å¾Œé©å¿œæ¨è«–ï¼›Miao et al., 2023ï¼‰ï¼šãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ã¨äºˆæ¸¬ç²¾åº¦ã‚’åˆ©ç”¨ã—ã¦é©å¿œçš„ã«æ¨è«–ã‚’è¡Œã†æ–¹æ³• ã“ã‚Œã‚‰ã®æ‰‹æ³•ã¯å…±é€šã—ã¦ã€è¦³æ¸¬ã•ã‚Œã¦ã„ãªã„çµæœã‚’AIã§è£œå®Œã—ãŸã†ãˆã§ã€ä¿¡é ¼ã§ãã‚‹çµ±è¨ˆçš„çµè«–ã‚’å°ãã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚ Overview data setup IPD ãƒ©ãƒ™ãƒ«ãªã—ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´é‡ã¨äºˆæ¸¬çµæœã‚’æ´»ç”¨ã—ã¦ã€ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ã‚’è£œå®Œã™ã‚‹ã“ã¨ã§ã€IPDæ‰‹æ³•ã‚’ç”¨ã„ã¦è£œæ­£ã•ã‚ŒãŸæ¨å®šå€¤ã¨æ¨™æº–èª¤å·®ã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ ã“ã†ã—ãŸæœ€å…ˆç«¯ã®æ‰‹æ³•ã«é–¢å¿ƒã®ã‚ã‚‹ç ”ç©¶è€…ã‚„å®Ÿå‹™è€…ãŒç°¡å˜ã«åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã€ç§ãŸã¡ã¯ãã‚Œã‚‰ã‚’IPDã¨ã„ã†æ çµ„ã¿ã®ã‚‚ã¨ã§å®Ÿè£…ã—ãŸRãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ipdã‚’é–‹ç™ºã—ã¾ã—ãŸã€‚æœ¬READMEã§ã¯ã€æœ¬ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®æ¦‚è¦ã€ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•ã€åŸºæœ¬çš„ãªä½¿ç”¨ä¾‹ã€ãŠã‚ˆã³è©³ç´°ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¸ã®ãƒªãƒ³ã‚¯ã‚’ç´¹ä»‹ã—ã¦ã„ã¾ã™ã€‚ä½¿ç”¨ä¾‹ã§ã¯ã€ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆã€ãƒ¢ãƒ‡ãƒ«ã®é©åˆã€ãã—ã¦ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒæä¾›ã™ã‚‹ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ã‚½ãƒƒãƒ‰ã®ä½¿ã„æ–¹ã‚’èª¬æ˜ã—ã¦ã„ã¾ã™ã€‚ ##ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³• GitHubã‹ã‚‰ipdã®é–‹ç™ºç‰ˆã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã«ã¯ã€devtoolsãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚ ##ä½¿ç”¨æ–¹æ³• ipdãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã«å«ã¾ã‚Œã‚‹ãƒ¡ã‚½ãƒƒãƒ‰ã®ä½¿ã„æ–¹ã‚’ç¤ºã™ã‚·ãƒ³ãƒ—ãƒ«ãªä¾‹ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚ ###ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿæˆ simdaté–¢æ•°ã‚’ä½¿ãˆã°ã€å„ç¨®å›å¸°ãƒ¢ãƒ‡ãƒ«ã«å¯¾å¿œã—ãŸåˆæˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã§ãã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µã‚¤ã‚ºã€åŠ¹æœé‡ã€æ®‹å·®åˆ†æ•£ã€ãã—ã¦ãƒ¢ãƒ‡ãƒ«ã®ç¨®é¡ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã§ã€è‡ªç”±ã«ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã§ãã¾ã™ã€‚ç¾åœ¨ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã®ç¨®é¡ã¯ã€ã€Œmeanï¼ˆå¹³å‡ï¼‰ã€ã€Œquantileï¼ˆåˆ†ä½æ•°ï¼‰ã€ã€Œolsï¼ˆç·šå½¢å›å¸°ï¼‰ã€ã€Œlogisticï¼ˆãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ï¼‰ã€ã€Œpoissonï¼ˆãƒã‚¢ã‚½ãƒ³å›å¸°ï¼‰ã€ã§ã™ã€‚ simdaté–¢æ•°ã¯ã€æ¬¡ã®3ç¨®é¡ã®ã‚µãƒ–ã‚»ãƒƒãƒˆã‚’å«ã‚€data.frameã‚’ç”Ÿæˆã—ã¾ã™ï¼š äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã«ä½¿ç”¨ã•ã‚Œã‚‹è¿½åŠ ã®è¦³æ¸¬å€¤ã‚’å«ã‚€ç‹¬ç«‹ã—ãŸã€Œtrainingï¼ˆè¨“ç·´ï¼‰ã€ã‚»ãƒƒãƒˆ è¦³æ¸¬ã•ã‚ŒãŸçµæœã¨äºˆæ¸¬ã•ã‚ŒãŸçµæœã‚’å«ã‚€ã€Œlabeledï¼ˆãƒ©ãƒ™ãƒ«ä»˜ãï¼‰ã€ã‚»ãƒƒãƒˆ åŒã˜ãè¦³æ¸¬ã•ã‚ŒãŸçµæœã¨äºˆæ¸¬å€¤ã€ãŠã‚ˆã³ç‰¹å¾´é‡ã‚’å«ã‚€ã€Œunlabeledï¼ˆãƒ©ãƒ™ãƒ«ãªã—ï¼‰ã€ã‚»ãƒƒãƒˆ simdaté–¢æ•°ã¯ã€ãƒ©ãƒ™ãƒ«ä»˜ãã¨ãƒ©ãƒ™ãƒ«ãªã—ã®ä¸¡æ–¹ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã—ã¦ã€è¦³æ¸¬ã•ã‚ŒãŸçµæœã¨è¦³æ¸¬ã•ã‚Œã¦ã„ãªã„çµæœã‚’æä¾›ã—ã¾ã™ãŒã€å®Ÿéš›ã«ã¯ãƒ©ãƒ™ãƒ«ãªã—ã‚»ãƒƒãƒˆã«ã¯è¦³æ¸¬ã•ã‚ŒãŸçµæœã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ã“ã‚Œã‚‰ã®å¤‰æ•°é–“ã®é–¢ä¿‚ã‚’è¦–è¦šåŒ–ã§ãã¾ã™ï¼š  ã‚°ãƒ©ãƒ•ã‹ã‚‰ã¯æ¬¡ã®ã‚ˆã†ãªå‚¾å‘ãŒèª­ã¿å–ã‚Œã¾ã™ï¼š -ãƒ—ãƒ­ãƒƒãƒˆAï¼šäºˆæ¸¬å€¤ã¯å®Ÿæ¸¬å€¤ã‚ˆã‚Šã‚‚å…±å¤‰é‡ã¨ã®ç›¸é–¢ãŒé«˜ããªã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚ -ãƒ—ãƒ­ãƒƒãƒˆBï¼šäºˆæ¸¬å€¤ã¯å®Ÿæ¸¬å€¤ã¨ç•°ãªã‚‹åˆ†å¸ƒã‚’æŒã¤ã€‚","code":"#-- devtoolsãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«      install.packages(\"devtools\")         #-- GitHubã‹ã‚‰ipdãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«      devtools::install_github(\"ipd-tools/ipd\") #â€“ ipdãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’èª­ã¿è¾¼ã‚€  library(ipd)  #â€“ ç·šå½¢å›å¸°ç”¨ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ  set.seed(123)  n <- c(10000, 500, 1000)  dat <- simdat(n = n, effect = 1, sigma_Y = 4, model = 'ols')  #â€“ è¨“ç·´ã€ãƒ©ãƒ™ãƒ«ä»˜ãã€ãƒ©ãƒ™ãƒ«ãªã—ã‚µãƒ–ã‚»ãƒƒãƒˆã®æœ€åˆã®6è¡Œã‚’è¡¨ç¤º  options(digits=2)  head(dat[dat$set_label == 'training',]) #>       X1    X2    X3     X4     Y  f set_label #> 1 -0.560 -0.56  0.82 -0.356 -0.15 NA  training #> 2 -0.230  0.13 -1.54  0.040 -4.49 NA  training #> 3  1.559  1.82 -0.59  1.152 -1.08 NA  training #> 4  0.071  0.16 -0.18  1.485 -3.67 NA  training #> 5  0.129 -0.72 -0.71  0.634  2.19 NA  training #> 6  1.715  0.58 -0.54 -0.037 -1.42 NA  training  head(dat[dat$set_label == 'labeled',]) #>          X1      X2    X3    X4     Y     f set_label #> 10001  2.37 -1.8984  0.20 -0.17  1.40  3.24   labeled #> 10002 -0.17  1.7428  0.26 -2.05  3.56  1.03   labeled #> 10003  0.93 -1.0947  0.76  1.25 -3.66  2.37   labeled #> 10004 -0.57  0.1757  0.32  0.65 -0.56  0.58   labeled #> 10005  0.23  2.0620 -1.35  1.46 -0.82 -0.15   labeled #> 10006  1.13 -0.0028  0.23 -0.24  7.30  2.16   labeled  head(dat[dat$set_label == 'unlabeled',]) #>          X1     X2    X3    X4    Y     f set_label #> 10501  0.99 -3.280 -0.39  0.97  8.4  1.25 unlabeled #> 10502 -0.66  0.142 -1.36 -0.22 -7.2 -1.08 unlabeled #> 10503  0.58 -1.368 -1.73  0.15  5.6 -0.31 unlabeled #> 10504 -0.14 -0.728  0.26 -0.23 -4.2  0.91 unlabeled #> 10505 -0.17 -0.068 -1.10  0.58  2.2 -0.39 unlabeled #> 10506  0.58  0.514 -0.69  0.97 -1.2  0.76 unlabeled"},{"path":"https://ipd-tools.github.io/ipd/README-JPN.html","id":"ãƒ¢ãƒ‡ãƒ«ã®é©åˆ","dir":"","previous_headings":"","what":"ãƒ¢ãƒ‡ãƒ«ã®é©åˆ","title":"ipd: Inference on Predicted Data","text":"ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã™ã‚‹ãŸã‚ã®2ã¤ã®éIPDã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨ipdãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã«å«ã¾ã‚Œã‚‹æ‰‹æ³•ã‚’æ¯”è¼ƒã—ã¾ã™ã€‚ä»¥ä¸‹ã®è¡¨ã«æ¯”è¼ƒæ¦‚è¦è¡¨ã‚’ç¤ºã—ã€ãã®å¾Œã«å„æ‰‹æ³•ã®å…·ä½“çš„ãªå‘¼ã³å‡ºã—æ–¹æ³•ã‚’ç¤ºã—ã¾ã™ï¼š IPDæ‰‹æ³•ã§ã¯ã€æ¨å®šå€¤ã‚„æ¨™æº–èª¤å·®ã¯æ¦‚ã­ä¸€è‡´ã—ã¾ã™ãŒã€ãƒŠã‚¤ãƒ¼ãƒ–æ‰‹æ³•ã§ã¯æ¨å®šå€¤ãŒç•°ãªã‚Šã€æ¨™æº–èª¤å·®ã‚‚éå°è©•ä¾¡ã•ã‚Œã‚‹å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚","code":"#>                            Estimate Std.Error #> ãƒŠã‚¤ãƒ¼ãƒ–                       0.98      0.03 #> ã‚¯ãƒ©ã‚·ãƒƒã‚¯                     1.10      0.19 #> PostPI\\n(ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—)     1.16      0.18 #> PostPI (è§£æçš„)                1.15      0.18 #> PPI++                          1.12      0.19 #> PSPA                           1.12      0.19"},{"path":"https://ipd-tools.github.io/ipd/README-JPN.html","id":"id_01-äºˆæ¸¬ã•ã‚ŒãŸçµæœã‚’ä½¿ç”¨ã—ãŸãƒŠã‚¤ãƒ¼ãƒ–å›å¸°","dir":"","previous_headings":"ãƒ¢ãƒ‡ãƒ«ã®é©åˆ","what":"0.1 äºˆæ¸¬ã•ã‚ŒãŸçµæœã‚’ä½¿ç”¨ã—ãŸã€ŒãƒŠã‚¤ãƒ¼ãƒ–ã€å›å¸°","title":"ipd: Inference on Predicted Data","text":"","code":"#--- ãƒŠã‚¤ãƒ¼ãƒ–å›å¸°ã‚’é©åˆ      lm(f ~ X1, data = dat[dat$set_label == \"unlabeled\",]) |>               summary() #>  #> Call: #> lm(formula = f ~ X1, data = dat[dat$set_label == \"unlabeled\",  #>     ]) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -2.5426 -0.6138 -0.0153  0.6345  2.8907  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)   0.8391     0.0297    28.3   <2e-16 *** #> X1            0.9848     0.0296    33.3   <2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.94 on 998 degrees of freedom #> Multiple R-squared:  0.527,  Adjusted R-squared:  0.526  #> F-statistic: 1.11e+03 on 1 and 998 DF,  p-value: <2e-16"},{"path":"https://ipd-tools.github.io/ipd/README-JPN.html","id":"id_02-ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ä½¿ç”¨ã—ãŸã‚¯ãƒ©ã‚·ãƒƒã‚¯å›å¸°","dir":"","previous_headings":"ãƒ¢ãƒ‡ãƒ«ã®é©åˆ","what":"0.2 ãƒ©ãƒ™ãƒ«ä»˜ããƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ä½¿ç”¨ã—ãŸã€Œã‚¯ãƒ©ã‚·ãƒƒã‚¯ã€å›å¸°","title":"ipd: Inference on Predicted Data","text":"æä¾›ã•ã‚Œã‚‹ãƒ©ãƒƒãƒ‘ãƒ¼é–¢æ•°ipd()ã‚’ä½¿ç”¨ã—ã¦ã€æ§˜ã€…ãªIPDæ‰‹æ³•ã‚’ãƒ‡ãƒ¼ã‚¿ã«é©åˆã•ã›ã€è¦ç´„ã‚’å–å¾—ã§ãã¾ã™ï¼š","code":"#â€” ã‚¯ãƒ©ã‚·ãƒƒã‚¯å›å¸°ã‚’é©åˆ  lm(Y ~ X1, data = dat[dat$set_label == 'labeled',]) |>  summary() #>  #> Call: #> lm(formula = Y ~ X1, data = dat[dat$set_label == \"labeled\", ]) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -15.262  -2.828  -0.094   2.821  11.685  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)    0.908      0.187    4.86  1.6e-06 *** #> X1             1.097      0.192    5.71  1.9e-08 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 4.2 on 498 degrees of freedom #> Multiple R-squared:  0.0614, Adjusted R-squared:  0.0596  #> F-statistic: 32.6 on 1 and 498 DF,  p-value: 1.95e-08"},{"path":"https://ipd-tools.github.io/ipd/README-JPN.html","id":"id_11-postpiãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—è£œæ­£wang-et-al-2020","dir":"","previous_headings":"ãƒ¢ãƒ‡ãƒ«ã®é©åˆ","what":"1.1 PostPIãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—è£œæ­£ï¼ˆWang et al., 2020ï¼‰","title":"ipd: Inference on Predicted Data","text":"","code":"#-- å¼ã‚’æŒ‡å®š      formula <- Y - f ~ X1      #-- PostPIãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—è£œæ­£ã‚’é©åˆ      nboot <- 200      ipd::ipd(formula,                      method = \"postpi_boot\", model = \"ols\", data = dat, label = \"set_label\",               nboot = nboot) |>               summary() #>  #> Call: #>  Y - f ~ X1  #>  #> Method: postpi_boot  #> Model: ols  #> Intercept: Yes  #>  #> Coefficients: #>             Estimate Std.Error Lower.CI Upper.CI #> (Intercept)    0.866     0.183    0.507     1.22 #> X1             1.164     0.183    0.806     1.52"},{"path":"https://ipd-tools.github.io/ipd/README-JPN.html","id":"id_12-postpiè§£æçš„è£œæ­£wang-et-al-2020","dir":"","previous_headings":"ãƒ¢ãƒ‡ãƒ«ã®é©åˆ","what":"1.2 PostPIè§£æçš„è£œæ­£ï¼ˆWang et al., 2020ï¼‰","title":"ipd: Inference on Predicted Data","text":"","code":"#â€“ PostPIè§£æçš„è£œæ­£ã‚’é©åˆ  ipd::ipd(formula,  method = 'postpi_analytic', model = 'ols', data = dat, label = 'set_label') |>  summary() #>  #> Call: #>  Y - f ~ X1  #>  #> Method: postpi_analytic  #> Model: ols  #> Intercept: Yes  #>  #> Coefficients: #>             Estimate Std.Error Lower.CI Upper.CI #> (Intercept)    0.865     0.183    0.505     1.22 #> X1             1.145     0.182    0.788     1.50"},{"path":"https://ipd-tools.github.io/ipd/README-JPN.html","id":"id_2-äºˆæ¸¬é§†å‹•æ¨è«–ppi-angelopoulos-et-al-2023","dir":"","previous_headings":"ãƒ¢ãƒ‡ãƒ«ã®é©åˆ","what":"2. äºˆæ¸¬é§†å‹•æ¨è«–ï¼ˆPPI; Angelopoulos et al., 2023ï¼‰","title":"ipd: Inference on Predicted Data","text":"","code":"#-- PPIè£œæ­£ã‚’é©åˆ      ipd::ipd(formula,                      method = \"ppi\", model = \"ols\", data = dat, label = \"set_label\") |>               summary() #>  #> Call: #>  Y - f ~ X1  #>  #> Method: ppi  #> Model: ols  #> Intercept: Yes  #>  #> Coefficients: #>             Estimate Std.Error Lower.CI Upper.CI #> (Intercept)    0.871     0.182    0.514     1.23 #> X1             1.122     0.195    0.740     1.50"},{"path":"https://ipd-tools.github.io/ipd/README-JPN.html","id":"id_3-ppiangelopoulos-et-al-2023","dir":"","previous_headings":"ãƒ¢ãƒ‡ãƒ«ã®é©åˆ","what":"3. PPI++ï¼ˆAngelopoulos et al., 2023ï¼‰","title":"ipd: Inference on Predicted Data","text":"","code":"#â€“ PPI++è£œæ­£ã‚’é©åˆ  ipd::ipd(formula,  method = 'ppi_plusplus', model = 'ols', data = dat, label = 'set_label')|>  summary() #>  #> Call: #>  Y - f ~ X1  #>  #> Method: ppi_plusplus  #> Model: ols  #> Intercept: Yes  #>  #> Coefficients: #>             Estimate Std.Error Lower.CI Upper.CI #> (Intercept)    0.881     0.182    0.524     1.24 #> X1             1.116     0.187    0.750     1.48"},{"path":"https://ipd-tools.github.io/ipd/README-JPN.html","id":"id_4-äºˆæ¸¬å¾Œé©å¿œæ¨è«–pspa-miao-et-al-2023","dir":"","previous_headings":"ãƒ¢ãƒ‡ãƒ«ã®é©åˆ","what":"4. äºˆæ¸¬å¾Œé©å¿œæ¨è«–ï¼ˆPSPA; Miao et al., 2023ï¼‰","title":"ipd: Inference on Predicted Data","text":"","code":"#-- PSPAè£œæ­£ã‚’é©åˆ      ipd::ipd(formula,                      method = \"pspa\", model = \"ols\", data = dat, label = \"set_label\") |>               summary() #>  #> Call: #>  Y - f ~ X1  #>  #> Method: pspa  #> Model: ols  #> Intercept: Yes  #>  #> Coefficients: #>             Estimate Std.Error Lower.CI Upper.CI #> (Intercept)    0.881     0.182    0.524     1.24 #> X1             1.109     0.187    0.743     1.47"},{"path":"https://ipd-tools.github.io/ipd/README-JPN.html","id":"å‡ºåŠ›ã¨æ•´å½¢","dir":"","previous_headings":"","what":"å‡ºåŠ›ã¨æ•´å½¢","title":"ipd: Inference on Predicted Data","text":"ãƒ¢ãƒ‡ãƒ«ã®æ¤œè¨¼ã‚’å®¹æ˜“ã«ã™ã‚‹ãŸã‚ã€printã€summaryã€tidyã€glanceã€augmentã¨ã„ã£ãŸã‚«ã‚¹ã‚¿ãƒ ãƒ¡ã‚½ãƒƒãƒ‰ã‚‚åˆ©ç”¨ã§ãã¾ã™ï¼š","code":"#â€“ PostPIãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—è£œæ­£ã‚’é©åˆ  nboot <- 200  fit_postpi <- ipd::ipd(formula,  method = 'postpi_boot', model = 'ols', data = dat, label = 'set_label',  nboot = nboot)  #â€“ ãƒ¢ãƒ‡ãƒ«ã‚’å‡ºåŠ›  print(fit_postpi) #>  #> Call: #>  Y - f ~ X1  #>  #> Coefficients: #> (Intercept)          X1  #>        0.86        1.15  #â€“ ãƒ¢ãƒ‡ãƒ«ã‚’è¦ç´„  summ_fit_postpi <- summary(fit_postpi)  #â€“ ãƒ¢ãƒ‡ãƒ«è¦ç´„ã‚’å‡ºåŠ›  print(summ_fit_postpi) #>  #> Call: #>  Y - f ~ X1  #>  #> Method: postpi_boot  #> Model: ols  #> Intercept: Yes  #>  #> Coefficients: #>             Estimate Std.Error Lower.CI Upper.CI #> (Intercept)    0.860     0.183    0.502     1.22 #> X1             1.148     0.182    0.790     1.50  #â€“ ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ã‚’æ•´å½¢  tidy(fit_postpi) #>                    term estimate std.error conf.low conf.high #> (Intercept) (Intercept)     0.86      0.18     0.50       1.2 #> X1                   X1     1.15      0.18     0.79       1.5  #â€“ ãƒ¢ãƒ‡ãƒ«ã®1è¡Œè¦ç´„ã‚’å–å¾—  glance(fit_postpi) #>        method model include_intercept nobs_labeled nobs_unlabeled       call #> 1 postpi_boot   ols              TRUE          500           1000 Y - f ~ X1  #â€“ å…ƒã®ãƒ‡ãƒ¼ã‚¿ã«é©åˆå€¤ã¨æ®‹å·®ã‚’è¿½åŠ   augmented_df <- augment(fit_postpi)  head(augmented_df) #>          X1     X2    X3    X4    Y     f set_label .fitted .resid #> 10501  0.99 -3.280 -0.39  0.97  8.4  1.25 unlabeled   1.992    6.5 #> 10502 -0.66  0.142 -1.36 -0.22 -7.2 -1.08 unlabeled   0.099   -7.3 #> 10503  0.58 -1.368 -1.73  0.15  5.6 -0.31 unlabeled   1.522    4.1 #> 10504 -0.14 -0.728  0.26 -0.23 -4.2  0.91 unlabeled   0.702   -4.9 #> 10505 -0.17 -0.068 -1.10  0.58  2.2 -0.39 unlabeled   0.667    1.5 #> 10506  0.58  0.514 -0.69  0.97 -1.2  0.76 unlabeled   1.521   -2.7"},{"path":"https://ipd-tools.github.io/ipd/README-JPN.html","id":"ãƒ“ãƒãƒƒãƒˆ","dir":"","previous_headings":"","what":"ãƒ“ãƒãƒƒãƒˆ","title":"ipd: Inference on Predicted Data","text":"ã•ã‚‰ãªã‚‹è©³ç´°ã¨ã—ã¦ã€ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ãƒ“ãƒãƒƒãƒˆã§ã‚ˆã‚Šå¤šãã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã¨ä¾‹ã‚’æä¾›ã—ã¦ã„ã¾ã™ï¼š","code":"vignette(\"ipd\")"},{"path":"https://ipd-tools.github.io/ipd/README-JPN.html","id":"ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯","dir":"","previous_headings":"","what":"ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯","title":"ipd: Inference on Predicted Data","text":"è³ªå•ã€ã‚³ãƒ¡ãƒ³ãƒˆã€ãã®ä»–ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã«ã¤ã„ã¦ã¯ã€é–‹ç™ºè€…ï¼ˆssalerno@fredhutch.orgï¼‰ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚","code":""},{"path":"https://ipd-tools.github.io/ipd/README-JPN.html","id":"è²¢çŒ®","dir":"","previous_headings":"","what":"è²¢çŒ®","title":"ipd: Inference on Predicted Data","text":"è²¢çŒ®ã‚’æ­“è¿ã—ã¾ã™ï¼GitHubã§å•é¡Œã‚’é–‹ãã‹ã€ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æå‡ºã—ã¦ãã ã•ã„ã€‚ç¾åœ¨ã€ä»¥ä¸‹ã®æ‰‹æ³•/ãƒ¢ãƒ‡ãƒ«ã®çµ„ã¿åˆã‚ã›ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã¾ã™ï¼š","code":""},{"path":"https://ipd-tools.github.io/ipd/README-JPN.html","id":"ãƒ©ã‚¤ã‚»ãƒ³ã‚¹","dir":"","previous_headings":"","what":"ãƒ©ã‚¤ã‚»ãƒ³ã‚¹","title":"ipd: Inference on Predicted Data","text":"ã“ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¯MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ä¸‹ã§ãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚","code":""},{"path":[]},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"background","dir":"Articles","previous_headings":"Introduction","what":"Background","title":"Getting Started with the ipd Package","text":"rapid advancement artificial intelligence machine learning (AI/ML), researchers wide range disciplines increasingly use predictions pre-trained algorithms outcome variables statistical analyses. However, reifying algorithmically-derived values measured outcomes may lead biased estimates anti-conservative inference (Hoffman et al., 2023). statistical challenges encountered drawing inference predicted data (IPD) include: Understanding relationship predicted outcomes true, unobserved counterparts Quantifying robustness AI/ML models resampling uncertainty training data Appropriately propagating bias uncertainty predictions downstream inferential tasks Several works proposed methods IPD, including post-prediction inference (PostPI) Wang et al., 2020, prediction-powered inference (PPI) PPI++ Angelopoulos et al., 2023a Angelopoulos et al., 2023b, post-prediction adaptive inference (PSPA) Miao et al., 2023, correction based Chen Chen method alternate PPI â€œâ€ Gronsbell et al., 2025. enable researchers practitioners interested state---art methods, developed ipd, open-source R package implements methods umbrella IPD. vignette provides guide using ipd package, including installation instructions, examples data generation, model fitting, usage custom methods. examples demonstrate packageâ€™s functionality.","code":""},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"notation","dir":"Articles","previous_headings":"Introduction","what":"Notation","title":"Getting Started with the ipd Package","text":"Following notation Miao et al., 2023, assume following data structure: Labeled data L={YL,XL,f(XL)}L=\\{Y^L,X^L,f(X^L)\\}; unlabeled data U={XU,f(XU)}U=\\{X^U,f(X^U)\\}. labeled set typically smaller size compared unlabeled set. access algorithm f(X)f(X) can predict outcome, YY. interest performing inference quantity outcome mean quantile, recover downstream inferential (mean) model: ğ”¼[Yğ’°âˆ£ğ—ğ’°]=gâˆ’1(ğ—ğ’°â€²Î²),\\mathbb{E}\\left[Y^{\\mathcal{U}} \\mid \\boldsymbol{X}^{\\mathcal{U}}\\right] =  g^{-1}\\left(\\boldsymbol{X}^{\\mathcal{U}'}\\beta\\right), Î²\\beta vector regression coefficients g(â‹…)g(\\cdot) given link function, identity link linear regression, logistic link logistic regression, log link Poisson regression. However, practice, observe Yğ’°Y^\\mathcal{U} â€˜unlabeledâ€™ subset data. Instead, values replaced predicted f(Xğ’°)f(X^\\mathcal{U}). can use methods IPD obtain corrected estimates standard errors replace unobserved Yğ’°Y^\\mathcal{U} f(Xğ’°)f(X^\\mathcal{U}).","code":""},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"installation","dir":"Articles","previous_headings":"Introduction","what":"Installation","title":"Getting Started with the ipd Package","text":"install ipd package Bioconductor, can use BiocManager package: , install development version ipd GitHub, can use devtools package:","code":"#-- Install BiocManager if it is not already installed  if (!require(\"BiocManager\", quietly = TRUE))     install.packages(\"BiocManager\")  BiocManager::install(version = \"3.21\")  #-- Install the ipd package from Bioconductor  BiocManager::install(\"ipd\") #-- Install devtools if it is not already installed  install.packages(\"devtools\")  #-- Install the ipd package from GitHub  devtools::install_github(\"ipd-tools/ipd\")"},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"usage","dir":"Articles","previous_headings":"","what":"Usage","title":"Getting Started with the ipd Package","text":"provide simple example demonstrate basic use functions included ipd package.","code":"#-- Load ipd Package  library(ipd)"},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"data-generation","dir":"Articles","previous_headings":"Usage","what":"Data Generation","title":"Getting Started with the ipd Package","text":"ipd packages provides unified function, simdat, generating synthetic datasets various models. function currently supports â€œmeanâ€, â€œquantileâ€, â€œolsâ€, â€œlogisticâ€, â€œpoissonâ€ models.","code":""},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"function-arguments","dir":"Articles","previous_headings":"Usage > Data Generation","what":"Function Arguments","title":"Getting Started with the ipd Package","text":"n: vector size 3 indicating sample size training, labeled, unlabeled data sets. effect: float specifying regression coefficient first variable interest (defaults 1). sigma_Y: float specifying residual variance generated outcome. model: type model generated. Must one \"mean\", \"quantile\", \"ols\", \"logistic\", \"poisson\". simdat function generate data.frame three subsets: (1) independent â€œtrainingâ€ set additional observations used fit prediction model, â€œlabeledâ€ â€œunlabeledâ€ sets contain observed predicted outcomes simulated features interest.","code":""},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"generating-data-for-linear-regression","dir":"Articles","previous_headings":"Usage > Data Generation","what":"Generating Data for Linear Regression","title":"Getting Started with the ipd Package","text":"can generate continuous outcome relevant predictors linear regression follows. simdat function generates four independent covariates, X1X_1, X2X_2, X3X_3, X4X_4, outcome: Y=effectÃ—X1+12Ã—X22+13Ã—X33+14Ã—X42+ÎµyY = \\text{effect}\\times X_1 + \\frac{1}{2}\\times X_2^2 +  \\frac{1}{3}\\times X_3^3 + \\frac{1}{4}\\times X_4^2 + \\varepsilon_y effect one function arguments Îµyâˆ¼N(0,sigma_Y)\\varepsilon_y \\sim N(0, \\text{sigma_Y}), sigma_Y another argument. , simdat function generates three subsets data, â€œtrainingâ€ subset, â€œlabeledâ€ subset, â€œunlabeledâ€ subset, based sizes n. learns prediction rule outcome â€œtrainingâ€ subset using generalized additive model predicts outcomes â€œlabeledâ€ â€œunlabeledâ€ subsets: simdat function provides observed unobserved outcomes labeled unlabeled datasets, though practice observed outcomes unlabeled set. can visualize relationships variables labeled data subset:  can see : predicted outcomes correlated covariate true outcomes (plot ) predicted outcomes perfect substitutes true outcomes (plot B)","code":"#-- Generate a Dataset for Linear Regression  set.seed(123)  n <- c(10000, 500, 1000)  dat_ols <- simdat(n = n, effect = 1, sigma_Y = 4, model = \"ols\",                        shift = 1, scale = 2)  #-- Print First 6 Rows of Training, Labeled, and Unlabeled Subsets  options(digits = 2)  head(dat_ols[dat_ols$set_label == \"training\", ]) #>       X1    X2    X3     X4     Y  f set_label #> 1 -0.560 -0.56  0.82 -0.356 -0.15 NA  training #> 2 -0.230  0.13 -1.54  0.040 -4.49 NA  training #> 3  1.559  1.82 -0.59  1.152 -1.08 NA  training #> 4  0.071  0.16 -0.18  1.485 -3.67 NA  training #> 5  0.129 -0.72 -0.71  0.634  2.19 NA  training #> 6  1.715  0.58 -0.54 -0.037 -1.42 NA  training  head(dat_ols[dat_ols$set_label == \"labeled\", ]) #>          X1      X2    X3    X4     Y      f set_label #> 10001  2.37 -1.8984  0.20 -0.17  1.40  1.120   labeled #> 10002 -0.17  1.7428  0.26 -2.05  3.56  0.017   labeled #> 10003  0.93 -1.0947  0.76  1.25 -3.66  0.686   labeled #> 10004 -0.57  0.1757  0.32  0.65 -0.56 -0.212   labeled #> 10005  0.23  2.0620 -1.35  1.46 -0.82 -0.573   labeled #> 10006  1.13 -0.0028  0.23 -0.24  7.30  0.579   labeled  head(dat_ols[dat_ols$set_label == \"unlabeled\", ]) #>          X1     X2    X3    X4    Y      f set_label #> 10501  0.99 -3.280 -0.39  0.97  8.4  0.124 unlabeled #> 10502 -0.66  0.142 -1.36 -0.22 -7.2 -1.040 unlabeled #> 10503  0.58 -1.368 -1.73  0.15  5.6 -0.653 unlabeled #> 10504 -0.14 -0.728  0.26 -0.23 -4.2 -0.047 unlabeled #> 10505 -0.17 -0.068 -1.10  0.58  2.2 -0.693 unlabeled #> 10506  0.58  0.514 -0.69  0.97 -1.2 -0.122 unlabeled"},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"generating-data-for-logistic-regression","dir":"Articles","previous_headings":"Usage > Data Generation","what":"Generating Data for Logistic Regression","title":"Getting Started with the ipd Package","text":"another example, can generate binary outcome relevant predictors logistic regression follows: can visualize relationships true predicted outcome variables labeled data subset see 81.8% observations correctly predicted:","code":"#-- Generate a Dataset for Logistic Regression  set.seed(123)  dat_logistic <- simdat(n = n, effect = 3, sigma_Y = 1, model = \"logistic\")  #-- Print First 6 Rows of Training, Labeled, and Unlabeled Subsets  head(dat_logistic[dat_logistic$set_label == \"training\", ]) #>       X1    X2    X3     X4 Y  f set_label #> 1 -0.560 -0.56  0.82 -0.356 1 NA  training #> 2 -0.230  0.13 -1.54  0.040 0 NA  training #> 3  1.559  1.82 -0.59  1.152 1 NA  training #> 4  0.071  0.16 -0.18  1.485 0 NA  training #> 5  0.129 -0.72 -0.71  0.634 0 NA  training #> 6  1.715  0.58 -0.54 -0.037 1 NA  training  head(dat_logistic[dat_logistic$set_label == \"labeled\", ]) #>          X1      X2    X3    X4 Y f set_label #> 10001  2.37 -1.8984  0.20 -0.17 1 1   labeled #> 10002 -0.17  1.7428  0.26 -2.05 1 1   labeled #> 10003  0.93 -1.0947  0.76  1.25 1 1   labeled #> 10004 -0.57  0.1757  0.32  0.65 1 0   labeled #> 10005  0.23  2.0620 -1.35  1.46 1 1   labeled #> 10006  1.13 -0.0028  0.23 -0.24 1 1   labeled  head(dat_logistic[dat_logistic$set_label == \"unlabeled\", ]) #>          X1     X2    X3    X4 Y f set_label #> 10501  0.99 -3.280 -0.39  0.97 1 1 unlabeled #> 10502 -0.66  0.142 -1.36 -0.22 0 0 unlabeled #> 10503  0.58 -1.368 -1.73  0.15 1 1 unlabeled #> 10504 -0.14 -0.728  0.26 -0.23 0 0 unlabeled #> 10505 -0.17 -0.068 -1.10  0.58 1 0 unlabeled #> 10506  0.58  0.514 -0.69  0.97 1 1 unlabeled"},{"path":[]},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"linear-regression","dir":"Articles","previous_headings":"Usage > Model Fitting","what":"Linear Regression","title":"Getting Started with the ipd Package","text":"compare two non-IPD approaches analyzing data methods included ipd package.","code":""},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"naive-regression-using-the-predicted-outcomes","dir":"Articles","previous_headings":"Usage > Model Fitting > Linear Regression","what":"0.1 â€˜Naiveâ€™ Regression Using the Predicted Outcomes","title":"Getting Started with the ipd Package","text":"","code":"#--- Fit the Naive Regression  lm(f ~ X1, data = dat_ols[dat_ols$set_label == \"unlabeled\", ]) |>      summary() #>  #> Call: #> lm(formula = f ~ X1, data = dat_ols[dat_ols$set_label == \"unlabeled\",  #>     ]) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -1.2713 -0.3069 -0.0076  0.3173  1.4453  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)  -0.0805     0.0148   -5.42  7.4e-08 *** #> X1            0.4924     0.0148   33.32  < 2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.47 on 998 degrees of freedom #> Multiple R-squared:  0.527,  Adjusted R-squared:  0.526  #> F-statistic: 1.11e+03 on 1 and 998 DF,  p-value: <2e-16"},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"classic-regression-using-only-the-labeled-data","dir":"Articles","previous_headings":"Usage > Model Fitting > Linear Regression","what":"0.2 â€˜Classicâ€™ Regression Using only the Labeled Data","title":"Getting Started with the ipd Package","text":"can fit various IPD methods data obtain summaries using provided wrapper function, ipd():","code":"#--- Fit the Classic Regression  lm(Y ~ X1, data = dat_ols[dat_ols$set_label == \"labeled\", ]) |>      summary() #>  #> Call: #> lm(formula = Y ~ X1, data = dat_ols[dat_ols$set_label == \"labeled\",  #>     ]) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -15.262  -2.828  -0.094   2.821  11.685  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)    0.908      0.187    4.86  1.6e-06 *** #> X1             1.097      0.192    5.71  1.9e-08 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 4.2 on 498 degrees of freedom #> Multiple R-squared:  0.0614, Adjusted R-squared:  0.0596  #> F-statistic: 32.6 on 1 and 498 DF,  p-value: 1.95e-08"},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"chen-and-chen-correction-gronsbell-et-al--2025","dir":"Articles","previous_headings":"Usage > Model Fitting > Linear Regression","what":"1. Chen and Chen Correction (Gronsbell et al., 2025)","title":"Getting Started with the ipd Package","text":"","code":"#-- Specify the Formula  formula <- Y - f ~ X1  #-- Fit the Chen and Chen Correction  ipd::ipd(formula, method = \"chen\", model = \"ols\",       data = dat_ols, label = \"set_label\") |>      summary() #>  #> Call: #>   Y - f ~ X1  #>  #> Method:    chen  #> Model:     ols  #> Intercept: Yes  #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)    0.880      0.182    4.83  1.3e-06 *** #> X1             1.114      0.186    5.98  2.2e-09 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"postpi-bootstrap-correction-wang-et-al--2020","dir":"Articles","previous_headings":"Usage > Model Fitting > Linear Regression","what":"2.1 PostPI Bootstrap Correction (Wang et al., 2020)","title":"Getting Started with the ipd Package","text":"","code":"#-- Fit the PostPI Bootstrap Correction  nboot <- 200  ipd::ipd(formula, method = \"postpi_boot\", model = \"ols\",       data = dat_ols, label = \"set_label\", nboot = nboot) |>      summary() #>  #> Call: #>   Y - f ~ X1  #>  #> Method:    postpi_boot  #> Model:     ols  #> Intercept: Yes  #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)    0.873      0.183    4.77  1.9e-06 *** #> X1             1.151      0.183    6.30  2.9e-10 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"postpi-analytic-correction-wang-et-al--2020","dir":"Articles","previous_headings":"Usage > Model Fitting > Linear Regression","what":"2.2 PostPI Analytic Correction (Wang et al., 2020)","title":"Getting Started with the ipd Package","text":"","code":"#-- Fit the PostPI Analytic Correction  ipd::ipd(formula, method = \"postpi_analytic\", model = \"ols\",       data = dat_ols, label = \"set_label\") |>      summary() #>  #> Call: #>   Y - f ~ X1  #>  #> Method:    postpi_analytic  #> Model:     ols  #> Intercept: Yes  #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)   -0.187      0.187   -1.00     0.32     #> X1             1.128      0.191    5.92  3.3e-09 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"prediction-powered-inference-ppi-angelopoulos-et-al--2023","dir":"Articles","previous_headings":"Usage > Model Fitting > Linear Regression","what":"3. Prediction-Powered Inference (PPI; Angelopoulos et al., 2023)","title":"Getting Started with the ipd Package","text":"","code":"#-- Fit the PPI Correction  ipd::ipd(formula, method = \"ppi\", model = \"ols\",       data = dat_ols, label = \"set_label\") |>      summary() #>  #> Call: #>   Y - f ~ X1  #>  #> Method:    ppi  #> Model:     ols  #> Intercept: Yes  #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)    0.890      0.183    4.87  1.1e-06 *** #> X1             1.110      0.195    5.69  1.3e-08 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"ppi-all-gronsbell-et-al--2025","dir":"Articles","previous_headings":"Usage > Model Fitting > Linear Regression","what":"4. PPI â€œAllâ€ (Gronsbell et al., 2025)","title":"Getting Started with the ipd Package","text":"","code":"#-- Fit the PPI Correction  ipd::ipd(formula, method = \"ppi_a\", model = \"ols\",       data = dat_ols, label = \"set_label\") |>      summary() #>  #> Call: #>   Y - f ~ X1  #>  #> Method:    ppi_a  #> Model:     ols  #> Intercept: Yes  #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)    0.896      0.183    4.91  9.2e-07 *** #> X1             1.106      0.195    5.67  1.4e-08 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"ppi-angelopoulos-et-al--2023","dir":"Articles","previous_headings":"Usage > Model Fitting > Linear Regression","what":"5. PPI++ (Angelopoulos et al., 2023)","title":"Getting Started with the ipd Package","text":"","code":"#-- Fit the PPI++ Correction  ipd::ipd(formula, method = \"ppi_plusplus\", model = \"ols\",       data = dat_ols, label = \"set_label\") |>      summary() #>  #> Call: #>   Y - f ~ X1  #>  #> Method:    ppi_plusplus  #> Model:     ols  #> Intercept: Yes  #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)    0.904      0.185    4.87  1.1e-06 *** #> X1             1.100      0.190    5.78  7.5e-09 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"post-prediction-adaptive-inference-pspa-miao-et-al--2023","dir":"Articles","previous_headings":"Usage > Model Fitting > Linear Regression","what":"6. Post-Prediction Adaptive Inference (PSPA; Miao et al., 2023)","title":"Getting Started with the ipd Package","text":"","code":"#-- Fit the PSPA Correction  ipd::ipd(formula, method = \"pspa\", model = \"ols\",       data = dat_ols, label = \"set_label\") |>      summary() #>  #> Call: #>   Y - f ~ X1  #>  #> Method:    pspa  #> Model:     ols  #> Intercept: Yes  #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)    0.900      0.185    4.87  1.1e-06 *** #> X1             1.095      0.190    5.76  8.5e-09 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"logistic-regression","dir":"Articles","previous_headings":"Usage > Model Fitting","what":"Logistic Regression","title":"Getting Started with the ipd Package","text":"also show methods compare logistic regression.","code":""},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"naive-regression-using-the-predicted-outcomes-1","dir":"Articles","previous_headings":"Usage > Model Fitting > Logistic Regression","what":"0.1 â€˜Naiveâ€™ Regression Using the Predicted Outcomes","title":"Getting Started with the ipd Package","text":"","code":"#--- Fit the Naive Regression  glm(f ~ X1, family = binomial,      data = dat_logistic[dat_logistic$set_label == \"unlabeled\", ]) |>      summary() #>  #> Call: #> glm(formula = f ~ X1, family = binomial, data = dat_logistic[dat_logistic$set_label ==  #>     \"unlabeled\", ]) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)    1.173      0.125    9.36   <2e-16 *** #> X1             3.832      0.257   14.93   <2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 1328.13  on 999  degrees of freedom #> Residual deviance:  569.36  on 998  degrees of freedom #> AIC: 573.4 #>  #> Number of Fisher Scoring iterations: 7"},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"classic-regression-using-only-the-labeled-data-1","dir":"Articles","previous_headings":"Usage > Model Fitting > Logistic Regression","what":"0.2 â€˜Classicâ€™ Regression Using only the Labeled Data","title":"Getting Started with the ipd Package","text":"can fit various IPD methods data obtain summaries using provided wrapper function, ipd():","code":"#--- Fit the Classic Regression  glm(Y ~ X1, family = binomial,       data = dat_logistic[dat_logistic$set_label == \"labeled\", ]) |>      summary() #>  #> Call: #> glm(formula = Y ~ X1, family = binomial, data = dat_logistic[dat_logistic$set_label ==  #>     \"labeled\", ]) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)    0.677      0.121    5.58  2.5e-08 *** #> X1             2.064      0.196   10.56  < 2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 665.99  on 499  degrees of freedom #> Residual deviance: 449.44  on 498  degrees of freedom #> AIC: 453.4 #>  #> Number of Fisher Scoring iterations: 5"},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"postpi-bootstrap-correction-wang-et-al--2020-1","dir":"Articles","previous_headings":"Usage > Model Fitting > Logistic Regression","what":"1. PostPI Bootstrap Correction (Wang et al., 2020)","title":"Getting Started with the ipd Package","text":"","code":"#-- Specify the Formula  formula <- Y - f ~ X1  #-- Fit the PostPI Bootstrap Correction  nboot <- 200  ipd::ipd(formula, method = \"postpi_boot\", model = \"logistic\",      data = dat_logistic, label = \"set_label\", nboot = nboot) |>      summary() #>  #> Call: #>   Y - f ~ X1  #>  #> Method:    postpi_boot  #> Model:     logistic  #> Intercept: Yes  #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)   0.5503     0.0741    7.43  1.1e-13 *** #> X1            1.1252     0.0891   12.63  < 2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"prediction-powered-inference-ppi-angelopoulos-et-al--2023-1","dir":"Articles","previous_headings":"Usage > Model Fitting > Logistic Regression","what":"2. Prediction-Powered Inference (PPI; Angelopoulos et al., 2023)","title":"Getting Started with the ipd Package","text":"","code":"#-- Fit the PPI Correction  ipd::ipd(formula, method = \"ppi\", model = \"logistic\",      data = dat_logistic, label = \"set_label\") |>      summary() #>  #> Call: #>   Y - f ~ X1  #>  #> Method:    ppi  #> Model:     logistic  #> Intercept: Yes  #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)    0.711      0.162    4.39  1.1e-05 *** #> X1             2.092      0.214    9.79  < 2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"ppi-angelopoulos-et-al--2023-1","dir":"Articles","previous_headings":"Usage > Model Fitting > Logistic Regression","what":"3. PPI++ (Angelopoulos et al., 2023)","title":"Getting Started with the ipd Package","text":"","code":"#-- Fit the PPI++ Correction  ipd::ipd(formula, method = \"ppi_plusplus\", model = \"logistic\",      data = dat_logistic, label = \"set_label\") |>      summary() #>  #> Call: #>   Y - f ~ X1  #>  #> Method:    ppi_plusplus  #> Model:     logistic  #> Intercept: Yes  #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)    0.688      0.128    5.39  7.1e-08 *** #> X1             2.074      0.189   10.95  < 2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"post-prediction-adaptive-inference-pspa-miao-et-al--2023-1","dir":"Articles","previous_headings":"Usage > Model Fitting > Logistic Regression","what":"4. Post-Prediction Adaptive Inference (PSPA; Miao et al., 2023)","title":"Getting Started with the ipd Package","text":"","code":"#-- Fit the PSPA Correction  ipd::ipd(formula, method = \"pspa\", model = \"logistic\",       data = dat_logistic, label = \"set_label\") |>      summary() #>  #> Call: #>   Y - f ~ X1  #>  #> Method:    pspa  #> Model:     logistic  #> Intercept: Yes  #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)    0.684      0.124    5.52  3.4e-08 *** #> X1             2.072      0.192   10.77  < 2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"printing-summarizing-and-tidying","dir":"Articles","previous_headings":"Usage","what":"Printing, Summarizing, and Tidying","title":"Getting Started with the ipd Package","text":"package also provides custom print, summary, tidy, glance, augment methods facilitate easy model inspection:","code":"#-- Fit the PostPI Bootstrap Correction  nboot <- 200  fit_postpi <- ipd::ipd(formula, method = \"postpi_boot\", model = \"ols\",      data = dat_ols, label = \"set_label\", nboot = nboot)"},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"print-method","dir":"Articles","previous_headings":"Usage > Printing, Summarizing, and Tidying","what":"Print Method","title":"Getting Started with the ipd Package","text":"print method gives abbreviated summary output ipd function:","code":"#-- Print the Model  print(fit_postpi) #> IPD inference summary #>   Method:   postpi_boot  #>   Model:    ols  #>   Formula:  Y - f ~ X1  #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)    0.867      0.183    4.73  2.2e-06 *** #> X1             1.154      0.183    6.32  2.6e-10 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"summary-method","dir":"Articles","previous_headings":"Usage > Printing, Summarizing, and Tidying","what":"Summary Method","title":"Getting Started with the ipd Package","text":"summary method gives detailed information estimated coefficients, standard errors, confidence limits:","code":"#-- Summarize the Model  summ_fit_postpi <- summary(fit_postpi)  #-- Print the Model Summary  print(summ_fit_postpi) #>  #> Call: #>   Y - f ~ X1  #>  #> Method:    postpi_boot  #> Model:     ols  #> Intercept: Yes  #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)    0.867      0.183    4.73  2.2e-06 *** #> X1             1.154      0.183    6.32  2.6e-10 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"tidy-method","dir":"Articles","previous_headings":"Usage > Printing, Summarizing, and Tidying","what":"Tidy Method","title":"Getting Started with the ipd Package","text":"tidy method organizes model coefficients tidy format.","code":"#-- Tidy the Model Output  tidy(fit_postpi) #> # A tibble: 2 Ã— 5 #>   term        estimate std.error conf.low conf.high #>   <chr>          <dbl>     <dbl>    <dbl>     <dbl> #> 1 (Intercept)    0.867     0.183    0.508      1.23 #> 2 X1             1.15      0.183    0.796      1.51"},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"glance-method","dir":"Articles","previous_headings":"Usage > Printing, Summarizing, and Tidying","what":"Glance Method","title":"Getting Started with the ipd Package","text":"glance method returns one-row summary model fit.","code":"#-- Get a One-Row Summary of the Model  glance(fit_postpi) #> # A tibble: 1 Ã— 6 #>   method      model intercept nobs_labeled nobs_unlabeled call       #>   <chr>       <chr> <lgl>            <int>          <int> <chr>      #> 1 postpi_boot ols   TRUE               500           1000 Y - f ~ X1"},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"augment-method","dir":"Articles","previous_headings":"Usage > Printing, Summarizing, and Tidying","what":"Augment Method","title":"Getting Started with the ipd Package","text":"augment method adds model predictions residuals original dataset.","code":"#-- Augment the Original Data with Fitted Values and Residuals  augmented_df <- augment(fit_postpi)  head(augmented_df) #>          X1     X2    X3    X4    Y      f set_label .fitted .resid #> 10501  0.99 -3.280 -0.39  0.97  8.4  0.124 unlabeled    2.00    6.4 #> 10502 -0.66  0.142 -1.36 -0.22 -7.2 -1.040 unlabeled    0.10   -7.3 #> 10503  0.58 -1.368 -1.73  0.15  5.6 -0.653 unlabeled    1.53    4.1 #> 10504 -0.14 -0.728  0.26 -0.23 -4.2 -0.047 unlabeled    0.71   -4.9 #> 10505 -0.17 -0.068 -1.10  0.58  2.2 -0.693 unlabeled    0.67    1.5 #> 10506  0.58  0.514 -0.69  0.97 -1.2 -0.122 unlabeled    1.53   -2.7"},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"conclusions","dir":"Articles","previous_headings":"","what":"Conclusions","title":"Getting Started with the ipd Package","text":"ipd package offers suite functions conducting inference predicted data. custom methods printing, summarizing, tidying, glancing, augmenting model outputs, ipd streamlines process IPD-based inference R. continue develop package include targets inference IPD methods developed, well additional functionality analyzing data. information detailed documentation, please refer function help pages within package, e.g.,","code":"?ipd"},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"feedback","dir":"Articles","previous_headings":"Conclusions","what":"Feedback","title":"Getting Started with the ipd Package","text":"questions, comments, feedback, please contact developers (ssalerno@fredhutch.org).","code":""},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"contributing","dir":"Articles","previous_headings":"Conclusions","what":"Contributing","title":"Getting Started with the ipd Package","text":"Contributions welcome! Please open issue submit pull request GitHub.","code":""},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"license","dir":"Articles","previous_headings":"Conclusions","what":"License","title":"Getting Started with the ipd Package","text":"package licensed MIT License.","code":""},{"path":"https://ipd-tools.github.io/ipd/articles/ipd.html","id":"session-info","dir":"Articles","previous_headings":"Conclusions","what":"Session Info","title":"Getting Started with the ipd Package","text":"","code":"sessionInfo() #> R version 4.5.0 (2025-04-11) #> Platform: x86_64-pc-linux-gnu #> Running under: Ubuntu 24.04.2 LTS #>  #> Matrix products: default #> BLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3  #> LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.26.so;  LAPACK version 3.12.0 #>  #> locale: #>  [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8        #>  [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8    #>  [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C           #> [10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C    #>  #> time zone: UTC #> tzcode source: system (glibc) #>  #> attached base packages: #> [1] stats     graphics  grDevices utils     datasets  methods   base      #>  #> other attached packages: #>  [1] caret_7.0-1      lattice_0.22-6   patchwork_1.3.0  lubridate_1.9.4  #>  [5] forcats_1.0.0    stringr_1.5.1    dplyr_1.1.4      purrr_1.0.4      #>  [9] readr_2.1.5      tidyr_1.3.1      tibble_3.2.1     ggplot2_3.5.2    #> [13] tidyverse_2.0.0  ipd_0.99.0       BiocStyle_2.36.0 #>  #> loaded via a namespace (and not attached): #>  [1] tidyselect_1.2.1     timeDate_4041.110    farver_2.1.2         #>  [4] fastmap_1.2.0        pROC_1.18.5          digest_0.6.37        #>  [7] rpart_4.1.24         timechange_0.3.0     lifecycle_1.0.4      #> [10] survival_3.8-3       magrittr_2.0.3       compiler_4.5.0       #> [13] rlang_1.1.6          sass_0.4.10          tools_4.5.0          #> [16] utf8_1.2.5           yaml_2.3.10          data.table_1.17.4    #> [19] knitr_1.50           labeling_0.4.3       plyr_1.8.9           #> [22] RColorBrewer_1.1-3   withr_3.0.2          BiocGenerics_0.54.0  #> [25] desc_1.4.3           nnet_7.3-20          grid_4.5.0           #> [28] stats4_4.5.0         e1071_1.7-16         future_1.49.0        #> [31] globals_0.18.0       scales_1.4.0         iterators_1.0.14     #> [34] MASS_7.3-65          cli_3.6.5            rmarkdown_2.29       #> [37] ragg_1.4.0           generics_0.1.4       future.apply_1.11.3  #> [40] tzdb_0.5.0           reshape2_1.4.4       proxy_0.4-27         #> [43] cachem_1.1.0         splines_4.5.0        parallel_4.5.0       #> [46] BiocManager_1.30.25  vctrs_0.6.5          hardhat_1.4.1        #> [49] Matrix_1.7-3         jsonlite_2.0.0       bookdown_0.43        #> [52] hms_1.1.3            listenv_0.9.1        systemfonts_1.2.3    #> [55] foreach_1.5.2        gam_1.22-5           gower_1.0.2          #> [58] jquerylib_0.1.4      recipes_1.3.1        glue_1.8.0           #> [61] parallelly_1.45.0    pkgdown_2.1.3        codetools_0.2-20     #> [64] stringi_1.8.7        gtable_0.3.6         pillar_1.10.2        #> [67] htmltools_0.5.8.1    ipred_0.9-15         randomForest_4.7-1.2 #> [70] lava_1.8.1           R6_2.6.1             textshaping_1.0.1    #> [73] evaluate_1.0.3       bslib_0.9.0          class_7.3-23         #> [76] Rcpp_1.0.14          nlme_3.1-168         prodlim_2025.04.28   #> [79] mgcv_1.9-1           ranger_0.17.0        xfun_0.52            #> [82] fs_1.6.6             pkgconfig_2.0.3      ModelMetrics_1.2.2.2"},{"path":"https://ipd-tools.github.io/ipd/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Stephen Salerno. Author, maintainer, copyright holder. Jiacheng Miao. Author. Awan Afiaz. Author. Kentaro Hoffman. Author. Jesse Gronsbell. Author. Jianhui Gao. Author. David Cheng. Author. Anna Neufeld. Author. Qiongshi Lu. Author. Tyler H McCormick. Author. Jeffrey T Leek. Author.","code":""},{"path":"https://ipd-tools.github.io/ipd/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Salerno S, Miao J, Afiaz , Hoffman K, Neufeld , Lu Q, McCormick T, Leek J (2025). â€œipd: R package conducting inference predicted data.â€ Bioinformatics, 41(2), btaf055. doi:10.1093/bioinformatics/btaf055.","code":"@Article{,   title = {ipd: an R package for conducting inference on predicted data},   author = {Stephen Salerno and Jiacheng Miao and Awan Afiaz and Kentaro Hoffman and Anna Neufeld and Qiongshi Lu and Tyler H McCormick and Jeffrey T Leek},   year = {2025},   journal = {Bioinformatics},   volume = {41},   number = {2},   pages = {btaf055},   doi = {10.1093/bioinformatics/btaf055}, }"},{"path":[]},{"path":[]},{"path":"https://ipd-tools.github.io/ipd/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Inference on Predicted Data","text":"ipd open-source R software package downstream modeling outcome associated features potentially sizable portion outcome data imputed artificial intelligence machine learning (AI/ML) prediction algorithm. package implements several recent proposed methods inference predicted data (IPD) single, user-friendly wrapper function, ipd. package also provides custom print, summary, tidy, glance, augment methods facilitate easy model inspection.","code":""},{"path":"https://ipd-tools.github.io/ipd/index.html","id":"background","dir":"","previous_headings":"","what":"Background","title":"Inference on Predicted Data","text":"Using predictions pre-trained algorithms outcomes downstream statistical analyses can lead biased estimates misleading conclusions. statistical challenges encountered drawing inference predicted data (IPD) include: Understanding relationship predicted outcomes true, unobserved counterparts. Quantifying robustness AI/ML models resampling uncertainty training data. Appropriately propagating bias uncertainty predictions downstream inferential tasks. Several works proposed methods IPD, including post-prediction inference (PostPI) Wang et al., 2020, prediction-powered inference (PPI) PPI++ Angelopoulos et al., 2023a Angelopoulos et al., 2023b, post-prediction adaptive inference (PSPA) Miao et al., 2023, correction based Chen Chen method alternate PPI â€œâ€ Gronsbell et al., 2025. method developed perform inference quantity outcome mean quantile, regression coefficient, : dataset consisting outcome features interst, outcome observed small â€˜labeledâ€™ subset missing , typically larger, â€˜unlabeledâ€™ subset. Access algorithm predict missing outcome entire dataset using fully observed features. Overview data setup IPD can use methods IPD obtain corrected estimates standard errors using predicted outcomes unlabeled features augment labeled subset data. enable researchers practitioners interested state---art methods, developed ipd package R implement methods umbrella IPD. README provides overview package, including installation instructions, basic usage examples, links documentation. examples show generate data, fit models, use custom methods provided package.","code":""},{"path":"https://ipd-tools.github.io/ipd/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Inference on Predicted Data","text":"install ipd package Bioconductor, can use BiocManager package: , install development version ipd GitHub, can use devtools package:","code":"#-- Install BiocManager if it is not already installed  if (!require(\"BiocManager\", quietly = TRUE))     install.packages(\"BiocManager\")  BiocManager::install(version = \"3.21\")  #-- Install the ipd package from Bioconductor  BiocManager::install(\"ipd\") #-- Install devtools if it is not already installed  install.packages(\"devtools\")  #-- Install the ipd package from GitHub  devtools::install_github(\"ipd-tools/ipd\")"},{"path":"https://ipd-tools.github.io/ipd/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Inference on Predicted Data","text":"provide simple example demonstrate basic use functions included ipd package.","code":""},{"path":"https://ipd-tools.github.io/ipd/index.html","id":"data-generation","dir":"","previous_headings":"Usage","what":"Data Generation","title":"Inference on Predicted Data","text":"can generate synthetic datasets different types regression models using provided simdat function specifying sizes datasets, effect size, residual variance, type model. function currently supports â€œmeanâ€, â€œquantileâ€, â€œolsâ€, â€œlogisticâ€, â€œpoissonâ€ models. simdat function generate data.frame three subsets: (1) independent â€œtrainingâ€ set additional observations used fit prediction model, â€œlabeledâ€ â€œunlabeledâ€ sets contain observed predicted outcomes simulated features interest. simdat function provides observed unobserved outcomes labeled unlabeled datasets, though practice observed outcomes unlabeled set. can visualize relationships variables:  can see : predicted outcomes correlated covariate true outcomes (plot ). predicted outcomes perfect substitutes true outcomes (plot B).","code":"#-- Load the ipd Library  library(ipd) #-- Generate Example Data for Linear Regression  set.seed(123)  n <- c(10000, 500, 1000)  dat <- simdat(n = n, effect = 1, sigma_Y = 4, model = \"ols\",                     shift = 1, scale = 2)  #-- Print First 6 Rows of Training, Labeled, and Unlabeled Subsets  options(digits = 2)  head(dat[dat$set_label == \"training\", ]) #>       X1    X2    X3     X4     Y  f set_label #> 1 -0.560 -0.56  0.82 -0.356 -0.15 NA  training #> 2 -0.230  0.13 -1.54  0.040 -4.49 NA  training #> 3  1.559  1.82 -0.59  1.152 -1.08 NA  training #> 4  0.071  0.16 -0.18  1.485 -3.67 NA  training #> 5  0.129 -0.72 -0.71  0.634  2.19 NA  training #> 6  1.715  0.58 -0.54 -0.037 -1.42 NA  training  head(dat[dat$set_label == \"labeled\", ]) #>          X1      X2    X3    X4     Y      f set_label #> 10001  2.37 -1.8984  0.20 -0.17  1.40  1.120   labeled #> 10002 -0.17  1.7428  0.26 -2.05  3.56  0.017   labeled #> 10003  0.93 -1.0947  0.76  1.25 -3.66  0.686   labeled #> 10004 -0.57  0.1757  0.32  0.65 -0.56 -0.212   labeled #> 10005  0.23  2.0620 -1.35  1.46 -0.82 -0.573   labeled #> 10006  1.13 -0.0028  0.23 -0.24  7.30  0.579   labeled  head(dat[dat$set_label == \"unlabeled\", ]) #>          X1     X2    X3    X4    Y      f set_label #> 10501  0.99 -3.280 -0.39  0.97  8.4  0.124 unlabeled #> 10502 -0.66  0.142 -1.36 -0.22 -7.2 -1.040 unlabeled #> 10503  0.58 -1.368 -1.73  0.15  5.6 -0.653 unlabeled #> 10504 -0.14 -0.728  0.26 -0.23 -4.2 -0.047 unlabeled #> 10505 -0.17 -0.068 -1.10  0.58  2.2 -0.693 unlabeled #> 10506  0.58  0.514 -0.69  0.97 -1.2 -0.122 unlabeled"},{"path":"https://ipd-tools.github.io/ipd/index.html","id":"model-fitting","dir":"","previous_headings":"Usage","what":"Model Fitting","title":"Inference on Predicted Data","text":"compare two non-IPD approaches analyzing data methods included ipd package. summary comparison provided table , followed specific calls method: can see IPD methods similar estimates standard errors, â€˜naiveâ€™ method different estimate standard errors small. compare two non-IPD approaches analyzing data methods included ipd package detail .","code":"#>                    Estimate Std. Error #> Naive                  0.49      0.015 #> Classic                1.10      0.192 #> Chen and Chen          1.11      0.186 #> PostPI (Bootstrap)     1.16      0.183 #> PostPI (Analytic)      1.13      0.191 #> PPI                    1.11      0.195 #> PPI All                1.11      0.195 #> PPI++                  1.10      0.190 #> PSPA                   1.09      0.190"},{"path":"https://ipd-tools.github.io/ipd/index.html","id":"id_01-naive-regression-using-the-predicted-outcomes","dir":"","previous_headings":"Usage > Model Fitting","what":"0.1 â€˜Naiveâ€™ Regression Using the Predicted Outcomes","title":"Inference on Predicted Data","text":"","code":"#--- Fit the Naive Regression  lm(f ~ X1, data = dat[dat$set_label == \"unlabeled\", ]) |>      summary() #>  #> Call: #> lm(formula = f ~ X1, data = dat[dat$set_label == \"unlabeled\",  #>     ]) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -1.2713 -0.3069 -0.0076  0.3173  1.4453  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)  -0.0805     0.0148   -5.42  7.4e-08 *** #> X1            0.4924     0.0148   33.32  < 2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 0.47 on 998 degrees of freedom #> Multiple R-squared:  0.527,  Adjusted R-squared:  0.526  #> F-statistic: 1.11e+03 on 1 and 998 DF,  p-value: <2e-16"},{"path":"https://ipd-tools.github.io/ipd/index.html","id":"id_02-classic-regression-using-only-the-labeled-data","dir":"","previous_headings":"Usage > Model Fitting","what":"0.2 â€˜Classicâ€™ Regression Using only the Labeled Data","title":"Inference on Predicted Data","text":"can fit various IPD methods data obtain summaries using provided wrapper function, ipd():","code":"#--- Fit the Classic Regression  lm(Y ~ X1, data = dat[dat$set_label == \"labeled\", ]) |>      summary() #>  #> Call: #> lm(formula = Y ~ X1, data = dat[dat$set_label == \"labeled\", ]) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -15.262  -2.828  -0.094   2.821  11.685  #>  #> Coefficients: #>             Estimate Std. Error t value Pr(>|t|)     #> (Intercept)    0.908      0.187    4.86  1.6e-06 *** #> X1             1.097      0.192    5.71  1.9e-08 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 4.2 on 498 degrees of freedom #> Multiple R-squared:  0.0614, Adjusted R-squared:  0.0596  #> F-statistic: 32.6 on 1 and 498 DF,  p-value: 1.95e-08"},{"path":"https://ipd-tools.github.io/ipd/index.html","id":"id_1-chen-and-chen-correction-gronsbell-et-al-2025","dir":"","previous_headings":"Usage > Model Fitting","what":"1. Chen and Chen Correction (Gronsbell et al., 2025)","title":"Inference on Predicted Data","text":"","code":"#-- Specify the Formula  formula <- Y - f ~ X1  #-- Fit the Chen and Chen Correction  ipd::ipd(formula, method = \"chen\", model = \"ols\",       data = dat, label = \"set_label\") |>      summary() #>  #> Call: #>   Y - f ~ X1  #>  #> Method:    chen  #> Model:     ols  #> Intercept: Yes  #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)    0.880      0.182    4.83  1.3e-06 *** #> X1             1.114      0.186    5.98  2.2e-09 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://ipd-tools.github.io/ipd/index.html","id":"id_21-postpi-bootstrap-correction-wang-et-al-2020","dir":"","previous_headings":"Usage > Model Fitting","what":"2.1 PostPI Bootstrap Correction (Wang et al., 2020)","title":"Inference on Predicted Data","text":"","code":"#-- Fit the PostPI Bootstrap Correction  nboot <- 200  ipd::ipd(formula, method = \"postpi_boot\", model = \"ols\",       data = dat, label = \"set_label\", nboot = nboot) |>      summary() #>  #> Call: #>   Y - f ~ X1  #>  #> Method:    postpi_boot  #> Model:     ols  #> Intercept: Yes  #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)    0.866      0.183    4.73  2.2e-06 *** #> X1             1.164      0.183    6.38  1.8e-10 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://ipd-tools.github.io/ipd/index.html","id":"id_22-postpi-analytic-correction-wang-et-al-2020","dir":"","previous_headings":"Usage > Model Fitting","what":"2.2 PostPI Analytic Correction (Wang et al., 2020)","title":"Inference on Predicted Data","text":"","code":"#-- Fit the PostPI Analytic Correction  ipd::ipd(formula, method = \"postpi_analytic\", model = \"ols\",       data = dat, label = \"set_label\") |>      summary() #>  #> Call: #>   Y - f ~ X1  #>  #> Method:    postpi_analytic  #> Model:     ols  #> Intercept: Yes  #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)   -0.187      0.187   -1.00     0.32     #> X1             1.128      0.191    5.92  3.3e-09 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://ipd-tools.github.io/ipd/index.html","id":"id_3-prediction-powered-inference-ppi-angelopoulos-et-al-2023","dir":"","previous_headings":"Usage > Model Fitting","what":"3. Prediction-Powered Inference (PPI; Angelopoulos et al., 2023)","title":"Inference on Predicted Data","text":"","code":"#-- Fit the PPI Correction  ipd::ipd(formula, method = \"ppi\", model = \"ols\",       data = dat, label = \"set_label\") |>      summary() #>  #> Call: #>   Y - f ~ X1  #>  #> Method:    ppi  #> Model:     ols  #> Intercept: Yes  #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)    0.890      0.183    4.87  1.1e-06 *** #> X1             1.110      0.195    5.69  1.3e-08 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://ipd-tools.github.io/ipd/index.html","id":"id_4-ppi-all-gronsbell-et-al-2025","dir":"","previous_headings":"Usage > Model Fitting","what":"4. PPI â€œAllâ€ (Gronsbell et al., 2025)","title":"Inference on Predicted Data","text":"","code":"#-- Fit the PPI Correction  ipd::ipd(formula, method = \"ppi_a\", model = \"ols\",       data = dat, label = \"set_label\") |>      summary() #>  #> Call: #>   Y - f ~ X1  #>  #> Method:    ppi_a  #> Model:     ols  #> Intercept: Yes  #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)    0.896      0.183    4.91  9.2e-07 *** #> X1             1.106      0.195    5.67  1.4e-08 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://ipd-tools.github.io/ipd/index.html","id":"id_5-ppi-angelopoulos-et-al-2023","dir":"","previous_headings":"Usage > Model Fitting","what":"5. PPI++ (Angelopoulos et al., 2023)","title":"Inference on Predicted Data","text":"","code":"#-- Fit the PPI++ Correction  ipd::ipd(formula, method = \"ppi_plusplus\", model = \"ols\",       data = dat, label = \"set_label\") |>      summary() #>  #> Call: #>   Y - f ~ X1  #>  #> Method:    ppi_plusplus  #> Model:     ols  #> Intercept: Yes  #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)    0.904      0.185    4.87  1.1e-06 *** #> X1             1.100      0.190    5.78  7.5e-09 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://ipd-tools.github.io/ipd/index.html","id":"id_6-post-prediction-adaptive-inference-pspa-miao-et-al-2023","dir":"","previous_headings":"Usage > Model Fitting","what":"6. Post-Prediction Adaptive Inference (PSPA; Miao et al., 2023)","title":"Inference on Predicted Data","text":"","code":"#-- Fit the PSPA Correction  ipd::ipd(formula, method = \"pspa\", model = \"ols\",       data = dat, label = \"set_label\") |>      summary() #>  #> Call: #>   Y - f ~ X1  #>  #> Method:    pspa  #> Model:     ols  #> Intercept: Yes  #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)    0.900      0.185    4.87  1.1e-06 *** #> X1             1.095      0.190    5.76  8.5e-09 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"https://ipd-tools.github.io/ipd/index.html","id":"printing-and-tidying","dir":"","previous_headings":"Usage","what":"Printing and Tidying","title":"Inference on Predicted Data","text":"package also provides custom print, summary, tidy, glance, augment methods facilitate easy model inspection:","code":"#-- Fit the PostPI Bootstrap Correction  nboot <- 200  fit_postpi <- ipd::ipd(formula, method = \"postpi_boot\", model = \"ols\",                              data = dat, label = \"set_label\", nboot = nboot)  #-- Print the Model  print(fit_postpi) #> IPD inference summary #>   Method:   postpi_boot  #>   Model:    ols  #>   Formula:  Y - f ~ X1  #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)    0.860      0.183    4.71  2.5e-06 *** #> X1             1.148      0.182    6.30  3.1e-10 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  #-- Summarize the Model  summ_fit_postpi <- summary(fit_postpi)  #-- Print the Model Summary  print(summ_fit_postpi) #>  #> Call: #>   Y - f ~ X1  #>  #> Method:    postpi_boot  #> Model:     ols  #> Intercept: Yes  #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)    0.860      0.183    4.71  2.5e-06 *** #> X1             1.148      0.182    6.30  3.1e-10 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  #-- Tidy the Model Output  tidy(fit_postpi) #> # A tibble: 2 Ã— 5 #>   term        estimate std.error conf.low conf.high #>   <chr>          <dbl>     <dbl>    <dbl>     <dbl> #> 1 (Intercept)    0.860     0.183    0.502      1.22 #> 2 X1             1.15      0.182    0.790      1.50  #-- Get a One-Row Summary of the Model  glance(fit_postpi) #> # A tibble: 1 Ã— 6 #>   method      model intercept nobs_labeled nobs_unlabeled call       #>   <chr>       <chr> <lgl>            <int>          <int> <chr>      #> 1 postpi_boot ols   TRUE               500           1000 Y - f ~ X1  #-- Augment the Original Data with Fitted Values and Residuals  augmented_df <- augment(fit_postpi)  head(augmented_df) #>          X1     X2    X3    X4    Y      f set_label .fitted .resid #> 10501  0.99 -3.280 -0.39  0.97  8.4  0.124 unlabeled   1.992    6.5 #> 10502 -0.66  0.142 -1.36 -0.22 -7.2 -1.040 unlabeled   0.099   -7.3 #> 10503  0.58 -1.368 -1.73  0.15  5.6 -0.653 unlabeled   1.522    4.1 #> 10504 -0.14 -0.728  0.26 -0.23 -4.2 -0.047 unlabeled   0.702   -4.9 #> 10505 -0.17 -0.068 -1.10  0.58  2.2 -0.693 unlabeled   0.667    1.5 #> 10506  0.58  0.514 -0.69  0.97 -1.2 -0.122 unlabeled   1.521   -2.7"},{"path":"https://ipd-tools.github.io/ipd/index.html","id":"vignette","dir":"","previous_headings":"","what":"Vignette","title":"Inference on Predicted Data","text":"additional details, provide use cases examples package vignette:","code":"vignette(\"ipd\")"},{"path":"https://ipd-tools.github.io/ipd/index.html","id":"feedback","dir":"","previous_headings":"","what":"Feedback","title":"Inference on Predicted Data","text":"questions, comments, feedback, please contact developers (ssalerno@fredhutch.org).","code":""},{"path":"https://ipd-tools.github.io/ipd/index.html","id":"contributing","dir":"","previous_headings":"","what":"Contributing","title":"Inference on Predicted Data","text":"Contributions welcome! Please open issue submit pull request GitHub. following method/model combinations currently implemented:","code":""},{"path":"https://ipd-tools.github.io/ipd/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Inference on Predicted Data","text":"package licensed MIT License.","code":""},{"path":"https://ipd-tools.github.io/ipd/index.html","id":"session-info","dir":"","previous_headings":"","what":"Session Info","title":"Inference on Predicted Data","text":"","code":"sessionInfo() #> R version 4.4.1 (2024-06-14 ucrt) #> Platform: x86_64-w64-mingw32/x64 #> Running under: Windows 11 x64 (build 22631) #>  #> Matrix products: default #>  #>  #> locale: #> [1] LC_COLLATE=English_United States.utf8  #> [2] LC_CTYPE=English_United States.utf8    #> [3] LC_MONETARY=English_United States.utf8 #> [4] LC_NUMERIC=C                           #> [5] LC_TIME=English_United States.utf8     #>  #> time zone: America/New_York #> tzcode source: internal #>  #> attached base packages: #> [1] stats     graphics  grDevices utils     datasets  methods   base      #>  #> other attached packages: #>  [1] patchwork_1.3.0 lubridate_1.9.4 forcats_1.0.0   stringr_1.5.1   #>  [5] dplyr_1.1.4     purrr_1.0.2     readr_2.1.5     tidyr_1.3.1     #>  [9] tibble_3.2.1    ggplot2_3.5.2   tidyverse_2.0.0 ipd_0.99.0      #>  #> loaded via a namespace (and not attached): #>  [1] gtable_0.3.6         xfun_0.52            recipes_1.2.1        #>  [4] lattice_0.22-6       tzdb_0.5.0           vctrs_0.6.5          #>  [7] tools_4.4.1          generics_0.1.3       stats4_4.4.1         #> [10] parallel_4.4.1       pkgconfig_2.0.3      ModelMetrics_1.2.2.2 #> [13] Matrix_1.7-0         data.table_1.17.0    lifecycle_1.0.4      #> [16] farver_2.1.2         compiler_4.4.1       munsell_0.5.1        #> [19] codetools_0.2-20     htmltools_0.5.8.1    class_7.3-22         #> [22] yaml_2.3.10          prodlim_2024.06.25   pillar_1.10.2        #> [25] MASS_7.3-60.2        gower_1.0.2          iterators_1.0.14     #> [28] rpart_4.1.23         foreach_1.5.2        nlme_3.1-164         #> [31] parallelly_1.43.0    lava_1.8.1           tidyselect_1.2.1     #> [34] digest_0.6.37        stringi_1.8.7        future_1.40.0        #> [37] reshape2_1.4.4       listenv_0.9.1        labeling_0.4.3       #> [40] splines_4.4.1        fastmap_1.2.0        grid_4.4.1           #> [43] colorspace_2.1-1     cli_3.6.3            magrittr_2.0.3       #> [46] utf8_1.2.4           randomForest_4.7-1.2 survival_3.8-3       #> [49] future.apply_1.11.3  withr_3.0.2          scales_1.3.0         #> [52] timechange_0.3.0     rmarkdown_2.29       globals_0.16.3       #> [55] nnet_7.3-19          timeDate_4041.110    ranger_0.17.0        #> [58] hms_1.1.3            gam_1.22-5           evaluate_1.0.3       #> [61] knitr_1.50           hardhat_1.4.1        caret_7.0-1          #> [64] mgcv_1.9-1           rlang_1.1.4          Rcpp_1.0.13-1        #> [67] glue_1.8.0           BiocGenerics_0.50.0  pROC_1.18.5          #> [70] ipred_0.9-15         rstudioapi_0.17.1    R6_2.6.1             #> [73] plyr_1.8.9"},{"path":"https://ipd-tools.github.io/ipd/reference/A.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculation of the matrix A based on single dataset â€” A","title":"Calculation of the matrix A based on single dataset â€” A","text":"function calculation matrix based single dataset","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/A.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculation of the matrix A based on single dataset â€” A","text":"","code":"A(   X,   Y,   quant = NA,   theta,   method = c(\"ols\", \"quantile\", \"mean\", \"logistic\", \"poisson\") )"},{"path":"https://ipd-tools.github.io/ipd/reference/A.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculation of the matrix A based on single dataset â€” A","text":"X Array data.frame containing covariates Y Array data.frame outcomes quant quantile quantile estimation theta parameter theta method indicates method used M-estimation. Options include \"mean\", \"quantile\", \"ols\", \"logistic\", \"poisson\".","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/A.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculation of the matrix A based on single dataset â€” A","text":"matrix based single dataset","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/Sigma_cal.html","id":null,"dir":"Reference","previous_headings":"","what":"Variance-covariance matrix of the estimation equation â€” Sigma_cal","title":"Variance-covariance matrix of the estimation equation â€” Sigma_cal","text":"Sigma_cal function variance-covariance matrix estimation equation","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/Sigma_cal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Variance-covariance matrix of the estimation equation â€” Sigma_cal","text":"","code":"Sigma_cal(   X_l,   X_u,   Y_l,   f_l,   f_u,   w,   theta,   quant = NA,   method = c(\"ols\", \"quantile\", \"mean\", \"logistic\", \"poisson\") )"},{"path":"https://ipd-tools.github.io/ipd/reference/Sigma_cal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Variance-covariance matrix of the estimation equation â€” Sigma_cal","text":"X_l Array data.frame containing observed covariates labeled data. X_u Array data.frame containing observed predicted covariates unlabeled data. Y_l Array data.frame observed outcomes labeled data. f_l Array data.frame predicted outcomes labeled data. f_u Array data.frame predicted outcomes unlabeled data. w weights vector PSPA linear regression (d-dimensional, d equals number covariates). theta parameter theta quant quantile quantile estimation method indicates method used M-estimation. Options include \"mean\", \"quantile\", \"ols\", \"logistic\", \"poisson\".","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/Sigma_cal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Variance-covariance matrix of the estimation equation â€” Sigma_cal","text":"variance-covariance matrix estimation equation","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/augment.ipd.html","id":null,"dir":"Reference","previous_headings":"","what":"Augment data from an ipd fit â€” augment.ipd","title":"Augment data from an ipd fit â€” augment.ipd","text":"Augment data ipd fit","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/augment.ipd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Augment data from an ipd fit â€” augment.ipd","text":"","code":"# S3 method for class 'ipd' augment(x, data = x@data_u, ...)"},{"path":"https://ipd-tools.github.io/ipd/reference/augment.ipd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Augment data from an ipd fit â€” augment.ipd","text":"x object class ipd. data data.frame augment; defaults x@data_u. ... Ignored.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/augment.ipd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Augment data from an ipd fit â€” augment.ipd","text":"data.frame columns .fitted .resid.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/augment.ipd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Augment data from an ipd fit â€” augment.ipd","text":"","code":"dat <- simdat()  fit <- ipd(Y - f ~ X1, method = \"pspa\", model = \"ols\",      data = dat, label = \"set_label\")  augmented_df <- augment(fit)  head(augmented_df) #>             X1         X2         X3          X4          Y          f #> 601  0.2360958 -0.5785249  1.1436235  0.04909540 -1.1141895  2.0340122 #> 602  0.6289534 -0.1691090 -1.3817136 -0.03280005 -1.8322586  0.2564554 #> 603  0.4179257 -1.9192325 -0.8440696 -0.51092478  2.9149733  0.7119315 #> 604  1.9767585 -1.5342664 -1.8365835  0.35643054  1.0645962  1.2354387 #> 605 -0.5062863 -1.1147612  1.0441708  0.41794614  3.3228702  1.3354883 #> 606 -1.1099689  1.5978116  0.2152101  0.57920526  0.6491361 -0.1933974 #>     set_label    .fitted    .resid #> 601 unlabeled  0.9681065 -2.082296 #> 602 unlabeled  1.3734770 -3.205736 #> 603 unlabeled  1.1557278  1.759246 #> 604 unlabeled  2.7642111 -1.699615 #> 605 unlabeled  0.2020786  3.120792 #> 606 unlabeled -0.4208319  1.069968"},{"path":"https://ipd-tools.github.io/ipd/reference/calc_lhat_glm.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate PPI++ Power Tuning Parameter â€” calc_lhat_glm","title":"Estimate PPI++ Power Tuning Parameter â€” calc_lhat_glm","text":"Calculates optimal value lhat prediction-powered confidence interval GLMs.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/calc_lhat_glm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate PPI++ Power Tuning Parameter â€” calc_lhat_glm","text":"","code":"calc_lhat_glm(   grads,   grads_hat,   grads_hat_unlabeled,   inv_hessian,   coord = NULL,   clip = FALSE )"},{"path":"https://ipd-tools.github.io/ipd/reference/calc_lhat_glm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate PPI++ Power Tuning Parameter â€” calc_lhat_glm","text":"grads (matrix): n x p matrix gradient loss function respect parameter evaluated labeled data. grads_hat (matrix): n x p matrix gradient loss function respect model parameter evaluated using predictions labeled data. grads_hat_unlabeled (matrix): N x p matrix gradient loss function respect parameter evaluated using predictions unlabeled data. inv_hessian (matrix): p x p matrix inverse Hessian loss function respect parameter. coord (int, optional): Coordinate optimize lhat. None, optimizes total variance coordinates. Must (1, ..., d) d shape estimand. clip (boolean, optional): Whether clip value lhat non-negative. Defaults False.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/calc_lhat_glm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate PPI++ Power Tuning Parameter â€” calc_lhat_glm","text":"(float): Optimal value lhat [0,1].","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/chen_ols.html","id":null,"dir":"Reference","previous_headings":"","what":"Chen & Chen OLS â€” chen_ols","title":"Chen & Chen OLS â€” chen_ols","text":"Helper function Chen & Chen OLS estimation","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/chen_ols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Chen & Chen OLS â€” chen_ols","text":"","code":"chen_ols(X_l, Y_l, f_l, X_u, f_u, intercept = TRUE)"},{"path":"https://ipd-tools.github.io/ipd/reference/chen_ols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Chen & Chen OLS â€” chen_ols","text":"X_l (matrix): n x p matrix covariates labeled data. Y_l (vector): n-vector labeled outcomes. f_l (vector): n-vector predictions labeled data. X_u (matrix): N x p matrix covariates unlabeled data. f_u (vector): N-vector predictions unlabeled data. intercept (Logical): design matrices include intercept columns? Default TRUE.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/chen_ols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Chen & Chen OLS â€” chen_ols","text":"(list): list containing following: est (vector): vector Chen & Chen OLS regression coefficient estimates. se (vector): vector standard errors coefficients.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/chen_ols.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Chen & Chen OLS â€” chen_ols","text":"Another look inference prediction (Gronsbell et al., 2025) https://arxiv.org/pdf/2411.19908","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/chen_ols.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Chen & Chen OLS â€” chen_ols","text":"","code":"dat <- simdat(model = \"ols\")  form <- Y - f ~ X1  X_l <- model.matrix(form, data = dat[dat$set_label == \"labeled\", ])  Y_l <- dat[dat$set_label == \"labeled\", all.vars(form)[1]] |>   matrix(ncol = 1)  f_l <- dat[dat$set_label == \"labeled\", all.vars(form)[2]] |>   matrix(ncol = 1)  X_u <- model.matrix(form, data = dat[dat$set_label == \"unlabeled\", ])  f_u <- dat[dat$set_label == \"unlabeled\", all.vars(form)[2]] |>   matrix(ncol = 1)  chen_ols(X_l, Y_l, f_l, X_u, f_u, intercept = TRUE) #> $est #>                  [,1] #> (Intercept) 0.6776193 #> X1          1.0552229 #>  #> $se #> (Intercept)          X1  #>  0.09224289  0.09029692  #>"},{"path":"https://ipd-tools.github.io/ipd/reference/compute_cdf.html","id":null,"dir":"Reference","previous_headings":"","what":"Empirical CDF of the Data â€” compute_cdf","title":"Empirical CDF of the Data â€” compute_cdf","text":"Computes empirical CDF data.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/compute_cdf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Empirical CDF of the Data â€” compute_cdf","text":"","code":"compute_cdf(Y, grid, w = NULL)"},{"path":"https://ipd-tools.github.io/ipd/reference/compute_cdf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Empirical CDF of the Data â€” compute_cdf","text":"Y (matrix): n x 1 matrix observed data. grid (matrix): Grid values compute CDF . w (vector, optional): n-vector sample weights.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/compute_cdf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Empirical CDF of the Data â€” compute_cdf","text":"(list): Empirical CDF standard deviation specified grid points.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/compute_cdf_diff.html","id":null,"dir":"Reference","previous_headings":"","what":"Empirical CDF Difference â€” compute_cdf_diff","title":"Empirical CDF Difference â€” compute_cdf_diff","text":"Computes difference empirical CDFs data predictions.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/compute_cdf_diff.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Empirical CDF Difference â€” compute_cdf_diff","text":"","code":"compute_cdf_diff(Y, f, grid, w = NULL)"},{"path":"https://ipd-tools.github.io/ipd/reference/compute_cdf_diff.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Empirical CDF Difference â€” compute_cdf_diff","text":"Y (matrix): n x 1 matrix observed data. f (matrix): n x 1 matrix predictions. grid (matrix): Grid values compute CDF . w (vector, optional): n-vector sample weights.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/compute_cdf_diff.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Empirical CDF Difference â€” compute_cdf_diff","text":"(list): Difference empirical CDFs data predictions standard deviation specified grid points.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/dot-build_design.html","id":null,"dir":"Reference","previous_headings":"","what":"Build design matrices and outcome vectors â€” .build_design","title":"Build design matrices and outcome vectors â€” .build_design","text":"Build design matrices outcome vectors","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/dot-build_design.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build design matrices and outcome vectors â€” .build_design","text":"","code":".build_design(formula, data_l, data_u, intercept = TRUE, na_action = \"na.fail\")"},{"path":"https://ipd-tools.github.io/ipd/reference/dot-build_design.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build design matrices and outcome vectors â€” .build_design","text":"formula two-sided formula Y - f ~ X... data_l labeled data.frame data_u unlabeled data.frame intercept include intercept? na_action \"na.fail\" \"na.omit\"","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/dot-build_design.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build design matrices and outcome vectors â€” .build_design","text":"list(X_l, Y_l, f_l, X_u, f_u)","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/dot-drop_unused_levels.html","id":null,"dir":"Reference","previous_headings":"","what":"Drop unused factor levels and report which were removed â€” .drop_unused_levels","title":"Drop unused factor levels and report which were removed â€” .drop_unused_levels","text":"Drop unused factor levels report removed","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/dot-drop_unused_levels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Drop unused factor levels and report which were removed â€” .drop_unused_levels","text":"","code":".drop_unused_levels(data, factor_vars)"},{"path":"https://ipd-tools.github.io/ipd/reference/dot-drop_unused_levels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Drop unused factor levels and report which were removed â€” .drop_unused_levels","text":"data data.frame factor_vars character vector factor column names","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/dot-drop_unused_levels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Drop unused factor levels and report which were removed â€” .drop_unused_levels","text":"data.frame unused levels dropped","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/dot-parse_inputs.html","id":null,"dir":"Reference","previous_headings":"","what":"Validate and split input data â€” .parse_inputs","title":"Validate and split input data â€” .parse_inputs","text":"Validate split input data","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/dot-parse_inputs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Validate and split input data â€” .parse_inputs","text":"","code":".parse_inputs(data, label = NULL, unlabeled_data = NULL, na_action = \"na.fail\")"},{"path":"https://ipd-tools.github.io/ipd/reference/dot-parse_inputs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Validate and split input data â€” .parse_inputs","text":"data data.frame coercible object label optional column flagging labeled vs. unlabeled rows unlabeled_data optional data.frame unlabeled observations na_action handle missing data: \"na.fail\" \"na.omit\"","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/dot-parse_inputs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Validate and split input data â€” .parse_inputs","text":"list components data_l data_u (data.frames)","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/dot-warn_differing_levels.html","id":null,"dir":"Reference","previous_headings":"","what":"Warn on differing factor levels between labeled and unlabeled data â€” .warn_differing_levels","title":"Warn on differing factor levels between labeled and unlabeled data â€” .warn_differing_levels","text":"Warn differing factor levels labeled unlabeled data","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/dot-warn_differing_levels.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Warn on differing factor levels between labeled and unlabeled data â€” .warn_differing_levels","text":"","code":".warn_differing_levels(data_l, data_u, factor_vars)"},{"path":"https://ipd-tools.github.io/ipd/reference/dot-warn_differing_levels.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Warn on differing factor levels between labeled and unlabeled data â€” .warn_differing_levels","text":"data_l labeled data.frame data_u unlabeled data.frame factor_vars character vector factor column names","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/dot-warn_differing_levels.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Warn on differing factor levels between labeled and unlabeled data â€” .warn_differing_levels","text":"Invisibly returns NULL.  Messages printed variable whose levels differ.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/est_ini.html","id":null,"dir":"Reference","previous_headings":"","what":"Initial estimation â€” est_ini","title":"Initial estimation â€” est_ini","text":"est_ini function initial estimation","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/est_ini.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initial estimation â€” est_ini","text":"","code":"est_ini(   X,   Y,   quant = NA,   method = c(\"ols\", \"quantile\", \"mean\", \"logistic\", \"poisson\") )"},{"path":"https://ipd-tools.github.io/ipd/reference/est_ini.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initial estimation â€” est_ini","text":"X Array data.frame containing covariates Y Array data.frame outcomes quant quantile quantile estimation method indicates method used M-estimation. Options include \"mean\", \"quantile\", \"ols\", \"logistic\", \"poisson\".","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/est_ini.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initial estimation â€” est_ini","text":"initial estimator","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/glance.ipd.html","id":null,"dir":"Reference","previous_headings":"","what":"Glance at an ipd fit â€” glance.ipd","title":"Glance at an ipd fit â€” glance.ipd","text":"Glance ipd fit","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/glance.ipd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Glance at an ipd fit â€” glance.ipd","text":"","code":"# S3 method for class 'ipd' glance(x, ...)"},{"path":"https://ipd-tools.github.io/ipd/reference/glance.ipd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Glance at an ipd fit â€” glance.ipd","text":"x object class ipd. ... Ignored.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/glance.ipd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Glance at an ipd fit â€” glance.ipd","text":"one-row tibble summarizing fit.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/glance.ipd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Glance at an ipd fit â€” glance.ipd","text":"","code":"dat <- simdat()  fit <- ipd(Y - f ~ X1, method = \"pspa\", model = \"ols\",      data = dat, label = \"set_label\")  glance(fit) #> # A tibble: 1 Ã— 6 #>   method model intercept nobs_labeled nobs_unlabeled call       #>   <chr>  <chr> <lgl>            <int>          <int> <chr>      #> 1 pspa   ols   TRUE               300            300 Y - f ~ X1"},{"path":"https://ipd-tools.github.io/ipd/reference/ipd-class.html","id":null,"dir":"Reference","previous_headings":"","what":"ipd: S4 class for inference on predicted data results â€” ipd-class","title":"ipd: S4 class for inference on predicted data results â€” ipd-class","text":"ipd: S4 class inference predicted data results","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ipd-class.html","id":"slots","dir":"Reference","previous_headings":"","what":"Slots","title":"ipd: S4 class for inference on predicted data results â€” ipd-class","text":"coefficients Numeric vector parameter estimates. se Numeric vector standard errors. ci Numeric matrix confidence intervals. coefTable Data frame summarizing Estimate, Std. Error, z value, Pr(>|z|). fit raw list returned helper function. formula formula used (class \"formula\"). data_l labeled data (data.frame). data_u unlabeled data (data.frame). method Character; IPD method used. model Character; downstream model fitted. intercept Logical; intercept included?","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ipd-package.html","id":null,"dir":"Reference","previous_headings":"","what":"ipd: Inference on Predicted Data â€” ipd-package","title":"ipd: Inference on Predicted Data â€” ipd-package","text":"Performs valid statistical inference predicted data (IPD) using recent methods, subset data, outcomes predicted algorithm. Provides wrapper function specified defaults type model method used estimation inference. provides methods tidying summarizing results. Salerno et al., (2025) doi:10.1093/bioinformatics/btaf055 . ipd package provides tools statistical modeling inference significant portion outcome data predicted AI/ML algorithms. implements several state---art methods inference predicted data (IPD), offering user-friendly interface facilitate use real-world applications.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ipd-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"ipd: Inference on Predicted Data â€” ipd-package","text":"package particularly useful scenarios predicted values (e.g., machine learning models) used proxies unobserved outcomes, can introduce biases estimation inference. ipd package integrates methods designed address challenges.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ipd-package.html","id":"features","dir":"Reference","previous_headings":"","what":"Features","title":"ipd: Inference on Predicted Data â€” ipd-package","text":"Multiple IPD methods: PostPI, PPI, PPI++, PSPA currently. Flexible wrapper functions ease use. Custom methods model inspection evaluation. Seamless integration common data structures R. Comprehensive documentation examples.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ipd-package.html","id":"key-functions","dir":"Reference","previous_headings":"","what":"Key Functions","title":"ipd: Inference on Predicted Data â€” ipd-package","text":"ipd: Main wrapper function implements various methods inference predicted data specified model/outcome type (e.g., mean estimation, linear regression). simdat: Simulates data demonstrating use various IPD methods. print.ipd: Prints brief summary IPD method/model combination. summary.ipd: Summarizes results fitted IPD models. tidy.ipd: Tidies IPD method/model fit data frame. glance.ipd: Glances IPD method/model fit, returning one-row summary. augment.ipd: Augments data used IPD method/model fit additional information observation.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ipd-package.html","id":"documentation","dir":"Reference","previous_headings":"","what":"Documentation","title":"ipd: Inference on Predicted Data â€” ipd-package","text":"package includes detailed documentation function, including usage examples. vignette also provided guide users common workflows applications package.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ipd-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"ipd: Inference on Predicted Data â€” ipd-package","text":"details statistical methods implemented package, please refer associated manuscripts following references: PostPI: Wang, S., McCormick, T. H., & Leek, J. T. (2020). Methods correcting inference based outcomes predicted machine learning. Proceedings National Academy Sciences, 117(48), 30266-30275. PPI: Angelopoulos, . N., Bates, S., Fannjiang, C., Jordan, M. ., & Zrnic, T. (2023). Prediction-powered inference. Science, 382(6671), 669-674. PPI++: Angelopoulos, . N., Duchi, J. C., & Zrnic, T. (2023). PPI++: Efficient prediction-powered inference. arXiv preprint arXiv:2311.01453. PSPA: Miao, J., Miao, X., Wu, Y., Zhao, J., & Lu, Q. (2023). Assumption-lean data-adaptive post-prediction inference. arXiv preprint arXiv:2311.14220.","code":""},{"path":[]},{"path":"https://ipd-tools.github.io/ipd/reference/ipd-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"ipd: Inference on Predicted Data â€” ipd-package","text":"Maintainer: Stephen Salerno ssalerno@fredhutch.org (ORCID) [copyright holder] Authors: Jiacheng Miao jmiao24@wisc.edu Awan Afiaz aafiaz@uw.edu Kentaro Hoffman khoffm3@uw.edu Jesse Gronsbell j.gronsbell@utoronto.ca Jianhui Gao jianhui.gao@mail.utoronto.ca David Cheng dcheng@mgh.harvard.edu Anna Neufeld acn2@williams.edu Qiongshi Lu qlu@biostat.wisc.edu Tyler H McCormick tylermc@uw.edu Jeffrey T Leek jtleek@fredhutch.org","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ipd-package.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ipd: Inference on Predicted Data â€” ipd-package","text":"","code":"#-- Generate Example Data  set.seed(12345)  dat <- simdat(n = c(300, 300, 300), effect = 1, sigma_Y = 1)  head(dat) #>           X1          X2         X3          X4         Y  f set_label #> 1  0.5855288 -0.78486098  1.1872102  1.05076285 1.4008570 NA  training #> 2  0.7094660 -2.56005244 -0.3567140 -0.07179733 4.1079201 NA  training #> 3 -0.1093033  0.07280078  1.2122385  0.11673662 1.4501726 NA  training #> 4 -0.4534972  0.75024358 -0.6939527  0.97786651 1.2987926 NA  training #> 5  0.6058875 -0.12824888  1.3560616 -1.03154201 2.5256490 NA  training #> 6 -1.8179560 -0.48786673  0.9057313  2.19912933 0.2889297 NA  training  formula <- Y - f ~ X1  #-- PostPI Analytic Correction (Wang et al., 2020)  fit_postpi1 <- ipd(formula,   method = \"postpi_analytic\", model = \"ols\",   data = dat, label = \"set_label\" )  #-- PostPI Bootstrap Correction (Wang et al., 2020)  nboot <- 200  fit_postpi2 <- ipd(formula,   method = \"postpi_boot\", model = \"ols\",   data = dat, label = \"set_label\", nboot = nboot )  #-- PPI (Angelopoulos et al., 2023)  fit_ppi <- ipd(formula,   method = \"ppi\", model = \"ols\",   data = dat, label = \"set_label\" )  #-- PPI++ (Angelopoulos et al., 2023)  fit_plusplus <- ipd(formula,   method = \"ppi_plusplus\", model = \"ols\",   data = dat, label = \"set_label\" )  #-- PSPA (Miao et al., 2023)  fit_pspa <- ipd(formula,   method = \"pspa\", model = \"ols\",   data = dat, label = \"set_label\" )  #-- Print the Model  print(fit_postpi1) #> IPD inference summary #>   Method:   postpi_analytic  #>   Model:    ols  #>   Formula:  Y - f ~ X1  #>  #> Coefficients: #>             Estimate Std. Error z value  Pr(>|z|)     #> (Intercept)  0.62451    0.10803  5.7811 7.420e-09 *** #> X1           0.79449    0.12965  6.1279 8.904e-10 *** #> --- #> Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1  #-- Summarize the Model  summ_fit_postpi1 <- summary(fit_postpi1)  #-- Print the Model Summary  print(summ_fit_postpi1) #>  #> Call: #>   Y - f ~ X1  #>  #> Method:    postpi_analytic  #> Model:     ols  #> Intercept: Yes  #>  #> Coefficients: #>             Estimate Std. Error z value  Pr(>|z|)     #> (Intercept)  0.62451    0.10803  5.7811 7.420e-09 *** #> X1           0.79449    0.12965  6.1279 8.904e-10 *** #> --- #> Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1  #-- Tidy the Model Output  tidy(fit_postpi1) #> # A tibble: 2 Ã— 5 #>   term        estimate std.error conf.low conf.high #>   <chr>          <dbl>     <dbl>    <dbl>     <dbl> #> 1 (Intercept)    0.625     0.108    0.413     0.836 #> 2 X1             0.794     0.130    0.540     1.05   #-- Get a One-Row Summary of the Model  glance(fit_postpi1) #> # A tibble: 1 Ã— 6 #>   method          model intercept nobs_labeled nobs_unlabeled call       #>   <chr>           <chr> <lgl>            <int>          <int> <chr>      #> 1 postpi_analytic ols   TRUE               300            300 Y - f ~ X1  #-- Augment the Original Data with Fitted Values and Residuals  augmented_df <- augment(fit_postpi1)  head(augmented_df) #>             X1         X2          X3         X4          Y           f #> 601 -1.6366291 -0.1746226 -0.18264862 -0.1995761 -1.1215870 -1.27598909 #> 602  0.2115626 -0.6706167 -1.39196798  0.7013954 -0.3900187 -0.27576946 #> 603 -0.4648317  0.5074258  0.70824781  0.8477244  1.2041955  0.80200786 #> 604 -0.6623572  1.2474343  0.18896582  0.2288555  0.1193828 -0.04566093 #> 605 -0.1329536 -1.2482755 -0.21736688 -0.1678426 -0.8563329  0.54360381 #> 606 -1.3217017 -1.9347187  0.07163463 -0.6305805 -0.2815313 -0.40867991 #>     set_label     .fitted      .resid #> 601 unlabeled -0.67577706 -0.44580990 #> 602 unlabeled  0.79259713 -1.18261583 #> 603 unlabeled  0.25520700  0.94898851 #> 604 unlabeled  0.09827451  0.02110826 #> 605 unlabeled  0.51888164 -1.37521458 #> 606 unlabeled -0.42556966  0.14403841"},{"path":"https://ipd-tools.github.io/ipd/reference/ipd.html","id":null,"dir":"Reference","previous_headings":"","what":"Inference on Predicted Data (ipd) â€” ipd","title":"Inference on Predicted Data (ipd) â€” ipd","text":"main wrapper function conduct ipd using various methods models, returns list fitted model components.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ipd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inference on Predicted Data (ipd) â€” ipd","text":"","code":"ipd(   formula,   method,   model,   data,   label = NULL,   unlabeled_data = NULL,   intercept = TRUE,   alpha = 0.05,   alternative = \"two-sided\",   na_action = \"na.fail\",   ... )"},{"path":"https://ipd-tools.github.io/ipd/reference/ipd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inference on Predicted Data (ipd) â€” ipd","text":"formula object class formula: symbolic description model fitted. Must form Y - f ~ X, Y name column corresponding observed outcome labeled data, f name column corresponding predicted outcome labeled unlabeled data, X corresponds features interest (.e., X = X1 + ... + Xp). See 1. Formula Details information. method IPD method used fitting model. Must one \"chen\", \"postpi_analytic\", \"postpi_boot\", \"ppi\", \"ppi_a\", \"ppi_plusplus\", \"pspa\". See 3. Method Details information. model type downstream inferential model fitted, parameter estimated. Must one \"mean\", \"quantile\", \"ols\", \"logistic\", \"poisson\". See 4. Model Details information. data data.frame containing variables model, either stacked data frame specific column identifying labeled versus unlabeled observations (label), labeled data set. Must contain columns observed outcomes (Y), predicted outcomes (f), features (X) needed specify formula. See 2. Data Details information. label string, int, logical specifying column data distinguishes labeled unlabeled observations. See Details section information. NULL, unlabeled_data must specified. See 2. Data Details information. unlabeled_data (optional) data.frame unlabeled data. NULL, label must specified. Specifying label unlabeled_data arguments result error message. specified, must contain columns predicted outcomes (f), features (X) needed specify formula. See 2. Data Details information. intercept Logical. intercept included model? Default TRUE. alpha significance level confidence intervals. Default 0.05. alternative string specifying alternative hypothesis. Must one \"two-sided\", \"less\", \"greater\". na_action (string, optional) missing covariate data handled. Currently \"na.fail\" \"na.omit\" accommodated. Defaults \"na.fail\". ... Additional arguments passed fitting function. See Details section information. See 5. Auxiliary Arguments 6. Arguments Details information.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ipd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inference on Predicted Data (ipd) â€” ipd","text":"summary model output. S4 object class IPD following slots: coefficients Named numeric vector estimated parameters. se Named numeric vector standard errors. ci matrix confidence intervals, columns lower upper. coefTable data.frame summarizing Estimate, Std. Error, z-value, Pr(>|z|) (glm-style). fit raw output list returned method-specific helper function. formula formula used fitting IPD model. data_l labeled data.frame used analysis. data_u unlabeled data.frame used analysis. method character string indicating IPD method applied. model character string indicating downstream inferential model. intercept logical indicating whether intercept included.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ipd.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Inference on Predicted Data (ipd) â€” ipd","text":"1. Formula: ipd function uses one formula argument specifies calibrating model (e.g., PostPI \"relationship model\", PPI \"rectifier\" model) inferential model. separate models created internally based specific method called. 2. Data: data can specified two ways: Single data argument (data) containing stacked data.frame label identifier (label). Two data arguments, one labeled data (data) one unlabeled data (unlabeled_data). option (1), provide one data argument (data) contains stacked data.frame unlabeled labeled data label argument specifies column identifying labeled versus unlabeled observations stacked data.frame (e.g., label = \"set_label\" column \"set_label\" stacked data denotes set observation belongs ). NOTE: Labeled data identifiers can : String \"l\", \"lab\", \"label\", \"labeled\", \"labelled\", \"tst\", \"test\", \"true\" Logical TRUE Factor Non-reference category (.e., binary 1) Unlabeled data identifiers can : String \"u\", \"unlab\", \"unlabeled\", \"unlabelled\", \"val\", \"validation\", \"false\" Logical FALSE Factor Non-reference category (.e., binary 0) option (2), provide separate data arguments labeled data set (data) unlabeled data set (unlabeled_data). second argument provided, function ignores label identifier assumes data provided stacked. NOTE: columns data unlabeled_data may used unless explicitly referenced formula argument label argument (data passed one stacked data frame). 3. Method: Use method argument specify fitting method: \"chen\" Gronsbell et al. (2025) Chen Chen Correction \"postpi_analytic\" Wang et al. (2020) Post-Prediction Inference (PostPI) Analytic Correction \"postpi_boot\" Wang et al. (2020) Post-Prediction Inference (PostPI) Bootstrap Correction \"ppi\" Angelopoulos et al. (2023) Prediction-Powered Inference (PPI) \"ppi_a\" Gronsbell et al. (2025) PPI \"\" Correction \"ppi_plusplus\" Angelopoulos et al. (2023) PPI++ \"pspa\" Miao et al. (2023) Assumption-Lean Data-Adaptive Post-Prediction Inference (PSPA) 4. Model: Use model argument specify type downstream inferential model parameter estimated: \"mean\" Mean value continuous outcome \"quantile\" qth quantile continuous outcome \"ols\" Linear regression coefficients continuous outcome \"logistic\" Logistic regression coefficients binary outcome \"poisson\" Poisson regression coefficients count outcome ipd wrapper function concatenate method model arguments identify required helper function, following naming convention \"method_model\". 5. Auxiliary Arguments: wrapper function take method-specific auxiliary arguments (e.g., q quantile estimation models) pass helper function \"...\" specified defaults simplicity. 6. Arguments: arguments relate methods (e.g., alpha, ci.type), method-specific arguments, defaults.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ipd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Inference on Predicted Data (ipd) â€” ipd","text":"","code":"#-- Generate Example Data  dat <- simdat(n = c(300, 300, 300), effect = 1, sigma_Y = 1)  head(dat) #>            X1          X2         X3         X4          Y  f set_label #> 1  0.91295168  0.82805181  0.9800060 -1.3185450  1.9821781 NA  training #> 2  0.34629713  0.95618711  1.5572516 -0.4150736  1.9104987 NA  training #> 3 -0.01794417 -0.02357563 -0.6602489  1.7181628 -0.5284219 NA  training #> 4  0.42511788 -0.20367165 -0.4274529  0.3139744  0.6832558 NA  training #> 5  0.98476232 -0.66591755 -1.4923011 -0.2940388  0.3307442 NA  training #> 6 -0.57141674 -0.34011487  0.8388489  0.7944130 -2.2485908 NA  training  formula <- Y - f ~ X1  #-- Chen and Chen Correction (Gronsbell et al., 2025)  ipd(formula,   method = \"chen\", model = \"ols\",   data = dat, label = \"set_label\" ) #> IPD inference summary #>   Method:   chen  #>   Model:    ols  #>   Formula:  Y - f ~ X1  #>  #> Coefficients: #>             Estimate Std. Error z value  Pr(>|z|)     #> (Intercept) 0.653826   0.084891   7.702  1.34e-14 *** #> X1          1.041654   0.096085  10.841 < 2.2e-16 *** #> --- #> Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1  #-- PostPI Analytic Correction (Wang et al., 2020)  ipd(formula,   method = \"postpi_analytic\", model = \"ols\",   data = dat, label = \"set_label\" ) #> IPD inference summary #>   Method:   postpi_analytic  #>   Model:    ols  #>   Formula:  Y - f ~ X1  #>  #> Coefficients: #>             Estimate Std. Error z value  Pr(>|z|)     #> (Intercept)  0.69068    0.11352  6.0843 1.170e-09 *** #> X1           1.03082    0.13585  7.5877 3.255e-14 *** #> --- #> Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1  #-- PostPI Bootstrap Correction (Wang et al., 2020)  nboot <- 200  ipd(formula,   method = \"postpi_boot\", model = \"ols\",   data = dat, label = \"set_label\", nboot = nboot ) #> IPD inference summary #>   Method:   postpi_boot  #>   Model:    ols  #>   Formula:  Y - f ~ X1  #>  #> Coefficients: #>             Estimate Std. Error z value  Pr(>|z|)     #> (Intercept) 0.635274   0.095072   6.682 2.357e-11 *** #> X1          1.024740   0.094036  10.897 < 2.2e-16 *** #> --- #> Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1  #-- PPI (Angelopoulos et al., 2023)  ipd(formula,   method = \"ppi\", model = \"ols\",   data = dat, label = \"set_label\" ) #> IPD inference summary #>   Method:   ppi  #>   Model:    ols  #>   Formula:  Y - f ~ X1  #>  #> Coefficients: #>             Estimate Std. Error z value  Pr(>|z|)     #> (Intercept) 0.636905   0.093397  6.8194 9.145e-12 *** #> X1          1.032763   0.100322 10.2945 < 2.2e-16 *** #> --- #> Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1  #-- PPI \"All\" (Gronsbell et al., 2025)  ipd(formula,   method = \"ppi_a\", model = \"ols\",   data = dat, label = \"set_label\" ) #> IPD inference summary #>   Method:   ppi_a  #>   Model:    ols  #>   Formula:  Y - f ~ X1  #>  #> Coefficients: #>             Estimate Std. Error z value  Pr(>|z|)     #> (Intercept) 0.655324   0.084638  7.7426 9.737e-15 *** #> X1          1.046635   0.093822 11.1555 < 2.2e-16 *** #> --- #> Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1  #-- PPI++ (Angelopoulos et al., 2023)  ipd(formula,   method = \"ppi_plusplus\", model = \"ols\",   data = dat, label = \"set_label\" ) #> IPD inference summary #>   Method:   ppi_plusplus  #>   Model:    ols  #>   Formula:  Y - f ~ X1  #>  #> Coefficients: #>             Estimate Std. Error z value  Pr(>|z|)     #> (Intercept) 0.652305   0.085908  7.5931 3.123e-14 *** #> X1          1.044527   0.096407 10.8346 < 2.2e-16 *** #> --- #> Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1  #-- PSPA (Miao et al., 2023)  ipd(formula,   method = \"pspa\", model = \"ols\",   data = dat, label = \"set_label\" ) #> IPD inference summary #>   Method:   pspa  #>   Model:    ols  #>   Formula:  Y - f ~ X1  #>  #> Coefficients: #>             Estimate Std. Error z value  Pr(>|z|)     #> (Intercept) 0.656443   0.085606  7.6682 1.744e-14 *** #> X1          1.039811   0.096154 10.8141 < 2.2e-16 *** #> --- #> Signif. codes:  0 â€˜***â€™ 0.001 â€˜**â€™ 0.01 â€˜*â€™ 0.05 â€˜.â€™ 0.1 â€˜ â€™ 1"},{"path":"https://ipd-tools.github.io/ipd/reference/link_Hessian.html","id":null,"dir":"Reference","previous_headings":"","what":"Hessians of the link function â€” link_Hessian","title":"Hessians of the link function â€” link_Hessian","text":"link_Hessian function Hessians link function","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/link_Hessian.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Hessians of the link function â€” link_Hessian","text":"","code":"link_Hessian(t, method = c(\"logistic\", \"poisson\"))"},{"path":"https://ipd-tools.github.io/ipd/reference/link_Hessian.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Hessians of the link function â€” link_Hessian","text":"t t method indicates method used M-estimation. Options include \"mean\", \"quantile\", \"ols\", \"logistic\", \"poisson\".","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/link_Hessian.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Hessians of the link function â€” link_Hessian","text":"Hessians link function","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/link_grad.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient of the link function â€” link_grad","title":"Gradient of the link function â€” link_grad","text":"link_grad function gradient link function","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/link_grad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient of the link function â€” link_grad","text":"","code":"link_grad(t, method = c(\"ols\", \"logistic\", \"poisson\"))"},{"path":"https://ipd-tools.github.io/ipd/reference/link_grad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient of the link function â€” link_grad","text":"t t method indicates method used M-estimation. Options include \"mean\", \"quantile\", \"ols\", \"logistic\", \"poisson\".","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/link_grad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient of the link function â€” link_grad","text":"gradient link function","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/log1pexp.html","id":null,"dir":"Reference","previous_headings":"","what":"Log1p Exponential â€” log1pexp","title":"Log1p Exponential â€” log1pexp","text":"Computes natural logarithm 1 plus exponential input, handle large inputs.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/log1pexp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log1p Exponential â€” log1pexp","text":"","code":"log1pexp(x)"},{"path":"https://ipd-tools.github.io/ipd/reference/log1pexp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log1p Exponential â€” log1pexp","text":"x (vector): numeric vector inputs.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/log1pexp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log1p Exponential â€” log1pexp","text":"(vector): numeric vector element result log(1 + exp(x)).","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/logistic_get_stats.html","id":null,"dir":"Reference","previous_headings":"","what":"Logistic Regression Gradient and Hessian â€” logistic_get_stats","title":"Logistic Regression Gradient and Hessian â€” logistic_get_stats","text":"Computes statistics needed logstic regression-based prediction-powered inference.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/logistic_get_stats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logistic Regression Gradient and Hessian â€” logistic_get_stats","text":"","code":"logistic_get_stats(   est,   X_l,   Y_l,   f_l,   X_u,   f_u,   w_l = NULL,   w_u = NULL,   use_u = TRUE )"},{"path":"https://ipd-tools.github.io/ipd/reference/logistic_get_stats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logistic Regression Gradient and Hessian â€” logistic_get_stats","text":"est (vector): Point estimates coefficients. X_l (matrix): Covariates labeled data set. Y_l (vector): Labels labeled data set. f_l (vector): Predictions labeled data set. X_u (matrix): Covariates unlabeled data set. f_u (vector): Predictions unlabeled data set. w_l (vector, optional): Sample weights labeled data set. w_u (vector, optional): Sample weights unlabeled data set. use_u (bool, optional): Whether use unlabeled data set.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/logistic_get_stats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Logistic Regression Gradient and Hessian â€” logistic_get_stats","text":"(list): list containing following: grads (matrix): n x p matrix gradient loss function respect coefficients. grads_hat (matrix): n x p matrix gradient loss function respect coefficients, evaluated using labeled predictions. grads_hat_unlabeled (matrix): N x p matrix gradient loss function respect coefficients, evaluated using unlabeled predictions. inv_hessian (matrix): p x p matrix inverse Hessian loss function respect coefficients.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/mean_psi.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample expectation of psi â€” mean_psi","title":"Sample expectation of psi â€” mean_psi","text":"mean_psi function sample expectation psi","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/mean_psi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample expectation of psi â€” mean_psi","text":"","code":"mean_psi(   X,   Y,   theta,   quant = NA,   method = c(\"ols\", \"quantile\", \"mean\", \"logistic\", \"poisson\") )"},{"path":"https://ipd-tools.github.io/ipd/reference/mean_psi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample expectation of psi â€” mean_psi","text":"X Array data.frame containing covariates Y Array data.frame outcomes theta parameter theta quant quantile quantile estimation method indicates method used M-estimation. Options include \"mean\", \"quantile\", \"ols\", \"logistic\", \"poisson\".","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/mean_psi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample expectation of psi â€” mean_psi","text":"sample expectation psi","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/mean_psi_pop.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample expectation of PSPA psi â€” mean_psi_pop","title":"Sample expectation of PSPA psi â€” mean_psi_pop","text":"mean_psi_pop function sample expectation PSPA psi","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/mean_psi_pop.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample expectation of PSPA psi â€” mean_psi_pop","text":"","code":"mean_psi_pop(   X_l,   X_u,   Y_l,   f_l,   f_u,   w,   theta,   quant = NA,   method = c(\"ols\", \"quantile\", \"mean\", \"logistic\", \"poisson\") )"},{"path":"https://ipd-tools.github.io/ipd/reference/mean_psi_pop.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample expectation of PSPA psi â€” mean_psi_pop","text":"X_l Array data.frame containing observed covariates labeled data. X_u Array data.frame containing observed predicted covariates unlabeled data. Y_l Array data.frame observed outcomes labeled data. f_l Array data.frame predicted outcomes labeled data. f_u Array data.frame predicted outcomes unlabeled data. w weights vector PSPA linear regression (d-dimensional, d equals number covariates). theta parameter theta quant quantile quantile estimation method indicates method used M-estimation. Options include \"mean\", \"quantile\", \"ols\", \"logistic\", \"poisson\".","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/mean_psi_pop.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample expectation of PSPA psi â€” mean_psi_pop","text":"sample expectation PSPA psi","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ols.html","id":null,"dir":"Reference","previous_headings":"","what":"Ordinary Least Squares â€” ols","title":"Ordinary Least Squares â€” ols","text":"Computes ordinary least squares coefficients.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Ordinary Least Squares â€” ols","text":"","code":"ols(X, Y, return_se = FALSE)"},{"path":"https://ipd-tools.github.io/ipd/reference/ols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Ordinary Least Squares â€” ols","text":"X (matrix): n x p matrix covariates. Y (vector): p-vector outcome values. return_se (bool, optional): Whether return standard errors coefficients.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Ordinary Least Squares â€” ols","text":"(list): list containing following: theta (vector): p-vector ordinary least squares estimates coefficients. se (vector): return_se == TRUE, return p-vector standard errors coefficients.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ols_get_stats.html","id":null,"dir":"Reference","previous_headings":"","what":"OLS Gradient and Hessian â€” ols_get_stats","title":"OLS Gradient and Hessian â€” ols_get_stats","text":"Computes statistics needed OLS-based prediction-powered inference.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ols_get_stats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"OLS Gradient and Hessian â€” ols_get_stats","text":"","code":"ols_get_stats(   est,   X_l,   Y_l,   f_l,   X_u,   f_u,   w_l = NULL,   w_u = NULL,   use_u = TRUE )"},{"path":"https://ipd-tools.github.io/ipd/reference/ols_get_stats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"OLS Gradient and Hessian â€” ols_get_stats","text":"est (vector): Point estimates coefficients. X_l (matrix): Covariates labeled data set. Y_l (vector): Labels labeled data set. f_l (vector): Predictions labeled data set. X_u (matrix): Covariates unlabeled data set. f_u (vector): Predictions unlabeled data set. w_l (vector, optional): Sample weights labeled data set. w_u (vector, optional): Sample weights unlabeled data set. use_u (boolean, optional): Whether use unlabeled data set.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ols_get_stats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"OLS Gradient and Hessian â€” ols_get_stats","text":"(list): list containing following: grads (matrix): n x p matrix gradient loss function respect coefficients. grads_hat (matrix): n x p matrix gradient loss function respect coefficients, evaluated using labeled predictions. grads_hat_unlabeled (matrix): N x p matrix gradient loss function respect coefficients, evaluated using unlabeled predictions. inv_hessian (matrix): p x p matrix inverse Hessian loss function respect coefficients.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/optim_est.html","id":null,"dir":"Reference","previous_headings":"","what":"One-step update for obtaining estimator â€” optim_est","title":"One-step update for obtaining estimator â€” optim_est","text":"optim_est function One-step update obtaining estimator","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/optim_est.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"One-step update for obtaining estimator â€” optim_est","text":"","code":"optim_est(   X_l,   X_u,   Y_l,   f_l,   f_u,   w,   theta,   quant = NA,   method = c(\"ols\", \"quantile\", \"mean\", \"logistic\", \"poisson\") )"},{"path":"https://ipd-tools.github.io/ipd/reference/optim_est.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"One-step update for obtaining estimator â€” optim_est","text":"X_l Array data.frame containing observed covariates labeled data. X_u Array data.frame containing observed predicted covariates unlabeled data. Y_l Array data.frame observed outcomes labeled data. f_l Array data.frame predicted outcomes labeled data. f_u Array data.frame predicted outcomes unlabeled data. w weights vector PSPA linear regression (d-dimensional, d equals number covariates). theta parameter theta quant quantile quantile estimation method indicates method used M-estimation. Options include \"mean\", \"quantile\", \"ols\", \"logistic\", \"poisson\".","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/optim_est.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"One-step update for obtaining estimator â€” optim_est","text":"estimator","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/optim_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"One-step update for obtaining the weight vector â€” optim_weights","title":"One-step update for obtaining the weight vector â€” optim_weights","text":"optim_weights function One-step update obtaining estimator","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/optim_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"One-step update for obtaining the weight vector â€” optim_weights","text":"","code":"optim_weights(   X_l,   X_u,   Y_l,   f_l,   f_u,   w,   theta,   quant = NA,   method = c(\"ols\", \"quantile\", \"mean\", \"logistic\", \"poisson\") )"},{"path":"https://ipd-tools.github.io/ipd/reference/optim_weights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"One-step update for obtaining the weight vector â€” optim_weights","text":"X_l Array data.frame containing observed covariates labeled data. X_u Array data.frame containing observed predicted covariates unlabeled data. Y_l Array data.frame observed outcomes labeled data. f_l Array data.frame predicted outcomes labeled data. f_u Array data.frame predicted outcomes unlabeled data. w weights vector PSPA linear regression (d-dimensional, d equals number covariates). theta parameter theta quant quantile quantile estimation method indicates method used M-estimation. Options include \"mean\", \"quantile\", \"ols\", \"logistic\", \"poisson\".","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/optim_weights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"One-step update for obtaining the weight vector â€” optim_weights","text":"weights","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/postpi_analytic_ols.html","id":null,"dir":"Reference","previous_headings":"","what":"PostPI OLS (Analytic Correction) â€” postpi_analytic_ols","title":"PostPI OLS (Analytic Correction) â€” postpi_analytic_ols","text":"Helper function PostPI OLS estimation (analytic correction)","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/postpi_analytic_ols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PostPI OLS (Analytic Correction) â€” postpi_analytic_ols","text":"","code":"postpi_analytic_ols(X_l, Y_l, f_l, X_u, f_u, original = FALSE)"},{"path":"https://ipd-tools.github.io/ipd/reference/postpi_analytic_ols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PostPI OLS (Analytic Correction) â€” postpi_analytic_ols","text":"X_l (matrix): n x p matrix covariates labeled data. Y_l (vector): n-vector labeled outcomes. f_l (vector): n-vector predictions labeled data. X_u (matrix): N x p matrix covariates unlabeled data. f_u (vector): N-vector predictions unlabeled data. original (boolean): Logical argument use original method Wang et al. (2020). Defaults FALSE; TRUE retained posterity.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/postpi_analytic_ols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PostPI OLS (Analytic Correction) â€” postpi_analytic_ols","text":"list outputs: estimate inference model parameters corresponding standard error estimate.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/postpi_analytic_ols.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PostPI OLS (Analytic Correction) â€” postpi_analytic_ols","text":"Methods correcting inference based outcomes predicted machine learning (Wang et al., 2020) https://www.pnas.org/doi/abs/10.1073/pnas.2001238117","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/postpi_analytic_ols.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PostPI OLS (Analytic Correction) â€” postpi_analytic_ols","text":"","code":"dat <- simdat(model = \"ols\")  form <- Y - f ~ X1  X_l <- model.matrix(form, data = dat[dat$set_label == \"labeled\", ])  Y_l <- dat[dat$set_label == \"labeled\", all.vars(form)[1]] |>   matrix(ncol = 1)  f_l <- dat[dat$set_label == \"labeled\", all.vars(form)[2]] |>   matrix(ncol = 1)  X_u <- model.matrix(form, data = dat[dat$set_label == \"unlabeled\", ])  f_u <- dat[dat$set_label == \"unlabeled\", all.vars(form)[2]] |>   matrix(ncol = 1)  postpi_analytic_ols(X_l, Y_l, f_l, X_u, f_u) #> $est #> [1] 0.5682036 1.0413733 #>  #> $se #> [1] 0.1033954 0.1212169 #>"},{"path":"https://ipd-tools.github.io/ipd/reference/postpi_boot_logistic.html","id":null,"dir":"Reference","previous_headings":"","what":"PostPI Logistic Regression (Bootstrap Correction) â€” postpi_boot_logistic","title":"PostPI Logistic Regression (Bootstrap Correction) â€” postpi_boot_logistic","text":"Helper function PostPI logistic regression (bootstrap correction)","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/postpi_boot_logistic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PostPI Logistic Regression (Bootstrap Correction) â€” postpi_boot_logistic","text":"","code":"postpi_boot_logistic(X_l, Y_l, f_l, X_u, f_u, nboot = 100, se_type = \"par\")"},{"path":"https://ipd-tools.github.io/ipd/reference/postpi_boot_logistic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PostPI Logistic Regression (Bootstrap Correction) â€” postpi_boot_logistic","text":"X_l (matrix): n x p matrix covariates labeled data. Y_l (vector): n-vector labeled outcomes. f_l (vector): n-vector predictions labeled data. X_u (matrix): N x p matrix covariates unlabeled data. f_u (vector): N-vector predictions unlabeled data. nboot (integer): Number bootstrap samples. Defaults 100. se_type (string): method calculate standard errors. Options include \"par\" (parametric) \"npar\" (nonparametric). Defaults \"par\".","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/postpi_boot_logistic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PostPI Logistic Regression (Bootstrap Correction) â€” postpi_boot_logistic","text":"list outputs: estimate inference model parameters corresponding standard error based parametric non-parametric bootstrap methods.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/postpi_boot_logistic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PostPI Logistic Regression (Bootstrap Correction) â€” postpi_boot_logistic","text":"Methods correcting inference based outcomes predicted machine learning (Wang et al., 2020) https://www.pnas.org/doi/abs/10.1073/pnas.2001238117","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/postpi_boot_logistic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PostPI Logistic Regression (Bootstrap Correction) â€” postpi_boot_logistic","text":"","code":"dat <- simdat(model = \"logistic\") #> Loading required package: ggplot2 #> Loading required package: lattice  form <- Y - f ~ X1  X_l <- model.matrix(form, data = dat[dat$set_label == \"labeled\", ])  Y_l <- dat[dat$set_label == \"labeled\", all.vars(form)[1]] |>   matrix(ncol = 1)  f_l <- dat[dat$set_label == \"labeled\", all.vars(form)[2]] |>   matrix(ncol = 1)  X_u <- model.matrix(form, data = dat[dat$set_label == \"unlabeled\", ])  f_u <- dat[dat$set_label == \"unlabeled\", all.vars(form)[2]] |>   matrix(ncol = 1)  postpi_boot_logistic(X_l, Y_l, f_l, X_u, f_u, nboot = 200) #> $est #> [1] 0.7048938 0.4037607 #>  #> $se #> [1] 0.1255146 0.1364894 #>"},{"path":"https://ipd-tools.github.io/ipd/reference/postpi_boot_ols.html","id":null,"dir":"Reference","previous_headings":"","what":"PostPI OLS (Bootstrap Correction) â€” postpi_boot_ols","title":"PostPI OLS (Bootstrap Correction) â€” postpi_boot_ols","text":"Helper function PostPI OLS estimation (bootstrap correction)","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/postpi_boot_ols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PostPI OLS (Bootstrap Correction) â€” postpi_boot_ols","text":"","code":"postpi_boot_ols(   X_l,   Y_l,   f_l,   X_u,   f_u,   nboot = 100,   se_type = \"par\",   rel_func = \"lm\",   scale_se = TRUE,   n_t = Inf )"},{"path":"https://ipd-tools.github.io/ipd/reference/postpi_boot_ols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PostPI OLS (Bootstrap Correction) â€” postpi_boot_ols","text":"X_l (matrix): n x p matrix covariates labeled data. Y_l (vector): n-vector labeled outcomes. f_l (vector): n-vector predictions labeled data. X_u (matrix): N x p matrix covariates unlabeled data. f_u (vector): N-vector predictions unlabeled data. nboot (integer): Number bootstrap samples. Defaults 100. se_type (string): method calculate standard errors. Options include \"par\" (parametric) \"npar\" (nonparametric). Defaults \"par\". rel_func (string): Method fitting relationship model. Options include \"lm\" (linear model), \"rf\" (random forest), \"gam\" (generalized additive model). Defaults \"lm\". scale_se (boolean): Logical argument scale relationship model error variance. Defaults TRUE; FALSE option retained posterity. n_t (integer, optional) Size dataset used train prediction function (necessary n_t < nrow(X_l). Defaults Inf.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/postpi_boot_ols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PostPI OLS (Bootstrap Correction) â€” postpi_boot_ols","text":"list outputs: estimate inference model parameters corresponding standard error based parametric non-parametric bootstrap methods.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/postpi_boot_ols.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PostPI OLS (Bootstrap Correction) â€” postpi_boot_ols","text":"Methods correcting inference based outcomes predicted machine learning (Wang et al., 2020) https://www.pnas.org/doi/abs/10.1073/pnas.2001238117","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/postpi_boot_ols.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PostPI OLS (Bootstrap Correction) â€” postpi_boot_ols","text":"","code":"dat <- simdat(model = \"ols\")  form <- Y - f ~ X1  X_l <- model.matrix(form, data = dat[dat$set_label == \"labeled\", ])  Y_l <- dat[dat$set_label == \"labeled\", all.vars(form)[1]] |>    matrix(ncol = 1)  f_l <- dat[dat$set_label == \"labeled\", all.vars(form)[2]] |>    matrix(ncol = 1)  X_u <- model.matrix(form, data = dat[dat$set_label == \"unlabeled\", ])  f_u <- dat[dat$set_label == \"unlabeled\", all.vars(form)[2]] |>    matrix(ncol = 1)  postpi_boot_ols(X_l, Y_l, f_l, X_u, f_u, nboot = 200) #> $est #> [1] 0.8449163 0.9214495 #>  #> $se #> [1] 0.09151302 0.09375500 #>"},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_a_ols.html","id":null,"dir":"Reference","previous_headings":"","what":"PPI ","title":"PPI ","text":"Helper function PPI \"\" OLS estimation","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_a_ols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PPI ","text":"","code":"ppi_a_ols(X_l, Y_l, f_l, X_u, f_u, w_l = NULL, w_u = NULL)"},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_a_ols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PPI ","text":"X_l (matrix): n x p matrix covariates labeled data. Y_l (vector): n-vector labeled outcomes. f_l (vector): n-vector predictions labeled data. X_u (matrix): N x p matrix covariates unlabeled data. f_u (vector): N-vector predictions unlabeled data. w_l (ndarray, optional): Sample weights labeled data set. Defaults vector ones. w_u (ndarray, optional): Sample weights unlabeled data set. Defaults vector ones.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_a_ols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PPI ","text":"(list): list containing following: est (vector): vector PPI OLS regression coefficient estimates. se (vector): vector standard errors coefficients. rectifier_est (vector): vector rectifier OLS regression coefficient estimates.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_a_ols.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PPI ","text":"Another look inference prediction (Gronsbell et al., 2025) https://arxiv.org/pdf/2411.19908","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_a_ols.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PPI ","text":"","code":"dat <- simdat()  form <- Y - f ~ X1  X_l <- model.matrix(form, data = dat[dat$set_label == \"labeled\", ])  Y_l <- dat[dat$set_label == \"labeled\", all.vars(form)[1]] |>    matrix(ncol = 1)  f_l <- dat[dat$set_label == \"labeled\", all.vars(form)[2]] |>    matrix(ncol = 1)  X_u <- model.matrix(form, data = dat[dat$set_label == \"unlabeled\", ])  f_u <- dat[dat$set_label == \"unlabeled\", all.vars(form)[2]] |>    matrix(ncol = 1)  ppi_a_ols(X_l, Y_l, f_l, X_u, f_u) #> $est #>                  [,1] #> (Intercept) 0.6675953 #> X1          0.9846550 #>  #> $se #> (Intercept)          X1  #>  0.08912708  0.07738890  #>  #> $rectifier_est #>                    [,1] #> (Intercept) 0.003684127 #> X1          0.070316087 #>"},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_logistic.html","id":null,"dir":"Reference","previous_headings":"","what":"PPI Logistic Regression â€” ppi_logistic","title":"PPI Logistic Regression â€” ppi_logistic","text":"Helper function PPI logistic regression","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_logistic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PPI Logistic Regression â€” ppi_logistic","text":"","code":"ppi_logistic(X_l, Y_l, f_l, X_u, f_u, opts = NULL)"},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_logistic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PPI Logistic Regression â€” ppi_logistic","text":"X_l (matrix): n x p matrix covariates labeled data. Y_l (vector): n-vector labeled outcomes. f_l (vector): n-vector predictions labeled data. X_u (matrix): N x p matrix covariates unlabeled data. f_u (vector): N-vector predictions unlabeled data. opts (list, optional): Options pass optimizer. See ?optim details.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_logistic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PPI Logistic Regression â€” ppi_logistic","text":"(list): list containing following: est (vector): vector PPI logistic regression coefficient estimates. se (vector): vector standard errors coefficients. rectifier_est (vector): vector rectifier logistic regression coefficient estimates. var_u (matrix): covariance matrix gradients unlabeled data. var_l (matrix): covariance matrix gradients labeled data. grads (matrix): matrix gradients labeled data. grads_hat_unlabeled (matrix): matrix predicted gradients unlabeled data. grads_hat (matrix): matrix predicted gradients labeled data. inv_hessian (matrix): inverse Hessian matrix.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_logistic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PPI Logistic Regression â€” ppi_logistic","text":"Prediction Powered Inference (Angelopoulos et al., 2023) https://www.science.org/doi/10.1126/science.adi6000","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_logistic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PPI Logistic Regression â€” ppi_logistic","text":"","code":"dat <- simdat(model = \"logistic\")  form <- Y - f ~ X1  X_l <- model.matrix(form, data = dat[dat$set_label == \"labeled\", ])  Y_l <- dat[dat$set_label == \"labeled\", all.vars(form)[1]] |>    matrix(ncol = 1)  f_l <- dat[dat$set_label == \"labeled\", all.vars(form)[2]] |>    matrix(ncol = 1)  X_u <- model.matrix(form, data = dat[dat$set_label == \"unlabeled\", ])  f_u <- dat[dat$set_label == \"unlabeled\", all.vars(form)[2]] |>    matrix(ncol = 1)  ppi_logistic(X_l, Y_l, f_l, X_u, f_u) #> $est #>           [,1] #> [1,] 0.1793968 #> [2,] 0.6494671 #>  #> $se #> [1] 0.1865305 0.1836512 #>  #> $rectifier_est #>             [,1] #> [1,]  0.08682910 #> [2,] -0.03653341 #>  #> $var_u #>             [,1]        [,2] #> [1,]  0.18022109 -0.03753627 #> [2,] -0.03753627  0.16889304 #>  #> $var_l #>             [,1]        [,2] #> [1,]  0.35240803 -0.05586951 #> [2,] -0.05586951  0.26862173 #>  #> $grads #>               [,1]          [,2] #>   [1,]  0.42955822 -0.3062621661 #>   [2,]  0.47026499 -0.2161209596 #>   [3,] -0.28823465 -0.3215683446 #>   [4,] -0.52869416  0.2395726190 #>   [5,]  0.40663873 -0.3489162529 #>   [6,]  0.54168405 -0.0102359802 #>   [7,]  0.47473951 -0.2050546250 #>   [8,] -0.49655107  0.1266103949 #>   [9,] -0.41601339 -0.1023359986 #>  [10,]  0.70275582  0.7369394570 #>  [11,]  0.47337208 -0.2084614412 #>  [12,]  0.45496839 -0.2521981094 #>  [13,] -0.69834289  1.0954872655 #>  [14,] -0.39974297 -0.1398028443 #>  [15,]  0.56786388  0.0819656549 #>  [16,]  0.47268275 -0.2101705193 #>  [17,] -0.40977186 -0.1170459478 #>  [18,] -0.21500360 -0.3693242050 #>  [19,] -0.30122878 -0.3070678449 #>  [20,]  0.62388697  0.3138158094 #>  [21,] -0.54481122  0.3012542763 #>  [22,] -0.40371378 -0.1309216389 #>  [23,] -0.41552125 -0.1035111881 #>  [24,]  0.22746660 -0.4910545416 #>  [25,] -0.52789747  0.2366130323 #>  [26,]  0.41543254 -0.3332255917 #>  [27,]  0.26242852 -0.4900453414 #>  [28,]  0.20417069 -0.4840694030 #>  [29,] -0.43903895 -0.0443904858 #>  [30,] -0.22540331 -0.3661659456 #>  [31,] -0.74325784  1.4217799995 #>  [32,]  0.49657155 -0.1476492728 #>  [33,] -0.44540390 -0.0273371619 #>  [34,] -0.44912130 -0.0171669152 #>  [35,]  0.33128806 -0.4497798060 #>  [36,] -0.36520854 -0.2099879166 #>  [37,] -0.31999497 -0.2830081595 #>  [38,] -0.25536180 -0.3502586231 #>  [39,] -0.53421251  0.2603017665 #>  [40,] -0.22984003 -0.3644424100 #>  [41,] -0.59161992  0.5010695125 #>  [42,] -0.34911156 -0.2384237556 #>  [43,] -0.49317424  0.1154914473 #>  [44,] -0.35058332 -0.2359360554 #>  [45,]  0.56037491  0.0546053985 #>  [46,]  0.66150950  0.4997287493 #>  [47,] -0.54218112  0.2909504267 #>  [48,]  0.26076961 -0.4903958012 #>  [49,] -0.67535260  0.9482368605 #>  [50,]  0.68646300  0.6386575895 #>  [51,]  0.33000641 -0.4509822331 #>  [52,]  0.62635518  0.3252149320 #>  [53,] -0.39511183 -0.1499480837 #>  [54,]  0.41858905 -0.3273892949 #>  [55,] -0.58982794  0.4928204598 #>  [56,]  0.59601155  0.1922355336 #>  [57,]  0.34957822 -0.4307594905 #>  [58,]  0.49684555 -0.1468922539 #>  [59,]  0.49457837 -0.1531284444 #>  [60,]  0.61757229  0.2851337592 #>  [61,]  0.41418110 -0.3355095322 #>  [62,] -0.24145761 -0.3588802707 #>  [63,] -0.33308289 -0.2640578702 #>  [64,] -0.63218013  0.7017874325 #>  [65,] -0.18954372 -0.3716881706 #>  [66,] -0.34088551 -0.2519130923 #>  [67,] -0.70552996  1.1440796185 #>  [68,] -0.60056273  0.5429909155 #>  [69,]  0.47248708 -0.2106546114 #>  [70,] -0.28752708 -0.3223069547 #>  [71,] -0.59455166  0.5146734180 #>  [72,]  0.59110275  0.1721330470 #>  [73,] -0.37138205 -0.1983638148 #>  [74,] -0.54485573  0.3014294512 #>  [75,]  0.52145637 -0.0750859870 #>  [76,] -0.60849592  0.5812540974 #>  [77,] -0.47273295  0.0511118399 #>  [78,]  0.36182016 -0.4160833974 #>  [79,] -0.26440101 -0.3435234949 #>  [80,] -0.20169622 -0.3715279138 #>  [81,] -0.46012310  0.0138502514 #>  [82,] -0.61909550  0.6340046305 #>  [83,] -0.41891766 -0.0953472839 #>  [84,] -0.64963888  0.7970597728 #>  [85,]  0.26252643 -0.4900237273 #>  [86,]  0.28754790 -0.4811391526 #>  [87,] -0.44245135 -0.0353041666 #>  [88,] -0.44578022 -0.0263146907 #>  [89,]  0.56812600  0.0829379073 #>  [90,]  0.69219368  0.6725097114 #>  [91,]  0.45621248 -0.2493643481 #>  [92,]  0.30723463 -0.4694974136 #>  [93,]  0.27801414 -0.4853102841 #>  [94,] -0.42355218 -0.0840047125 #>  [95,] -0.51094759  0.1755909041 #>  [96,] -0.31979084 -0.2832896153 #>  [97,]  0.30003983 -0.4742232099 #>  [98,]  0.82888116  1.7846052481 #>  [99,]  0.75398206  1.0919272518 #> [100,] -0.41198298 -0.1118830005 #> [101,] -0.48049046  0.0749581037 #> [102,] -0.49324381  0.1157191217 #> [103,] -0.34327921 -0.2480604410 #> [104,]  0.61063699  0.2544155626 #> [105,] -0.42616493 -0.0775067330 #> [106,] -0.45148135 -0.0106292084 #> [107,]  0.36769072 -0.4084904174 #> [108,] -0.26860303 -0.3400926154 #> [109,] -0.55805524  0.3545869697 #> [110,]  0.34661621 -0.4340758440 #> [111,]  0.42590837 -0.3134382525 #> [112,] -0.24745693 -0.3554205574 #> [113,]  0.60577066  0.2333401490 #> [114,]  0.75703818  1.1156387946 #> [115,]  0.56953006  0.0881630152 #> [116,] -0.30445939 -0.3031879209 #> [117,] -0.64949728  0.7962639524 #> [118,] -0.38061728 -0.1802278473 #> [119,]  0.49296603 -0.1575252761 #> [120,] -0.51437549  0.1876354783 #> [121,]  0.33075713 -0.4502799838 #> [122,] -0.44681935 -0.0234830652 #> [123,] -0.34791327 -0.2404325618 #> [124,]  0.59469699  0.1868150114 #> [125,]  0.30391882 -0.4717426050 #> [126,] -0.31148262 -0.2943768481 #> [127,] -0.45184258 -0.0096229792 #> [128,]  0.58898109  0.1635609539 #> [129,] -0.29937325 -0.3092469314 #> [130,]  0.27836567 -0.4851735889 #> [131,]  0.54492168  0.0006508340 #> [132,]  0.66034705  0.4935765218 #> [133,] -0.45345428 -0.0051154411 #> [134,] -0.28929718 -0.3204492809 #> [135,]  0.54488787  0.0005364103 #> [136,]  0.50557353 -0.1222948810 #> [137,] -0.23705804 -0.3611641047 #> [138,]  0.34289990 -0.4381076022 #> [139,]  0.56644077  0.0767043037 #> [140,] -0.16282806 -0.3655199389 #> [141,]  0.47879869 -0.1948119501 #> [142,]  0.77028187  1.2222028642 #> [143,]  0.31640329 -0.4626918878 #> [144,]  0.41245150 -0.3386382307 #> [145,] -0.41384562 -0.1074927542 #> [146,] -0.42694749 -0.0755459236 #> [147,] -0.20972712 -0.3704476015 #> [148,]  0.21786471 -0.4889373901 #> [149,]  0.59889784  0.2042331666 #> [150,]  0.67728300  0.5859827886 #> [151,] -0.29420254 -0.3151288477 #> [152,] -0.73629479  1.3674525172 #> [153,]  0.63793927  0.3801645635 #> [154,] -0.58317793  0.4626417233 #> [155,] -0.24159786 -0.3588039340 #> [156,] -0.41645367 -0.1012824189 #> [157,] -0.24246869 -0.3583250512 #> [158,] -0.57556025  0.4288966387 #> [159,] -0.41000981 -0.1164928746 #> [160,]  0.26686894 -0.4889613550 #> [161,] -0.26505930 -0.3429985410 #> [162,] -0.33408950 -0.2625266303 #> [163,] -0.22603145 -0.3659355052 #> [164,]  0.57572884  0.1115766511 #> [165,]  0.40273809 -0.3556094386 #> [166,]  0.47951526 -0.1929836045 #> [167,] -0.65544531  0.8300293862 #> [168,] -0.59101801  0.4982931331 #> [169,]  0.61269125  0.2634301443 #> [170,]  0.45396275 -0.2544758690 #> [171,]  0.36273205 -0.4149276126 #> [172,]  0.33416059 -0.4470228029 #> [173,] -0.43324539 -0.0595202715 #> [174,] -0.24509359 -0.3568308533 #> [175,] -0.79288471  1.8578479292 #> [176,] -0.60007789  0.5406855059 #> [177,]  0.55650686  0.0407871539 #> [178,]  0.41788800 -0.3286948659 #> [179,] -0.46257699  0.0209572067 #> [180,] -0.17307921 -0.3689779013 #> [181,] -0.54814230  0.3144398232 #> [182,]  0.52101565 -0.0764392920 #> [183,]  0.69245056  0.6740450905 #> [184,] -0.41499487 -0.1047652369 #> [185,]  0.50616297 -0.1205996788 #> [186,]  0.32093053 -0.4590085208 #> [187,] -0.45544864  0.0005031620 #> [188,]  0.46517009 -0.2284372571 #> [189,] -0.47576536  0.0603489001 #> [190,] -0.54307882  0.2944567625 #> [191,]  0.44700193 -0.2699274190 #> [192,] -0.57829563  0.4409137578 #> [193,]  0.34314244 -0.4378488553 #> [194,] -0.22595568 -0.3659635405 #> [195,]  0.77072818  1.2259062384 #> [196,]  0.64156509  0.3978662776 #> [197,]  0.45122455 -0.2606195462 #> [198,] -0.09197210 -0.2988561902 #> [199,]  0.70570878  0.7554410477 #> [200,] -0.34438549 -0.2462597536 #> [201,] -0.25094091 -0.3532296809 #> [202,]  0.63370554  0.3598010008 #> [203,] -0.32183614 -0.2804499536 #> [204,]  0.29120411 -0.4792847853 #> [205,]  0.33798675 -0.4432173443 #> [206,] -0.58516202  0.4715748464 #> [207,] -0.57110855  0.4095765499 #> [208,] -0.09801533 -0.3078813149 #> [209,]  0.65439382  0.4624945604 #> [210,]  0.69405418  0.6836647971 #> [211,]  0.48124264 -0.1885510664 #> [212,] -0.46277692  0.0215392939 #> [213,]  0.51099347 -0.1065436901 #> [214,] -0.27369036 -0.3356857579 #> [215,] -0.33608777 -0.2594556885 #> [216,] -0.35097745 -0.2352660361 #> [217,]  0.42048135 -0.3238385263 #> [218,]  0.35023853 -0.4300077457 #> [219,] -0.48541228  0.0904574690 #> [220,]  0.30395449 -0.4717190574 #> [221,] -0.27473091 -0.3347503499 #> [222,]  0.51017142 -0.1089563876 #> [223,]  0.39698531 -0.3651832847 #> [224,]  0.69078335  0.6641079815 #> [225,]  0.47868937 -0.1950903574 #> [226,] -0.36680190 -0.2070260044 #> [227,] -0.26380540 -0.3439944395 #> [228,] -0.32806045 -0.2715405446 #> [229,]  0.74103406  0.9948879209 #> [230,] -0.44976367 -0.0153936843 #> [231,]  0.65057197  0.4429096402 #> [232,]  0.76146124  1.1505278211 #> [233,] -0.30275985 -0.3052426618 #> [234,]  0.30363270 -0.4719309545 #> [235,] -0.42534093 -0.0795641162 #> [236,] -0.45846478  0.0090866013 #> [237,] -0.39950067 -0.1403393239 #> [238,]  0.50389900 -0.1270871318 #> [239,]  0.45700496 -0.2475500234 #> [240,]  0.57965516  0.1267015693 #> [241,]  0.38072634 -0.3903379562 #> [242,] -0.40188498 -0.1350329601 #> [243,] -0.36907960 -0.2027457945 #> [244,] -0.28356331 -0.3263468619 #> [245,]  0.30205507 -0.4729541209 #> [246,] -0.42986554 -0.0681749853 #> [247,] -0.52907328  0.2409839127 #> [248,]  0.53192141 -0.0422096547 #> [249,]  0.18733815 -0.4750168494 #> [250,] -0.48914719  0.1024126325 #> [251,] -0.71760466  1.2286716281 #> [252,] -0.49705567  0.1282838703 #> [253,]  0.45228900 -0.2582413525 #> [254,] -0.53272085  0.2546588250 #> [255,]  0.58842100  0.1613096931 #> [256,] -0.39485190 -0.1505107194 #> [257,] -0.47484038  0.0575198587 #> [258,] -0.66465306  0.8836867295 #> [259,] -0.50449371  0.1533149205 #> [260,]  0.52052423 -0.0779453463 #> [261,] -0.23931740 -0.3600181473 #> [262,] -0.37831715 -0.1848287198 #> [263,] -0.52178553  0.2141832404 #> [264,]  0.49618248 -0.1487226246 #> [265,] -0.34988277 -0.2371230104 #> [266,] -0.44655588 -0.0242021540 #> [267,]  0.35023332 -0.4300136955 #> [268,] -0.60228856  0.5512279095 #> [269,]  0.35194221 -0.4280471702 #> [270,] -0.68023645  0.9785169545 #> [271,]  0.52585015 -0.0614566848 #> [272,] -0.58915245  0.4897239267 #> [273,] -0.42596872 -0.0779973119 #> [274,] -0.45276051 -0.0070593614 #> [275,]  0.23088074 -0.4915543461 #> [276,] -0.41418865 -0.1066801359 #> [277,] -0.19189578 -0.3717978396 #> [278,]  0.61622773  0.2791149497 #> [279,] -0.27182178 -0.3373365423 #> [280,]  0.70927075  0.7780510559 #> [281,] -0.51824411  0.2014078191 #> [282,] -0.55011358  0.3223146234 #> [283,]  0.45347770 -0.2555703592 #> [284,] -0.65718457  0.8400341991 #> [285,] -0.51578848  0.1926436409 #> [286,] -0.47975096  0.0726542434 #> [287,]  0.59294321  0.1796257595 #> [288,] -0.45847254  0.0091088070 #> [289,] -0.52745884  0.2349871501 #> [290,]  0.66891045  0.5395476083 #> [291,] -0.28129361 -0.3285853522 #> [292,] -0.49031180  0.1061748189 #> [293,]  0.40226631 -0.3564079037 #> [294,] -0.46565799  0.0299786942 #> [295,]  0.64885268  0.4341918333 #> [296,] -0.24047138 -0.3594109327 #> [297,] -0.54213365  0.2907653427 #> [298,] -0.43937970 -0.0434889957 #> [299,]  0.61256470  0.2628727753 #> [300,] -0.23207536 -0.3634897193 #>  #> $grads_hat_unlabeled #>              [,1]         [,2] #>   [1,] -0.5371873  0.271643785 #>   [2,] -0.2665503 -0.341792304 #>   [3,] -0.3268345 -0.273327274 #>   [4,]  0.3024587 -0.472694813 #>   [5,] -0.7514194  1.487404139 #>   [6,] -0.2863687 -0.323504727 #>   [7,]  0.1762252 -0.467117095 #>   [8,] -0.2410241 -0.359114880 #>   [9,] -0.3694411 -0.202061493 #>  [10,]  0.4029928 -0.355177306 #>  [11,]  0.5910499  0.171918628 #>  [12,]  0.4692606 -0.218572857 #>  [13,]  0.3916991 -0.373669391 #>  [14,] -0.5769333  0.434914990 #>  [15,]  0.4272007 -0.310914145 #>  [16,] -0.4493036 -0.016664231 #>  [17,]  0.5436846 -0.003525789 #>  [18,] -0.3079500 -0.298873160 #>  [19,]  0.5523318  0.026108208 #>  [20,] -0.2402483 -0.359529460 #>  [21,] -0.3541993 -0.229728165 #>  [22,] -0.3652297 -0.209948765 #>  [23,] -0.5690053  0.400549922 #>  [24,] -0.3333112 -0.263711426 #>  [25,] -0.2646930 -0.343291222 #>  [26,] -0.7599091  1.558012649 #>  [27,]  0.5953090  0.189335193 #>  [28,] -0.6094767  0.586056406 #>  [29,] -0.5392802  0.279694433 #>  [30,] -0.6433790  0.762244359 #>  [31,] -0.3939221 -0.152517552 #>  [32,] -0.4878337  0.098188974 #>  [33,]  0.4386250 -0.287799203 #>  [34,] -0.2844447 -0.325462923 #>  [35,] -0.3612474 -0.217236214 #>  [36,]  0.4198984 -0.324936465 #>  [37,]  0.3087711 -0.468418112 #>  [38,] -0.6195974  0.636549800 #>  [39,] -0.4182388 -0.096989136 #>  [40,] -0.2420912 -0.358533686 #>  [41,]  0.3833104 -0.386527203 #>  [42,] -0.5607127  0.365583974 #>  [43,] -0.5370684  0.271188026 #>  [44,]  0.2935477 -0.478022149 #>  [45,]  0.8293826  1.790204431 #>  [46,] -0.2974156 -0.311506852 #>  [47,] -0.3596760 -0.220066246 #>  [48,] -0.1885525 -0.371621486 #>  [49,] -0.3035500 -0.304291069 #>  [50,]  0.5210774 -0.076249826 #>  [51,] -0.6064898  0.571481229 #>  [52,]  0.6029373  0.221247832 #>  [53,]  0.5104144 -0.108244046 #>  [54,]  0.4695439 -0.217882517 #>  [55,] -0.2988668 -0.309835395 #>  [56,] -0.5448917  0.301570902 #>  [57,] -0.3764591 -0.188504542 #>  [58,] -0.4121867 -0.111404577 #>  [59,]  0.4324356 -0.300501536 #>  [60,]  0.4489897 -0.265570873 #>  [61,] -0.1464398 -0.357021133 #>  [62,]  0.4144113 -0.335090722 #>  [63,]  0.8682466  2.280879053 #>  [64,] -0.3464839 -0.242809278 #>  [65,] -0.5988711  0.534963838 #>  [66,] -0.1574185 -0.363126889 #>  [67,] -0.2106229 -0.370279844 #>  [68,] -0.6515004  0.807557778 #>  [69,] -0.2217520 -0.367416351 #>  [70,] -0.2021159 -0.371490459 #>  [71,] -0.5175263  0.198837843 #>  [72,] -0.5466110  0.308359657 #>  [73,] -0.2678214 -0.340745188 #>  [74,]  0.4751806 -0.203950973 #>  [75,] -0.5764576  0.432826612 #>  [76,]  0.5873858  0.157161315 #>  [77,] -0.3899056 -0.161080318 #>  [78,] -0.3507880 -0.235588336 #>  [79,] -0.1884554 -0.371614296 #>  [80,] -0.5392887  0.279726993 #>  [81,]  0.4671832 -0.223606924 #>  [82,] -0.6333333  0.707907026 #>  [83,] -0.2437254 -0.357619170 #>  [84,]  0.2848032 -0.482438577 #>  [85,] -0.5051118  0.155425620 #>  [86,]  0.3535505 -0.426168640 #>  [87,] -0.2512248 -0.353045276 #>  [88,]  0.3448477 -0.436012407 #>  [89,] -0.3972999 -0.145183364 #>  [90,] -0.4357771 -0.052954698 #>  [91,] -0.3196176 -0.283528070 #>  [92,] -0.2406286 -0.359327042 #>  [93,] -0.2248462 -0.366366569 #>  [94,]  0.2490575 -0.492020677 #>  [95,] -0.4717960  0.048279717 #>  [96,] -0.2325236 -0.363291922 #>  [97,] -0.3342137 -0.262336897 #>  [98,]  0.2027365 -0.483431580 #>  [99,] -0.3788345 -0.183798802 #> [100,]  0.2047241 -0.484308958 #> [101,] -0.6091424  0.584417545 #> [102,] -0.4623832  0.020393337 #> [103,]  0.4951618 -0.151529763 #> [104,]  0.5872291  0.156534916 #> [105,]  0.4998811 -0.138444063 #> [106,] -0.4652902  0.028895964 #> [107,] -0.4640279  0.025191807 #> [108,] -0.2359031 -0.361727907 #> [109,]  0.7093651  0.778654197 #> [110,] -0.4951735  0.122057724 #> [111,] -0.2146205 -0.369416716 #> [112,] -0.3761448 -0.189122847 #> [113,] -0.5626079  0.373487942 #> [114,] -0.3352097 -0.260810234 #> [115,]  0.7166056  0.825643514 #> [116,] -0.5015376  0.143285067 #> [117,] -0.1628415 -0.365525411 #> [118,]  0.3878696 -0.379631594 #> [119,]  0.4334237 -0.298502029 #> [120,] -0.1876918 -0.371553700 #> [121,] -0.4274740 -0.074222977 #> [122,] -0.4543598 -0.002570022 #> [123,] -0.4676068  0.035741733 #> [124,] -0.6453987  0.773395982 #> [125,] -0.3091351 -0.297379268 #> [126,]  0.3482953 -0.432207050 #> [127,] -0.4138186 -0.107556797 #> [128,] -0.3212867 -0.281217045 #> [129,] -0.5211963  0.212046547 #> [130,]  0.4213489 -0.322197624 #> [131,]  0.3511423 -0.428971457 #> [132,]  0.6226966  0.308356434 #> [133,] -0.1844389 -0.371214139 #> [134,] -0.4524541 -0.007916166 #> [135,]  0.4024154 -0.356155889 #> [136,] -0.4149344 -0.104909208 #> [137,]  0.5484429  0.012653564 #> [138,]  0.4100810 -0.342873668 #> [139,] -0.3890536 -0.162874830 #> [140,] -0.5717781  0.412463640 #> [141,] -0.4021835 -0.134364371 #> [142,]  0.2971110 -0.475991770 #> [143,]  0.1890628 -0.476103763 #> [144,] -0.3080192 -0.298786222 #> [145,]  0.5127718 -0.101295273 #> [146,] -0.2748497 -0.334642816 #> [147,] -0.5389523  0.278428935 #> [148,] -0.4902147  0.105860390 #> [149,]  0.7643717  1.173863448 #> [150,]  0.3415599 -0.439526091 #> [151,] -0.5066796  0.160801308 #> [152,] -0.3262818 -0.274127570 #> [153,] -0.4365403 -0.050961400 #> [154,]  0.2589446 -0.490747008 #> [155,] -0.5053280  0.156165102 #> [156,] -0.5386716  0.277347064 #> [157,] -0.4832619  0.083650112 #> [158,]  0.2479179 -0.492098859 #> [159,] -0.2336495 -0.362785073 #> [160,] -0.1825243 -0.370952268 #> [161,] -0.2808232 -0.329042475 #> [162,] -0.3214925 -0.280930153 #> [163,] -0.5771382  0.435815252 #> [164,] -0.2728197 -0.336459601 #> [165,] -0.5219803  0.214890703 #> [166,] -0.4051906 -0.127575466 #> [167,]  0.4083252 -0.345971769 #> [168,] -0.3612276 -0.217272134 #> [169,] -0.5193912  0.205528119 #> [170,] -0.1983851 -0.371749235 #> [171,] -0.6492628  0.794947134 #> [172,]  0.4822333 -0.185992953 #> [173,] -0.2018607 -0.371513488 #> [174,]  0.4473377 -0.269194744 #> [175,] -0.1246349 -0.339641197 #> [176,]  0.3218481 -0.458236001 #> [177,]  0.3409757 -0.440138659 #> [178,] -0.4299339 -0.068001204 #> [179,] -0.3962753 -0.147420892 #> [180,]  0.5437814 -0.003199841 #> [181,] -0.6441145  0.766296438 #> [182,]  0.4261853 -0.312898822 #> [183,]  0.4518854 -0.259144533 #> [184,]  0.5690267  0.086286610 #> [185,]  0.4326369 -0.300094997 #> [186,] -0.3928169 -0.154890786 #> [187,] -0.4607511  0.015662521 #> [188,]  0.6441425  0.410598572 #> [189,] -0.3820469 -0.177340174 #> [190,]  0.4463770 -0.271287752 #> [191,] -0.4954137  0.122849929 #> [192,] -0.3909949 -0.158774952 #> [193,] -0.2377028 -0.360842878 #> [194,] -0.2713769 -0.337724053 #> [195,] -0.2076491 -0.370800414 #> [196,] -0.6550389  0.827700303 #> [197,] -0.2889765 -0.320788241 #> [198,]  0.5084756 -0.113906762 #> [199,] -0.3898070 -0.161288565 #> [200,]  0.3021836 -0.472871738 #> [201,] -0.6029094  0.554202570 #> [202,] -0.1941850 -0.371839300 #> [203,]  0.3142594 -0.464361701 #> [204,]  0.4356214 -0.294016411 #> [205,] -0.4888978  0.101609268 #> [206,] -0.5054544  0.156597681 #> [207,]  0.5832820  0.140878678 #> [208,] -0.2858176 -0.324069667 #> [209,] -0.3913148 -0.158095589 #> [210,] -0.5923286  0.504345591 #> [211,]  0.4676792 -0.222409398 #> [212,] -0.3005091 -0.307917293 #> [213,]  0.3989209 -0.362001558 #> [214,] -0.5896037  0.491791796 #> [215,]  0.3053779 -0.470768814 #> [216,] -0.3586776 -0.221851042 #> [217,] -0.4601415  0.013903426 #> [218,]  0.4480185 -0.267704944 #> [219,] -0.5673488  0.393485808 #> [220,]  0.4985691 -0.142109421 #> [221,] -0.3621240 -0.215646259 #> [222,] -0.4747136  0.057132961 #> [223,] -0.4329309 -0.060330884 #> [224,]  0.4410227 -0.282763980 #> [225,]  0.3080236 -0.468946297 #> [226,] -0.2846293 -0.325276729 #> [227,]  0.5422292 -0.008412900 #> [228,]  0.3093395 -0.468012572 #> [229,] -0.3252572 -0.275602940 #> [230,] -0.6333739  0.708122582 #> [231,] -0.5680595  0.396511588 #> [232,] -0.1808146 -0.370679326 #> [233,]  0.5724167  0.098995874 #> [234,] -0.1536342 -0.361213685 #> [235,] -0.3221445 -0.280018025 #> [236,]  0.4800322 -0.191660784 #> [237,]  0.5318309 -0.042500058 #> [238,]  0.2183543 -0.489070954 #> [239,] -0.7049472  1.140091816 #> [240,]  0.4699155 -0.216975460 #> [241,] -0.3882240 -0.164614688 #> [242,] -0.3603105 -0.218926714 #> [243,]  0.3421271 -0.438927928 #> [244,] -0.4579667  0.007662013 #> [245,]  0.4077855 -0.346917409 #> [246,] -0.4972516  0.128934529 #> [247,] -0.2233641 -0.366883051 #> [248,]  0.4871672 -0.173078221 #> [249,] -0.3830042 -0.175394420 #> [250,] -0.5947103  0.515413533 #> [251,] -0.4420163 -0.036469872 #> [252,] -0.3763759 -0.188668432 #> [253,] -0.3212964 -0.281203535 #> [254,]  0.3236088 -0.456729033 #> [255,]  0.3134017 -0.465016315 #> [256,] -0.2061199 -0.371027470 #> [257,] -0.4112641 -0.113567291 #> [258,] -0.2583373 -0.348139209 #> [259,]  0.3899170 -0.376463356 #> [260,] -0.3387227 -0.255342855 #> [261,] -0.5452636  0.303035949 #> [262,]  0.4735912 -0.207917117 #> [263,] -0.6208480  0.642909713 #> [264,]  0.4432916 -0.277940220 #> [265,] -0.1904687 -0.371739436 #> [266,] -0.3610599 -0.217575323 #> [267,]  0.4285525 -0.308254211 #> [268,] -0.2872203 -0.322625513 #> [269,] -0.4276999 -0.073654210 #> [270,] -0.3313174 -0.266717993 #> [271,] -0.3030196 -0.304930534 #> [272,] -0.3662575 -0.208040913 #> [273,] -0.3231825 -0.278556916 #> [274,] -0.6102077  0.589645734 #> [275,]  0.4220828 -0.320802931 #> [276,] -0.3366689 -0.258554821 #> [277,]  0.4326564 -0.300055546 #> [278,]  0.6373453  0.377287730 #> [279,]  0.3623158 -0.415456259 #> [280,]  0.4429070 -0.278761965 #> [281,] -0.1617601 -0.365079051 #> [282,] -0.3226141 -0.279358403 #> [283,] -0.4544104 -0.002427478 #> [284,]  0.4660762 -0.226268965 #> [285,] -0.2126759 -0.369859887 #> [286,] -0.1521160 -0.360389943 #> [287,] -0.4898854  0.104795612 #> [288,] -0.3964954 -0.146941181 #> [289,]  0.8292105  1.788281338 #> [290,] -0.5876438  0.482833731 #> [291,] -0.3907903 -0.159208994 #> [292,] -0.5191140  0.204530833 #> [293,] -0.4286527 -0.071249970 #> [294,] -0.2708843 -0.338150714 #> [295,] -0.5380001  0.274763271 #> [296,]  0.3337495 -0.447422639 #> [297,] -0.4172275 -0.099425527 #> [298,] -0.4762981  0.061982933 #> [299,] -0.5322688  0.252954362 #> [300,]  0.4135180 -0.336712940 #>  #> $grads_hat #>               [,1]          [,2] #>   [1,]  0.42955822 -0.3062621661 #>   [2,] -0.52973501  0.2434517576 #>   [3,] -0.28823465 -0.3215683446 #>   [4,] -0.52869416  0.2395726190 #>   [5,]  0.40663873 -0.3489162529 #>   [6,]  0.54168405 -0.0102359802 #>   [7,] -0.52526049  0.2268761906 #>   [8,]  0.50344893 -0.1283692101 #>   [9,] -0.41601339 -0.1023359986 #>  [10,] -0.29724418 -0.3117028140 #>  [11,]  0.47337208 -0.2084614412 #>  [12,] -0.54503161  0.3021219582 #>  [13,] -0.69834289  1.0954872655 #>  [14,] -0.39974297 -0.1398028443 #>  [15,] -0.43213612 -0.0623746657 #>  [16,]  0.47268275 -0.2101705193 #>  [17,] -0.40977186 -0.1170459478 #>  [18,] -0.21500360 -0.3693242050 #>  [19,] -0.30122878 -0.3070678449 #>  [20,] -0.37611303 -0.1891852565 #>  [21,] -0.54481122  0.3012542763 #>  [22,] -0.40371378 -0.1309216389 #>  [23,] -0.41552125 -0.1035111881 #>  [24,]  0.22746660 -0.4910545416 #>  [25,] -0.52789747  0.2366130323 #>  [26,] -0.58456746  0.4688916240 #>  [27,]  0.26242852 -0.4900453414 #>  [28,] -0.79582931  1.8868360742 #>  [29,] -0.43903895 -0.0443904858 #>  [30,] -0.22540331 -0.3661659456 #>  [31,] -0.74325784  1.4217799995 #>  [32,] -0.50342845  0.1496880858 #>  [33,] -0.44540390 -0.0273371619 #>  [34,] -0.44912130 -0.0171669152 #>  [35,]  0.33128806 -0.4497798060 #>  [36,] -0.36520854 -0.2099879166 #>  [37,] -0.31999497 -0.2830081595 #>  [38,] -0.25536180 -0.3502586231 #>  [39,] -0.53421251  0.2603017665 #>  [40,] -0.22984003 -0.3644424100 #>  [41,] -0.59161992  0.5010695125 #>  [42,] -0.34911156 -0.2384237556 #>  [43,] -0.49317424  0.1154914473 #>  [44,] -0.35058332 -0.2359360554 #>  [45,] -0.43962509 -0.0428390037 #>  [46,] -0.33849050 -0.2557082429 #>  [47,]  0.45781888 -0.2456791564 #>  [48,]  0.26076961 -0.4903958012 #>  [49,]  0.32464740 -0.4558250499 #>  [50,] -0.31353700 -0.2917022239 #>  [51,] -0.66999359  0.9156040383 #>  [52,] -0.37364482 -0.1940031476 #>  [53,]  0.60488817  0.2295598786 #>  [54,] -0.58141095  0.4547365098 #>  [55,]  0.41017206 -0.3427121211 #>  [56,] -0.40398845 -0.1303010591 #>  [57,] -0.65042178  0.8014668339 #>  [58,] -0.50315445  0.1487574773 #>  [59,]  0.49457837 -0.1531284444 #>  [60,]  0.61757229  0.2851337592 #>  [61,] -0.58581890  0.4745456129 #>  [62,] -0.24145761 -0.3588802707 #>  [63,] -0.33308289 -0.2640578702 #>  [64,]  0.36781987 -0.4083193219 #>  [65,] -0.18954372 -0.3716881706 #>  [66,] -0.34088551 -0.2519130923 #>  [67,]  0.29447004 -0.4775093856 #>  [68,]  0.39943727 -0.3611459674 #>  [69,]  0.47248708 -0.2106546114 #>  [70,] -0.28752708 -0.3223069547 #>  [71,] -0.59455166  0.5146734180 #>  [72,] -0.40889725 -0.1190735936 #>  [73,] -0.37138205 -0.1983638148 #>  [74,] -0.54485573  0.3014294512 #>  [75,] -0.47854363  0.0689068606 #>  [76,]  0.39150408 -0.3739767963 #>  [77,] -0.47273295  0.0511118399 #>  [78,]  0.36182016 -0.4160833974 #>  [79,] -0.26440101 -0.3435234949 #>  [80,] -0.20169622 -0.3715279138 #>  [81,]  0.53987690 -0.0162509355 #>  [82,]  0.38090450 -0.3900774851 #>  [83,] -0.41891766 -0.0953472839 #>  [84,] -0.64963888  0.7970597728 #>  [85,]  0.26252643 -0.4900237273 #>  [86,]  0.28754790 -0.4811391526 #>  [87,] -0.44245135 -0.0353041666 #>  [88,] -0.44578022 -0.0263146907 #>  [89,]  0.56812600  0.0829379073 #>  [90,] -0.30780632 -0.2990532134 #>  [91,] -0.54378752  0.2972326024 #>  [92,]  0.30723463 -0.4694974136 #>  [93,] -0.72198586  1.2603213739 #>  [94,] -0.42355218 -0.0840047125 #>  [95,] -0.51094759  0.1755909041 #>  [96,]  0.68020916  0.6025694540 #>  [97,]  0.30003983 -0.4742232099 #>  [98,]  0.82888116  1.7846052481 #>  [99,] -0.24601794 -0.3562865805 #> [100,] -0.41198298 -0.1118830005 #> [101,] -0.48049046  0.0749581037 #> [102,] -0.49324381  0.1157191217 #> [103,] -0.34327921 -0.2480604410 #> [104,] -0.38936301 -0.1622240549 #> [105,] -0.42616493 -0.0775067330 #> [106,] -0.45148135 -0.0106292084 #> [107,]  0.36769072 -0.4084904174 #> [108,] -0.26860303 -0.3400926154 #> [109,]  0.44194476 -0.2808106494 #> [110,]  0.34661621 -0.4340758440 #> [111,]  0.42590837 -0.3134382525 #> [112,] -0.24745693 -0.3554205574 #> [113,] -0.39422934 -0.1518553757 #> [114,] -0.24296182 -0.3580501484 #> [115,] -0.43046994 -0.0666365668 #> [116,] -0.30445939 -0.3031879209 #> [117,] -0.64949728  0.7962639524 #> [118,]  0.61938272  0.2932867748 #> [119,] -0.50703397  0.1620206293 #> [120,]  0.48562451 -0.1771476088 #> [121,]  0.33075713 -0.4502799838 #> [122,] -0.44681935 -0.0234830652 #> [123,]  0.65208673  0.4506378314 #> [124,] -0.40530301 -0.1273197749 #> [125,]  0.30391882 -0.4717426050 #> [126,] -0.31148262 -0.2943768481 #> [127,]  0.54815742  0.0116742150 #> [128,]  0.58898109  0.1635609539 #> [129,] -0.29937325 -0.3092469314 #> [130,]  0.27836567 -0.4851735889 #> [131,] -0.45507832 -0.0005435284 #> [132,] -0.33965295 -0.2538736609 #> [133,] -0.45345428 -0.0051154411 #> [134,] -0.28929718 -0.3204492809 #> [135,] -0.45511213 -0.0004480313 #> [136,]  0.50557353 -0.1222948810 #> [137,] -0.23705804 -0.3611641047 #> [138,]  0.34289990 -0.4381076022 #> [139,]  0.56644077  0.0767043037 #> [140,] -0.16282806 -0.3655199389 #> [141,] -0.52120131  0.2120645787 #> [142,]  0.77028187  1.2222028642 #> [143,]  0.31640329 -0.4626918878 #> [144,]  0.41245150 -0.3386382307 #> [145,] -0.41384562 -0.1074927542 #> [146,] -0.42694749 -0.0755459236 #> [147,] -0.20972712 -0.3704476015 #> [148,]  0.21786471 -0.4889373901 #> [149,]  0.59889784  0.2042331666 #> [150,] -0.32271700 -0.2792135728 #> [151,]  0.70579746  0.7560000566 #> [152,] -0.73629479  1.3674525172 #> [153,] -0.36206073 -0.2157613799 #> [154,] -0.58317793  0.4626417233 #> [155,] -0.24159786 -0.3588039340 #> [156,] -0.41645367 -0.1012824189 #> [157,] -0.24246869 -0.3583250512 #> [158,]  0.42443975 -0.3162844977 #> [159,] -0.41000981 -0.1164928746 #> [160,]  0.26686894 -0.4889613550 #> [161,] -0.26505930 -0.3429985410 #> [162,] -0.33408950 -0.2625266303 #> [163,] -0.22603145 -0.3659355052 #> [164,] -0.42427116 -0.0822240465 #> [165,]  0.40273809 -0.3556094386 #> [166,]  0.47951526 -0.1929836045 #> [167,]  0.34455469 -0.4363300958 #> [168,]  0.40898199 -0.3448167691 #> [169,] -0.38730875 -0.1665256329 #> [170,] -0.54603725  0.3060896655 #> [171,]  0.36273205 -0.4149276126 #> [172,]  0.33416059 -0.4470228029 #> [173,] -0.43324539 -0.0595202715 #> [174,] -0.24509359 -0.3568308533 #> [175,]  0.20711529 -0.4853022321 #> [176,]  0.39992211 -0.3603400366 #> [177,]  0.55650686  0.0407871539 #> [178,] -0.58211200  0.4578672432 #> [179,]  0.53742301 -0.0243481308 #> [180,] -0.17307921 -0.3689779013 #> [181,] -0.54814230  0.3144398232 #> [182,] -0.47898435  0.0702727928 #> [183,] -0.30754944 -0.2993747115 #> [184,]  0.58500513  0.1476842390 #> [185,] -0.49383703  0.1176628686 #> [186,]  0.32093053 -0.4590085208 #> [187,] -0.45544864  0.0005031620 #> [188,]  0.46517009 -0.2284372571 #> [189,]  0.52423464 -0.0664970300 #> [190,] -0.54307882  0.2944567625 #> [191,]  0.44700193 -0.2699274190 #> [192,]  0.42170437 -0.3215228455 #> [193,]  0.34314244 -0.4378488553 #> [194,] -0.22595568 -0.3659635405 #> [195,] -0.22927182 -0.3646755930 #> [196,] -0.35843491 -0.2222832354 #> [197,]  0.45122455 -0.2606195462 #> [198,] -0.09197210 -0.2988561902 #> [199,] -0.29429122 -0.3150303337 #> [200,] -0.34438549 -0.2462597536 #> [201,] -0.25094091 -0.3532296809 #> [202,]  0.63370554  0.3598010008 #> [203,] -0.32183614 -0.2804499536 #> [204,]  0.29120411 -0.4792847853 #> [205,] -0.66201325  0.8681279739 #> [206,] -0.58516202  0.4715748464 #> [207,]  0.42889145 -0.3075840548 #> [208,] -0.09801533 -0.3078813149 #> [209,] -0.34560618 -0.2442580757 #> [210,] -0.30594582 -0.3013660751 #> [211,]  0.48124264 -0.1885510664 #> [212,] -0.46277692  0.0215392939 #> [213,] -0.48900653  0.1019593478 #> [214,] -0.27369036 -0.3356857579 #> [215,] -0.33608777 -0.2594556885 #> [216,] -0.35097745 -0.2352660361 #> [217,] -0.57951865  0.4463229310 #> [218,] -0.64976147  0.7977490814 #> [219,] -0.48541228  0.0904574690 #> [220,] -0.69604551  1.0802206759 #> [221,] -0.27473091 -0.3347503499 #> [222,] -0.48982858  0.1046118029 #> [223,]  0.39698531 -0.3651832847 #> [224,] -0.30921665 -0.2972759065 #> [225,] -0.52131063  0.2124606967 #> [226,] -0.36680190 -0.2070260044 #> [227,] -0.26380540 -0.3439944395 #> [228,] -0.32806045 -0.2715405446 #> [229,] -0.25896594 -0.3476791473 #> [230,] -0.44976367 -0.0153936843 #> [231,]  0.65057197  0.4429096402 #> [232,] -0.23853876 -0.3604194982 #> [233,] -0.30275985 -0.3052426618 #> [234,]  0.30363270 -0.4719309545 #> [235,] -0.42534093 -0.0795641162 #> [236,] -0.45846478  0.0090866013 #> [237,]  0.60049933  0.2109475053 #> [238,] -0.49610100  0.1251204181 #> [239,] -0.54299504  0.2941290474 #> [240,] -0.42034484 -0.0918793689 #> [241,] -0.61927366  0.6349075104 #> [242,] -0.40188498 -0.1350329601 #> [243,] -0.36907960 -0.2027457945 #> [244,] -0.28356331 -0.3263468619 #> [245,]  0.30205507 -0.4729541209 #> [246,] -0.42986554 -0.0681749853 #> [247,] -0.52907328  0.2409839127 #> [248,]  0.53192141 -0.0422096547 #> [249,]  0.18733815 -0.4750168494 #> [250,] -0.48914719  0.1024126325 #> [251,]  0.28239534 -0.4835129463 #> [252,] -0.49705567  0.1282838703 #> [253,]  0.45228900 -0.2582413525 #> [254,]  0.46727915 -0.2233754484 #> [255,] -0.41157900 -0.1128302382 #> [256,] -0.39485190 -0.1505107194 #> [257,] -0.47484038  0.0575198587 #> [258,]  0.33534694 -0.4458591464 #> [259,]  0.49550629 -0.1505836578 #> [260,] -0.47947577  0.0717985896 #> [261,] -0.23931740 -0.3600181473 #> [262,] -0.37831715 -0.1848287198 #> [263,]  0.47821447 -0.1962981302 #> [264,]  0.49618248 -0.1487226246 #> [265,] -0.34988277 -0.2371230104 #> [266,] -0.44655588 -0.0242021540 #> [267,]  0.35023332 -0.4300136955 #> [268,] -0.60228856  0.5512279095 #> [269,]  0.35194221 -0.4280471702 #> [270,] -0.68023645  0.9785169545 #> [271,]  0.52585015 -0.0614566848 #> [272,] -0.58915245  0.4897239267 #> [273,]  0.57403128  0.1051084153 #> [274,] -0.45276051 -0.0070593614 #> [275,]  0.23088074 -0.4915543461 #> [276,] -0.41418865 -0.1066801359 #> [277,] -0.19189578 -0.3717978396 #> [278,]  0.61622773  0.2791149497 #> [279,]  0.72817822  0.9036844907 #> [280,] -0.29072925 -0.3189222126 #> [281,] -0.51824411  0.2014078191 #> [282,]  0.44988642 -0.2635909721 #> [283,] -0.54652230  0.3080083056 #> [284,]  0.34281543 -0.4381975749 #> [285,] -0.51578848  0.1926436409 #> [286,] -0.47975096  0.0726542434 #> [287,] -0.40705679 -0.1233134723 #> [288,] -0.45847254  0.0091088070 #> [289,] -0.52745884  0.2349871501 #> [290,] -0.33108955 -0.2670590233 #> [291,] -0.28129361 -0.3285853522 #> [292,] -0.49031180  0.1061748189 #> [293,]  0.40226631 -0.3564079037 #> [294,] -0.46565799  0.0299786942 #> [295,] -0.35114732 -0.2349767584 #> [296,] -0.24047138 -0.3594109327 #> [297,] -0.54213365  0.2907653427 #> [298,] -0.43937970 -0.0434889957 #> [299,] -0.38743530 -0.1662619326 #> [300,] -0.23207536 -0.3634897193 #>  #> $inv_hessian #>           [,1]      [,2] #> [1,] 4.4654436 0.2523231 #> [2,] 0.2523231 4.8551413 #>"},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_mean.html","id":null,"dir":"Reference","previous_headings":"","what":"PPI Mean Estimation â€” ppi_mean","title":"PPI Mean Estimation â€” ppi_mean","text":"Helper function PPI mean estimation","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PPI Mean Estimation â€” ppi_mean","text":"","code":"ppi_mean(Y_l, f_l, f_u, alpha = 0.05, alternative = \"two-sided\")"},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PPI Mean Estimation â€” ppi_mean","text":"Y_l (vector): n-vector labeled outcomes. f_l (vector): n-vector predictions labeled data. f_u (vector): N-vector predictions unlabeled data. alpha (scalar): type error rate hypothesis testing - values (0, 1); defaults 0.05. alternative (string): Alternative hypothesis. Must one \"two-sided\", \"less\", \"greater\".","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_mean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PPI Mean Estimation â€” ppi_mean","text":"tuple: Lower upper bounds prediction-powered confidence interval mean.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_mean.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PPI Mean Estimation â€” ppi_mean","text":"Prediction Powered Inference (Angelopoulos et al., 2023) https://www.science.org/doi/10.1126/science.adi6000","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_mean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PPI Mean Estimation â€” ppi_mean","text":"","code":"dat <- simdat(model = \"mean\")  form <- Y - f ~ 1  Y_l <- dat[dat$set_label == \"labeled\", all.vars(form)[1]] |>   matrix(ncol = 1)  f_l <- dat[dat$set_label == \"labeled\", all.vars(form)[2]] |>   matrix(ncol = 1)  f_u <- dat[dat$set_label == \"unlabeled\", all.vars(form)[2]] |>   matrix(ncol = 1)  ppi_mean(Y_l, f_l, f_u) #>          lower    upper #> [1,] 0.9546156 1.340257"},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_ols.html","id":null,"dir":"Reference","previous_headings":"","what":"PPI OLS â€” ppi_ols","title":"PPI OLS â€” ppi_ols","text":"Helper function prediction-powered inference OLS estimation","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_ols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PPI OLS â€” ppi_ols","text":"","code":"ppi_ols(X_l, Y_l, f_l, X_u, f_u, w_l = NULL, w_u = NULL)"},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_ols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PPI OLS â€” ppi_ols","text":"X_l (matrix): n x p matrix covariates labeled data. Y_l (vector): n-vector labeled outcomes. f_l (vector): n-vector predictions labeled data. X_u (matrix): N x p matrix covariates unlabeled data. f_u (vector): N-vector predictions unlabeled data. w_l (ndarray, optional): Sample weights labeled data set. Defaults vector ones. w_u (ndarray, optional): Sample weights unlabeled data set. Defaults vector ones.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_ols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PPI OLS â€” ppi_ols","text":"(list): list containing following: est (vector): vector PPI OLS regression coefficient estimates. se (vector): vector standard errors coefficients. rectifier_est (vector): vector rectifier OLS regression coefficient estimates.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_ols.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PPI OLS â€” ppi_ols","text":"Prediction Powered Inference (Angelopoulos et al., 2023) https://www.science.org/doi/10.1126/science.adi6000","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_ols.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PPI OLS â€” ppi_ols","text":"","code":"dat <- simdat()  form <- Y - f ~ X1  X_l <- model.matrix(form, data = dat[dat$set_label == \"labeled\", ])  Y_l <- dat[dat$set_label == \"labeled\", all.vars(form)[1]] |>    matrix(ncol = 1)  f_l <- dat[dat$set_label == \"labeled\", all.vars(form)[2]] |>    matrix(ncol = 1)  X_u <- model.matrix(form, data = dat[dat$set_label == \"unlabeled\", ])  f_u <- dat[dat$set_label == \"unlabeled\", all.vars(form)[2]] |>    matrix(ncol = 1)  ppi_ols(X_l, Y_l, f_l, X_u, f_u) #> $est #>                  [,1] #> (Intercept) 0.7606754 #> X1          0.7987879 #>  #> $se #> (Intercept)          X1  #>  0.10279409  0.09320508  #>  #> $rectifier_est #>                   [,1] #> (Intercept) 0.18486040 #> X1          0.08278839 #>"},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_logistic.html","id":null,"dir":"Reference","previous_headings":"","what":"PPI++ Logistic Regression â€” ppi_plusplus_logistic","title":"PPI++ Logistic Regression â€” ppi_plusplus_logistic","text":"Helper function PPI++ logistic regression","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_logistic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PPI++ Logistic Regression â€” ppi_plusplus_logistic","text":"","code":"ppi_plusplus_logistic(   X_l,   Y_l,   f_l,   X_u,   f_u,   lhat = NULL,   coord = NULL,   opts = NULL,   w_l = NULL,   w_u = NULL )"},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_logistic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PPI++ Logistic Regression â€” ppi_plusplus_logistic","text":"X_l (matrix): n x p matrix covariates labeled data. Y_l (vector): n-vector labeled outcomes. f_l (vector): n-vector predictions labeled data. X_u (matrix): N x p matrix covariates unlabeled data. f_u (vector): N-vector predictions unlabeled data. lhat (float, optional): Power-tuning parameter (see https://arxiv.org/abs/2311.01453). default value, NULL, estimate optimal value data. Setting lhat = 1 recovers PPI power tuning, setting lhat = 0 recovers classical point estimate. coord (int, optional): Coordinate optimize lhat = 1. NULL, optimizes total variance coordinates. Must (1, ..., d) d dimension estimand. opts (list, optional): Options pass optimizer. See ?optim details. w_l (ndarray, optional): Sample weights labeled data set. Defaults vector ones. w_u (ndarray, optional): Sample weights unlabeled data set. Defaults vector ones.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_logistic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PPI++ Logistic Regression â€” ppi_plusplus_logistic","text":"(list): list containing following: est (vector): vector PPI++ logistic regression coefficient estimates. se (vector): vector standard errors coefficients. lambda (float): estimated power-tuning parameter. rectifier_est (vector): vector rectifier logistic regression coefficient estimates. var_u (matrix): covariance matrix gradients unlabeled data. var_l (matrix): covariance matrix gradients labeled data. grads (matrix): matrix gradients labeled data. grads_hat_unlabeled (matrix): matrix predicted gradients unlabeled data. grads_hat (matrix): matrix predicted gradients labeled data. inv_hessian (matrix): inverse Hessian matrix.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_logistic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PPI++ Logistic Regression â€” ppi_plusplus_logistic","text":"PPI++: Efficient Prediction Powered Inference (Angelopoulos et al., 2023) https://arxiv.org/abs/2311.01453","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_logistic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PPI++ Logistic Regression â€” ppi_plusplus_logistic","text":"","code":"dat <- simdat(model = \"logistic\")  form <- Y - f ~ X1  X_l <- model.matrix(form, data = dat[dat$set_label == \"labeled\", ])  Y_l <- dat[dat$set_label == \"labeled\", all.vars(form)[1]] |>    matrix(ncol = 1)  f_l <- dat[dat$set_label == \"labeled\", all.vars(form)[2]] |>    matrix(ncol = 1)  X_u <- model.matrix(form, data = dat[dat$set_label == \"unlabeled\", ])  f_u <- dat[dat$set_label == \"unlabeled\", all.vars(form)[2]] |>    matrix(ncol = 1)  ppi_plusplus_logistic(X_l, Y_l, f_l, X_u, f_u) #> $est #>           [,1] #> [1,] 0.4865938 #> [2,] 0.7040716 #>  #> $se #> [1] 0.1268517 0.1347547 #>  #> $lambda #> [1] 0.081643 #>  #> $rectifier_est #>              [,1] #> [1,] -0.006157121 #> [2,] -0.006461035 #>  #> $var_u #>               [,1]          [,2] #> [1,]  0.0013050030 -0.0005640268 #> [2,] -0.0005640268  0.0011172474 #>  #> $var_l #>            [,1]       [,2] #> [1,]  0.2178305 -0.0413854 #> [2,] -0.0413854  0.1667002 #>  #> $grads #>               [,1]         [,2] #>   [1,]  0.64981379  0.121483408 #>   [2,] -0.34865053 -0.068525846 #>   [3,]  0.55159384 -0.218955189 #>   [4,] -0.67080193  1.141779389 #>   [5,] -0.29953318 -0.154400444 #>   [6,]  0.56397541 -0.183659285 #>   [7,]  0.54753800 -0.230087001 #>   [8,] -0.28019681 -0.181827539 #>   [9,] -0.36687570 -0.030769545 #>  [10,] -0.53069983  0.459451715 #>  [11,] -0.28516830 -0.175123236 #>  [12,]  0.41170112 -0.493249199 #>  [13,]  0.37593880 -0.530434067 #>  [14,]  0.50406934 -0.336715636 #>  [15,]  0.47235425 -0.400715374 #>  [16,]  0.62060624  0.004873018 #>  [17,] -0.21294580 -0.248209545 #>  [18,] -0.17319888 -0.264822150 #>  [19,] -0.47280342  0.253635917 #>  [20,]  0.58752019 -0.110875203 #>  [21,]  0.27273457 -0.568417965 #>  [22,] -0.55328453  0.550512664 #>  [23,]  0.44853982 -0.441592210 #>  [24,] -0.31170860 -0.135273833 #>  [25,] -0.34191820 -0.081665409 #>  [26,] -0.33408434 -0.096407560 #>  [27,]  0.73882457  0.580583978 #>  [28,] -0.38665732  0.013844019 #>  [29,] -0.14390616 -0.265018904 #>  [30,] -0.65956354  1.075376028 #>  [31,]  0.53629900 -0.259851493 #>  [32,]  0.36566398 -0.538810162 #>  [33,] -0.23376174 -0.232608103 #>  [34,] -0.38185370  0.002660886 #>  [35,]  0.70804096  0.401545717 #>  [36,] -0.40782411  0.065816400 #>  [37,]  0.38773758 -0.519551856 #>  [38,] -0.19255699 -0.258964580 #>  [39,]  0.49004503 -0.366395951 #>  [40,] -0.37440244 -0.014241907 #>  [41,] -0.37323324 -0.016845275 #>  [42,] -0.37737464 -0.007564277 #>  [43,]  0.47317933 -0.399190709 #>  [44,] -0.27284229 -0.191301755 #>  [45,] -0.27444274 -0.189285242 #>  [46,] -0.34057269 -0.084239323 #>  [47,] -0.45818541  0.207557627 #>  [48,]  0.15968778 -0.486986115 #>  [49,] -0.23638102 -0.230323878 #>  [50,] -0.37260416 -0.018240529 #>  [51,] -0.41869881  0.094243217 #>  [52,]  0.70125021  0.365195221 #>  [53,]  0.43045030 -0.468683339 #>  [54,] -0.44430724  0.165900673 #>  [55,] -0.18877292 -0.260450470 #>  [56,]  0.57769557 -0.142171872 #>  [57,] -0.50369016  0.358667240 #>  [58,] -0.14569671 -0.265324239 #>  [59,] -0.39765028  0.040285390 #>  [60,]  0.38480410 -0.522384106 #>  [61,] -0.36688923 -0.030740320 #>  [62,] -0.30050342 -0.152928717 #>  [63,]  0.38868949 -0.518614730 #>  [64,]  0.49317236 -0.359969437 #>  [65,] -0.11389706 -0.253159685 #>  [66,] -0.51348100  0.394210375 #>  [67,]  0.41565022 -0.488368515 #>  [68,] -0.26336085 -0.202729518 #>  [69,] -0.49157438  0.316201073 #>  [70,] -0.24103058 -0.226095128 #>  [71,] -0.20686027 -0.251897877 #>  [72,] -0.25371565 -0.213437745 #>  [73,]  0.50809014 -0.327793344 #>  [74,] -0.18238363 -0.262586825 #>  [75,] -0.39308637  0.029163980 #>  [76,]  0.58836060 -0.108134954 #>  [77,]  0.42479247 -0.476469698 #>  [78,]  0.71688530  0.450522602 #>  [79,] -0.14631699 -0.265420010 #>  [80,]  0.61443605 -0.017973930 #>  [81,] -0.21262401 -0.248414606 #>  [82,] -0.39866588  0.042788108 #>  [83,] -0.29954920 -0.154376221 #>  [84,] -0.36067404 -0.043976254 #>  [85,]  0.44982345 -0.439541324 #>  [86,]  0.42796296 -0.472146417 #>  [87,] -0.08646345 -0.229768931 #>  [88,] -0.39857539  0.042564691 #>  [89,]  0.71846942  0.459496369 #>  [90,]  0.68034657  0.259714369 #>  [91,] -0.25121153 -0.216065383 #>  [92,] -0.26292888 -0.203228951 #>  [93,] -0.33851627 -0.088139620 #>  [94,]  0.51939225 -0.301708065 #>  [95,] -0.58056018  0.669280865 #>  [96,] -0.44273106  0.161296392 #>  [97,]  0.65693971  0.152174527 #>  [98,]  0.66275415  0.177907030 #>  [99,] -0.41407472  0.082011373 #> [100,] -0.55265216  0.547875426 #> [101,] -0.12503347 -0.259100241 #> [102,] -0.56034047  0.580289531 #> [103,] -0.27401322 -0.189828891 #> [104,] -0.38694108  0.014511677 #> [105,] -0.59808372  0.750995038 #> [106,] -0.17385918 -0.264694851 #> [107,]  0.74647724  0.629052748 #> [108,]  0.61408899 -0.019241304 #> [109,]  0.47986005 -0.386573298 #> [110,]  0.72259351  0.483153554 #> [111,]  0.74094662  0.593855268 #> [112,]  0.52849703 -0.279596054 #> [113,] -0.11032917 -0.250846303 #> [114,]  0.69875228  0.352089213 #> [115,] -0.32233253 -0.117419275 #> [116,]  0.47353305 -0.398534817 #> [117,]  0.54100271 -0.247586392 #> [118,] -0.33841607 -0.088328625 #> [119,] -0.32344829 -0.115481251 #> [120,] -0.53239410  0.466063600 #> [121,] -0.43629188  0.142752507 #> [122,] -0.65468810  1.047305767 #> [123,]  0.59608577 -0.082471427 #> [124,] -0.21559247 -0.246480706 #> [125,]  0.59897741 -0.072642164 #> [126,]  0.64683064  0.108905436 #> [127,]  0.66842766  0.203629801 #> [128,] -0.20369820 -0.253655114 #> [129,]  0.24268172 -0.559981640 #> [130,]  0.50257979 -0.339973891 #> [131,]  0.86212376  1.648703378 #> [132,] -0.11388179 -0.253150218 #> [133,]  0.35985977 -0.543091029 #> [134,]  0.80482131  1.063205913 #> [135,] -0.58463148  0.687876332 #> [136,] -0.60770828  0.797780248 #> [137,] -0.25103346 -0.216249836 #> [138,]  0.51091890 -0.321404414 #> [139,] -0.36251580 -0.040092858 #> [140,] -0.42213669  0.103476302 #> [141,] -0.27057984 -0.194109336 #> [142,]  0.72790129  0.514241716 #> [143,] -0.24983776 -0.217480078 #> [144,] -0.33919524 -0.086856331 #> [145,] -0.51551722  0.401742273 #> [146,]  0.32901680 -0.560406785 #> [147,] -0.38961974  0.020852987 #> [148,] -0.15203039 -0.266062943 #> [149,]  0.54470045 -0.237750969 #> [150,] -0.50778685  0.373404410 #> [151,] -0.37879876 -0.004334323 #> [152,] -0.18648518 -0.261269500 #> [153,] -0.17875979 -0.263587726 #> [154,] -0.41962409  0.096716528 #> [155,]  0.48234777 -0.381750449 #> [156,] -0.36991803 -0.024155018 #> [157,] -0.14367857 -0.264977007 #> [158,] -0.35308189 -0.059639648 #> [159,] -0.33434752 -0.095921850 #> [160,] -0.43918904  0.151043120 #> [161,] -0.41833563  0.093274759 #> [162,]  0.80485517  1.063497083 #> [163,] -0.22866073 -0.236852544 #> [164,] -0.29594209 -0.159768508 #> [165,] -0.41778245  0.091802201 #> [166,] -0.27362095 -0.190323819 #> [167,]  0.48224806 -0.381945043 #> [168,] -0.31011931 -0.137851532 #> [169,]  0.31979636 -0.563811579 #> [170,]  0.65440178  0.141138265 #> [171,] -0.60995549  0.808904898 #> [172,]  0.68610723  0.287851823 #> [173,]  0.75741641  0.701370499 #> [174,] -0.29598632 -0.159703164 #> [175,]  0.82147547  1.213165834 #> [176,]  0.56106903 -0.192124283 #> [177,]  0.68121545  0.263914459 #> [178,] -0.23053175 -0.235327127 #> [179,]  0.71561434  0.443367731 #> [180,]  0.80844196  1.094643315 #> [181,] -0.59137209  0.719178308 #> [182,] -0.39792899  0.040971211 #> [183,]  0.38585442 -0.521379686 #> [184,] -0.31714229 -0.126277423 #> [185,] -0.24464094 -0.222658922 #> [186,]  0.58984631 -0.103266010 #> [187,]  0.53023581 -0.275259894 #> [188,] -0.13917820 -0.264004182 #> [189,] -0.44141153  0.157461569 #> [190,]  0.45128365 -0.437187439 #> [191,]  0.41728440 -0.486303226 #> [192,] -0.68369222  1.220990787 #> [193,] -0.57458088  0.642387764 #> [194,] -0.38928001  0.020044848 #> [195,] -0.10214638 -0.244750087 #> [196,] -0.25895505 -0.207736216 #> [197,]  0.49090436 -0.364640956 #> [198,] -0.52899202  0.452822300 #> [199,]  0.74025318  0.589504409 #> [200,]  0.70331693  0.376145698 #> [201,] -0.39554593  0.035132056 #> [202,] -0.67618080  1.174426673 #> [203,] -0.54321127  0.509109327 #> [204,]  0.55609332 -0.206359164 #> [205,] -0.22095903 -0.242745411 #> [206,]  0.74677383  0.630965518 #> [207,] -0.22268499 -0.241479106 #> [208,] -0.24428575 -0.223002865 #> [209,]  0.49154819 -0.363320678 #> [210,]  0.65562502  0.146442876 #> [211,] -0.34723896 -0.071316877 #> [212,] -0.47622592  0.264755847 #> [213,] -0.54508522  0.516714410 #> [214,] -0.34018333 -0.084980904 #> [215,] -0.44525458  0.168680375 #> [216,] -0.68736814  1.244202561 #> [217,]  0.37170464 -0.534009535 #> [218,]  0.25347506 -0.564053298 #> [219,] -0.72551104  1.502973046 #> [220,]  0.51967954 -0.301025454 #> [221,]  0.51476583 -0.312566552 #> [222,] -0.69638565  1.302364973 #> [223,] -0.24794139 -0.219401600 #> [224,] -0.15160669 -0.266029952 #> [225,]  0.60752569 -0.042859366 #> [226,]  0.73923852  0.583162782 #> [227,] -0.28792610 -0.171300248 #> [228,]  0.73639832  0.565565573 #> [229,] -0.19928784 -0.255922252 #> [230,] -0.40721240  0.064252372 #> [231,] -0.39031313  0.022505928 #> [232,]  0.58426208 -0.121403963 #> [233,] -0.36733815 -0.029769869 #> [234,]  0.43240209 -0.465921835 #> [235,]  0.25394992 -0.564205413 #> [236,]  0.31962163 -0.563868226 #> [237,] -0.47075024  0.247025812 #> [238,] -0.31391648 -0.131652536 #> [239,]  0.52782987 -0.281250090 #> [240,]  0.47776262 -0.390586886 #> [241,] -0.36548763 -0.033757718 #> [242,] -0.31066969 -0.136961609 #> [243,]  0.50968035 -0.324213179 #> [244,]  0.52658856 -0.284313290 #> [245,]  0.72355183  0.488712630 #> [246,]  0.69363076  0.325653024 #> [247,] -0.30596844 -0.144469194 #> [248,]  0.55923755 -0.197401520 #> [249,] -0.27324921 -0.190791434 #> [250,]  0.62855486  0.035199335 #> [251,]  0.71570287  0.443864855 #> [252,] -0.35042070 -0.064998759 #> [253,]  0.56657504 -0.175992939 #> [254,] -0.26510535 -0.200693718 #> [255,]  0.33138567 -0.559400397 #> [256,]  0.40757479 -0.498182855 #> [257,] -0.43466018  0.138121047 #> [258,]  0.51394173 -0.314474376 #> [259,] -0.12498879 -0.259080167 #> [260,] -0.50399080  0.359742197 #> [261,] -0.42263219  0.104816874 #> [262,] -0.54295223  0.508061553 #> [263,] -0.52616695  0.441933272 #> [264,] -0.22534902 -0.239462867 #> [265,]  0.53042433 -0.274787562 #> [266,]  0.57791630 -0.141483497 #> [267,] -0.41713013  0.090069666 #> [268,] -0.35535691 -0.055004221 #> [269,] -0.39034161  0.022573915 #> [270,] -0.53610961  0.480686160 #> [271,] -0.40568818  0.060371377 #> [272,]  0.51506095 -0.311881418 #> [273,] -0.36928737 -0.025533521 #> [274,] -0.36262860 -0.039853953 #> [275,] -0.27285122 -0.191290564 #> [276,]  0.48524828 -0.376041440 #> [277,]  0.62867610  0.035669867 #> [278,] -0.42543499  0.112446438 #> [279,] -0.13453565 -0.262708237 #> [280,] -0.42575751  0.113329488 #> [281,]  0.39795080 -0.509033893 #> [282,] -0.57319830  0.636239157 #> [283,]  0.49055524 -0.365354955 #> [284,] -0.45658854  0.202661665 #> [285,]  0.40676747 -0.499128342 #> [286,] -0.41088569  0.073700151 #> [287,]  0.38936244 -0.517946886 #> [288,] -0.49028842  0.311790725 #> [289,] -0.45337911  0.192902835 #> [290,] -0.29528596 -0.160735829 #> [291,] -0.50200962  0.352677462 #> [292,] -0.26626540 -0.199323247 #> [293,] -0.48481313  0.293218511 #> [294,] -0.13982851 -0.264161855 #> [295,] -0.55319116  0.550122950 #> [296,]  0.39246739 -0.514808090 #> [297,] -0.09351397 -0.237064475 #> [298,] -0.16823942 -0.265610292 #> [299,] -0.61397328  0.828987703 #> [300,]  0.36558493 -0.538870648 #>  #> $grads_hat_unlabeled #>               [,1]          [,2] #>   [1,]  0.78114738  0.8717910571 #>   [2,]  0.36319112 -0.5406737221 #>   [3,] -0.38258628  0.0043518486 #>   [4,]  0.68812850  0.2978887822 #>   [5,] -0.14724436 -0.2655536387 #>   [6,]  0.44135589 -0.4527542750 #>   [7,] -0.33089892 -0.1022337770 #>   [8,] -0.25424883 -0.2128701149 #>   [9,]  0.33903353 -0.5557840624 #>  [10,] -0.29065159 -0.1674493726 #>  [11,] -0.65680298  1.0594284916 #>  [12,] -0.63219340  0.9232603850 #>  [13,] -0.31667260 -0.1270662840 #>  [14,] -0.28986663 -0.1685658504 #>  [15,] -0.48650959  0.2989373646 #>  [16,] -0.14501763 -0.2652134986 #>  [17,]  0.49846424 -0.3488447661 #>  [18,] -0.22188969 -0.2420665159 #>  [19,]  0.67481590  0.2333385516 #>  [20,]  0.61015837 -0.0334650368 #>  [21,]  0.36740728 -0.5374609276 #>  [22,] -0.33173011 -0.1007229015 #>  [23,] -0.34896557 -0.0679003232 #>  [24,] -0.44345201  0.1633992109 #>  [25,]  0.55198746 -0.2178636740 #>  [26,] -0.28115053 -0.1805601185 #>  [27,] -0.57068214  0.6251159409 #>  [28,]  0.62139175  0.0078247413 #>  [29,]  0.49006108 -0.3663632396 #>  [30,]  0.57654514 -0.1457488054 #>  [31,] -0.43383766  0.1357966931 #>  [32,] -0.10443327 -0.2465671743 #>  [33,]  0.37265445 -0.5332225874 #>  [34,] -0.49046908  0.3124092046 #>  [35,]  0.50537553 -0.3338375423 #>  [36,]  0.37660016 -0.5298598913 #>  [37,] -0.29400192 -0.1626167944 #>  [38,]  0.40652201 -0.4994145167 #>  [39,] -0.12680495 -0.2598723853 #>  [40,] -0.36278426 -0.0395240758 #>  [41,] -0.25515988 -0.2118935919 #>  [42,] -0.35664888 -0.0523496432 #>  [43,] -0.53402740  0.4724706918 #>  [44,] -0.20310542 -0.2539723273 #>  [45,] -0.47399884  0.2575054934 #>  [46,] -0.30371346 -0.1479946725 #>  [47,] -0.41685345  0.0893361139 #>  [48,] -0.66274322  1.0939203594 #>  [49,] -0.69348242  1.2834468202 #>  [50,] -0.30543822 -0.1453025588 #>  [51,] -0.30882461 -0.1399334521 #>  [52,]  0.30502612 -0.5675640842 #>  [53,] -0.50771923  0.3731595983 #>  [54,] -0.20862279 -0.2508709804 #>  [55,] -0.30774262 -0.1416609418 #>  [56,]  0.65305561  0.1353319638 #>  [57,]  0.61043096 -0.0324862701 #>  [58,] -0.29673195 -0.1585985064 #>  [59,] -0.59944728  0.7575395361 #>  [60,] -0.40994145  0.0712587405 #>  [61,] -0.08242722 -0.2251558889 #>  [62,]  0.15351001 -0.4783457339 #>  [63,]  0.41866911 -0.4845322647 #>  [64,] -0.46675016  0.2342780304 #>  [65,] -0.34798904 -0.0698361571 #>  [66,] -0.32073259 -0.1201774645 #>  [67,] -0.28188470 -0.1795784027 #>  [68,]  0.63867242  0.0753020589 #>  [69,] -0.24447191 -0.2228227624 #>  [70,] -0.28912873 -0.1696099402 #>  [71,] -0.30692905 -0.1429524627 #>  [72,] -0.29664424 -0.1587287359 #>  [73,] -0.50564155  0.3656629962 #>  [74,] -0.59552805  0.7388024976 #>  [75,] -0.48907527  0.3076470073 #>  [76,]  0.63816229  0.0732389294 #>  [77,] -0.57550854  0.6465278516 #>  [78,] -0.31828601 -0.1243476565 #>  [79,] -0.32256348 -0.1170191058 #>  [80,] -0.19586746 -0.2575317419 #>  [81,] -0.33176587 -0.1006577407 #>  [82,] -0.17551510 -0.2643526792 #>  [83,]  0.57938077 -0.1368992487 #>  [84,]  0.61331081 -0.0220762510 #>  [85,]  0.28833435 -0.5692718793 #>  [86,]  0.54347714 -0.2410237569 #>  [87,] -0.13320048 -0.2622795970 #>  [88,] -0.18565955 -0.2615503129 #>  [89,] -0.35566344 -0.0543758618 #>  [90,]  0.59157672 -0.0975552933 #>  [91,] -0.22974691 -0.2359714365 #>  [92,]  0.39635761 -0.5107420253 #>  [93,] -0.43243477  0.1318482550 #>  [94,] -0.28091783 -0.1808701758 #>  [95,] -0.39952138  0.0449041668 #>  [96,] -0.68865110  1.2523708916 #>  [97,]  0.66456997  0.1860729150 #>  [98,] -0.37732048 -0.0076867297 #>  [99,] -0.56029533  0.5800969833 #> [100,] -0.39275756  0.0283706267 #> [101,]  0.55316466 -0.2145873974 #> [102,] -0.64075796  0.9694566627 #> [103,] -0.24563191 -0.2216925187 #> [104,] -0.46367424  0.2245919407 #> [105,] -0.25408549 -0.2130443127 #> [106,] -0.41943759  0.0962173127 #> [107,]  0.60746364 -0.0430795155 #> [108,] -0.34451414 -0.0766504104 #> [109,] -0.55013001  0.5374081406 #> [110,] -0.39507968  0.0339961398 #> [111,]  0.51334126 -0.3158594758 #> [112,]  0.48703882 -0.3724707935 #> [113,] -0.19946487 -0.2558353997 #> [114,] -0.52415202  0.4342255440 #> [115,] -0.19000968 -0.2599827601 #> [116,]  0.57069555 -0.1636564453 #> [117,]  0.29460351 -0.5689467920 #> [118,]  0.68234919  0.2694181400 #> [119,] -0.22777343 -0.2375631762 #> [120,]  0.48103926 -0.3842956675 #> [121,] -0.45700461  0.2039347172 #> [122,]  0.66286210  0.1783907430 #> [123,] -0.34718260 -0.0714279119 #> [124,] -0.20667188 -0.2520056302 #> [125,]  0.70048902  0.3611865432 #> [126,]  0.54979043 -0.2239307657 #> [127,] -0.21467333 -0.2470896270 #> [128,] -0.45190184  0.1884472474 #> [129,]  0.56249587 -0.1879824508 #> [130,]  0.74566685  0.6238394309 #> [131,] -0.17233183 -0.2649813635 #> [132,] -0.54231174  0.5054744188 #> [133,]  0.36966299 -0.5356715322 #> [134,] -0.53536511  0.4777425943 #> [135,]  0.77259786  0.8081219173 #> [136,]  0.41657863 -0.4871984634 #> [137,]  0.47515388 -0.3955120159 #> [138,] -0.49099157  0.3141999629 #> [139,] -0.49613894  0.3320052651 #> [140,]  0.29073956 -0.5691922700 #> [141,] -0.29720040 -0.1579017532 #> [142,] -0.10940435 -0.2502130693 #> [143,] -0.32094076 -0.1198199777 #> [144,] -0.57845638  0.6597623608 #> [145,] -0.58883295  0.7073110710 #> [146,] -0.18746867 -0.2609247624 #> [147,] -0.46694702  0.2349013833 #> [148,] -0.34630979 -0.0731436236 #> [149,] -0.47789452  0.2702233582 #> [150,] -0.55909699  0.5749948732 #> [151,] -0.33686301 -0.0912458628 #> [152,] -0.32105038 -0.1196315666 #> [153,] -0.43942509  0.1517223993 #> [154,] -0.18180283 -0.2627575793 #> [155,] -0.62452376  0.8829264071 #> [156,]  0.61445150 -0.0179174668 #> [157,] -0.36972788 -0.0245710603 #> [158,]  0.40565232 -0.5004236950 #> [159,]  0.51221299 -0.3184506781 #> [160,] -0.13504522 -0.2628651946 #> [161,]  0.51733448 -0.3065689084 #> [162,] -0.54384135  0.5116614875 #> [163,] -0.33233435 -0.0996203792 #> [164,]  0.64209876  0.0892747655 #> [165,]  0.23408846 -0.5558906982 #> [166,]  0.29240526 -0.5691042072 #> [167,]  0.39659669 -0.5104872927 #> [168,]  0.56228744 -0.1885891580 #> [169,] -0.34394419 -0.0777570063 #> [170,]  0.41490491 -0.4893015747 #> [171,]  0.46889335 -0.4070308133 #> [172,] -0.27432440 -0.1894352048 #> [173,] -0.42323683  0.1064560643 #> [174,] -0.25472848 -0.2123570347 #> [175,] -0.38653526  0.0135570579 #> [176,] -0.11956676 -0.2564217553 #> [177,] -0.27708141 -0.1859056429 #> [178,] -0.63409077  0.9333880740 #> [179,] -0.55731405  0.5674384849 #> [180,] -0.48903315  0.3075034450 #> [181,] -0.63683867  0.9481626357 #> [182,] -0.43318686  0.1339625107 #> [183,] -0.54124081  0.5011600486 #> [184,] -0.66044105  1.0804749274 #> [185,] -0.48696773  0.3004872582 #> [186,]  0.51023365 -0.3229606198 #> [187,]  0.37414724 -0.5319681198 #> [188,]  0.57158590 -0.1609607768 #> [189,] -0.47405175  0.2576771255 #> [190,] -0.24435361 -0.2229372564 #> [191,] -0.53638249  0.4817667757 #> [192,] -0.47216037  0.2515607676 #> [193,]  0.45200497 -0.4360164286 #> [194,]  0.62565473  0.0240162203 #> [195,] -0.42117672  0.1008861464 #> [196,] -0.57861084  0.6604591281 #> [197,] -0.29185768 -0.1657222308 #> [198,] -0.13584513 -0.2631042242 #> [199,]  0.43892878 -0.4564048885 #> [200,] -0.12703769 -0.2599703936 #> [201,] -0.38033407 -0.0008301041 #> [202,] -0.28746981 -0.1719378858 #> [203,] -0.50317276  0.3568196809 #> [204,] -0.48357775  0.2890739676 #> [205,]  0.55277525 -0.2156731403 #> [206,] -0.25415452 -0.2129707278 #> [207,]  0.49989777 -0.3457767278 #> [208,]  0.51220515 -0.3184686344 #> [209,] -0.44242687  0.1604107590 #> [210,]  0.49711599 -0.3517090658 #> [211,]  0.53959966 -0.2512735948 #> [212,] -0.33067426 -0.1026410208 #> [213,] -0.75320612  1.7142032468 #> [214,] -0.34351779 -0.0785828691 #> [215,] -0.33281992 -0.0987318611 #> [216,]  0.65949695  0.1634144385 #> [217,]  0.59211397 -0.0957735054 #> [218,] -0.51669601  0.4061247973 #> [219,]  0.62636895  0.0267575967 #> [220,] -0.42970363  0.1242189241 #> [221,] -0.52627099  0.4423325816 #> [222,] -0.21221843 -0.2486714809 #> [223,] -0.11427178 -0.2533908325 #> [224,] -0.69711588  1.3071525052 #> [225,] -0.27098945 -0.1936047670 #> [226,] -0.51586000  0.4030150010 #> [227,] -0.41077458  0.0734124153 #> [228,] -0.22078711 -0.2428698253 #> [229,] -0.47229416  0.2519921287 #> [230,] -0.31311519 -0.1329722168 #> [231,]  0.74112100  0.5949515095 #> [232,] -0.44933497  0.1807596366 #> [233,] -0.20584191 -0.2524757546 #> [234,] -0.24105965 -0.2260679907 #> [235,]  0.50385759 -0.3371803496 #> [236,] -0.32229741 -0.1174800937 #> [237,] -0.44478351  0.1672969880 #> [238,] -0.76020150  1.7711523237 #> [239,] -0.30540808 -0.1453498458 #> [240,] -0.22946154 -0.2362041204 #> [241,]  0.39440897 -0.5127973264 #> [242,] -0.38772814  0.0163676294 #> [243,]  0.63175868  0.0477137311 #> [244,] -0.27461863 -0.1890620829 #> [245,] -0.39099590  0.0241381395 #> [246,] -0.27707300 -0.1859165249 #> [247,] -0.28405803 -0.1766414175 #> [248,] -0.57279205  0.6344374055 #> [249,] -0.54996915  0.5367432750 #> [250,] -0.54851854  0.5307627798 #> [251,] -0.23947934 -0.2275306322 #> [252,]  0.73605023  0.5634243873 #> [253,]  0.59983628 -0.0696990012 #> [254,] -0.39780097  0.0406560982 #> [255,]  0.48129007 -0.3838092490 #> [256,] -0.71677975  1.4406800490 #> [257,] -0.29353683 -0.1632941678 #> [258,] -0.38439508  0.0085493604 #> [259,] -0.33763005 -0.0898079646 #> [260,]  0.63937143  0.0781363411 #> [261,]  0.46611487 -0.4120078675 #> [262,] -0.43415420  0.1366903791 #> [263,]  0.48951157 -0.3674812707 #> [264,] -0.34281865 -0.0799331812 #> [265,] -0.35293470 -0.0599378392 #> [266,] -0.45492636  0.1975939991 #> [267,] -0.60901748  0.8042519832 #> [268,] -0.31491435 -0.1300004880 #> [269,] -0.45138805  0.1869029860 #> [270,] -0.26846798 -0.1966844651 #> [271,] -0.29601659 -0.1596584144 #> [272,]  0.64122581  0.0856957338 #> [273,] -0.41820287  0.0929210620 #> [274,] -0.28278773 -0.1783636700 #> [275,] -0.39453418  0.0326698533 #> [276,]  0.26571521 -0.5672539432 #> [277,] -0.49862680  0.3407179681 #> [278,]  0.67393993  0.2292173040 #> [279,]  0.56550373 -0.1791631221 #> [280,] -0.19609114 -0.2574304854 #> [281,] -0.55282113  0.5485795940 #> [282,]  0.43694541 -0.4593431022 #> [283,] -0.37648006 -0.0095831511 #> [284,] -0.20633261 -0.2521987182 #> [285,]  0.66453525  0.1859161890 #> [286,] -0.46634919  0.2330096326 #> [287,] -0.36913187 -0.0258728215 #> [288,] -0.57678462  0.6522422359 #> [289,] -0.28716929 -0.1723567492 #> [290,] -0.32740706 -0.1085087103 #> [291,] -0.53563721  0.4788176147 #> [292,] -0.23563671 -0.2309801729 #> [293,] -0.07721231 -0.2186998766 #> [294,]  0.65443669  0.1412892605 #> [295,] -0.59865474  0.7537323352 #> [296,]  0.60001493 -0.0690854607 #> [297,] -0.25516262 -0.2118906508 #> [298,] -0.25169724 -0.2155606547 #> [299,]  0.57409621 -0.1533025729 #> [300,] -0.26330764 -0.2027911363 #>  #> $grads_hat #>               [,1]         [,2] #>   [1,] -0.35018621 -0.065467702 #>   [2,] -0.34865053 -0.068525846 #>   [3,]  0.55159384 -0.218955189 #>   [4,] -0.67080193  1.141779389 #>   [5,] -0.29953318 -0.154400444 #>   [6,] -0.43602459  0.141991943 #>   [7,]  0.54753800 -0.230087001 #>   [8,] -0.28019681 -0.181827539 #>   [9,] -0.36687570 -0.030769545 #>  [10,] -0.53069983  0.459451715 #>  [11,] -0.28516830 -0.175123236 #>  [12,]  0.41170112 -0.493249199 #>  [13,] -0.62406120  0.880524506 #>  [14,] -0.49593066  0.331279047 #>  [15,]  0.47235425 -0.400715374 #>  [16,]  0.62060624  0.004873018 #>  [17,] -0.21294580 -0.248209545 #>  [18,] -0.17319888 -0.264822150 #>  [19,] -0.47280342  0.253635917 #>  [20,]  0.58752019 -0.110875203 #>  [21,]  0.27273457 -0.568417965 #>  [22,]  0.44671547 -0.444477496 #>  [23,] -0.55146018  0.542918403 #>  [24,] -0.31170860 -0.135273833 #>  [25,]  0.65808180  0.157179463 #>  [26,] -0.33408434 -0.096407560 #>  [27,]  0.73882457  0.580583978 #>  [28,] -0.38665732  0.013844019 #>  [29,] -0.14390616 -0.265018904 #>  [30,] -0.65956354  1.075376028 #>  [31,] -0.46370100  0.224675780 #>  [32,]  0.36566398 -0.538810162 #>  [33,] -0.23376174 -0.232608103 #>  [34,] -0.38185370  0.002660886 #>  [35,] -0.29195904 -0.165576440 #>  [36,] -0.40782411  0.065816400 #>  [37,] -0.61226242  0.820405591 #>  [38,] -0.19255699 -0.258964580 #>  [39,] -0.50995497  0.381282181 #>  [40,]  0.62559756  0.023797126 #>  [41,] -0.37323324 -0.016845275 #>  [42,]  0.62262536  0.012480199 #>  [43,]  0.47317933 -0.399190709 #>  [44,]  0.72715771  0.509842328 #>  [45,] -0.27444274 -0.189285242 #>  [46,] -0.34057269 -0.084239323 #>  [47,] -0.45818541  0.207557627 #>  [48,] -0.84031222  2.562627966 #>  [49,] -0.23638102 -0.230323878 #>  [50,] -0.37260416 -0.018240529 #>  [51,]  0.58130119 -0.130842726 #>  [52,] -0.29874979 -0.155582121 #>  [53,]  0.43045030 -0.468683339 #>  [54,] -0.44430724  0.165900673 #>  [55,] -0.18877292 -0.260450470 #>  [56,] -0.42230443  0.103929847 #>  [57,] -0.50369016  0.358667240 #>  [58,] -0.14569671 -0.265324239 #>  [59,] -0.39765028  0.040285390 #>  [60,] -0.61519590  0.835148469 #>  [61,] -0.36688923 -0.030740320 #>  [62,]  0.69949658  0.355979698 #>  [63,] -0.61131051  0.815650136 #>  [64,]  0.49317236 -0.359969437 #>  [65,] -0.11389706 -0.253159685 #>  [66,] -0.51348100  0.394210375 #>  [67,] -0.58434978  0.686582168 #>  [68,] -0.26336085 -0.202729518 #>  [69,]  0.50842562 -0.327040492 #>  [70,] -0.24103058 -0.226095128 #>  [71,] -0.20686027 -0.251897877 #>  [72,] -0.25371565 -0.213437745 #>  [73,]  0.50809014 -0.327793344 #>  [74,] -0.18238363 -0.262586825 #>  [75,] -0.39308637  0.029163980 #>  [76,] -0.41163940  0.075655318 #>  [77,]  0.42479247 -0.476469698 #>  [78,]  0.71688530  0.450522602 #>  [79,] -0.14631699 -0.265420010 #>  [80,] -0.38556395  0.011278797 #>  [81,] -0.21262401 -0.248414606 #>  [82,] -0.39866588  0.042788108 #>  [83,] -0.29954920 -0.154376221 #>  [84,] -0.36067404 -0.043976254 #>  [85,]  0.44982345 -0.439541324 #>  [86,]  0.42796296 -0.472146417 #>  [87,] -0.08646345 -0.229768931 #>  [88,] -0.39857539  0.042564691 #>  [89,] -0.28153058 -0.180052586 #>  [90,] -0.31965343 -0.122023970 #>  [91,] -0.25121153 -0.216065383 #>  [92,] -0.26292888 -0.203228951 #>  [93,]  0.66148373  0.172230789 #>  [94,] -0.48060775  0.279178658 #>  [95,] -0.58056018  0.669280865 #>  [96,]  0.55726894 -0.203024990 #>  [97,]  0.65693971  0.152174527 #>  [98,]  0.66275415  0.177907030 #>  [99,]  0.58592528 -0.116047985 #> [100,]  0.44734784 -0.443481287 #> [101,] -0.12503347 -0.259100241 #> [102,] -0.56034047  0.580289531 #> [103,] -0.27401322 -0.189828891 #> [104,] -0.38694108  0.014511677 #> [105,] -0.59808372  0.750995038 #> [106,] -0.17385918 -0.264694851 #> [107,] -0.25352276 -0.213642394 #> [108,] -0.38591101  0.012091783 #> [109,] -0.52013995  0.419022628 #> [110,]  0.72259351  0.483153554 #> [111,]  0.74094662  0.593855268 #> [112,] -0.47150297  0.249443921 #> [113,] -0.11032917 -0.250846303 #> [114,] -0.30124772 -0.151793529 #> [115,]  0.67766747  0.246860662 #> [116,] -0.52646695  0.443085042 #> [117,] -0.45899729  0.210057143 #> [118,] -0.33841607 -0.088328625 #> [119,]  0.67655171  0.241550314 #> [120,]  0.46760590 -0.409347298 #> [121,]  0.56370812 -0.184442457 #> [122,] -0.65468810  1.047305767 #> [123,] -0.40391423  0.055883541 #> [124,] -0.21559247 -0.246480706 #> [125,] -0.40102259  0.048634803 #> [126,] -0.35316936 -0.059462340 #> [127,] -0.33157234 -0.101010195 #> [128,] -0.20369820 -0.253655114 #> [129,]  0.24268172 -0.559981640 #> [130,]  0.50257979 -0.339973891 #> [131,] -0.13787624 -0.263670990 #> [132,] -0.11388179 -0.253150218 #> [133,] -0.64014023  0.966083019 #> [134,]  0.80482131  1.063205913 #> [135,]  0.41536852 -0.488721838 #> [136,]  0.39229172 -0.514988193 #> [137,]  0.74896654  0.645188462 #> [138,] -0.48908110  0.307666876 #> [139,] -0.36251580 -0.040092858 #> [140,]  0.57786331 -0.141648806 #> [141,] -0.27057984 -0.194109336 #> [142,] -0.27209871 -0.192230059 #> [143,] -0.24983776 -0.217480078 #> [144,] -0.33919524 -0.086856331 #> [145,]  0.48448278 -0.377557155 #> [146,]  0.32901680 -0.560406785 #> [147,] -0.38961974  0.020852987 #> [148,] -0.15203039 -0.266062943 #> [149,]  0.54470045 -0.237750969 #> [150,]  0.49221315 -0.361952190 #> [151,] -0.37879876 -0.004334323 #> [152,] -0.18648518 -0.261269500 #> [153,] -0.17875979 -0.263587726 #> [154,]  0.58037591 -0.133767210 #> [155,] -0.51765223  0.409691902 #> [156,]  0.63008197  0.041143281 #> [157,] -0.14367857 -0.264977007 #> [158,]  0.64691811  0.109272012 #> [159,] -0.33434752 -0.095921850 #> [160,] -0.43918904  0.151043120 #> [161,]  0.58166437 -0.129691569 #> [162,]  0.80485517  1.063497083 #> [163,] -0.22866073 -0.236852544 #> [164,] -0.29594209 -0.159768508 #> [165,]  0.58221755 -0.127934652 #> [166,] -0.27362095 -0.190323819 #> [167,]  0.48224806 -0.381945043 #> [168,] -0.31011931 -0.137851532 #> [169,]  0.31979636 -0.563811579 #> [170,] -0.34559822 -0.074536980 #> [171,] -0.60995549  0.808904898 #> [172,] -0.31389277 -0.131691671 #> [173,] -0.24258359 -0.224633333 #> [174,]  0.70401368  0.379859496 #> [175,] -0.17852453 -0.263647377 #> [176,]  0.56106903 -0.192124283 #> [177,] -0.31878455 -0.123502561 #> [178,] -0.23053175 -0.235327127 #> [179,] -0.28438566 -0.176194660 #> [180,] -0.19155804 -0.259372646 #> [181,] -0.59137209  0.719178308 #> [182,]  0.60207101 -0.061989900 #> [183,] -0.61414558  0.829854507 #> [184,] -0.31714229 -0.126277423 #> [185,] -0.24464094 -0.222658922 #> [186,] -0.41015369  0.071806731 #> [187,]  0.53023581 -0.275259894 #> [188,] -0.13917820 -0.264004182 #> [189,] -0.44141153  0.157461569 #> [190,]  0.45128365 -0.437187439 #> [191,] -0.58271560  0.679096748 #> [192,] -0.68369222  1.220990787 #> [193,] -0.57458088  0.642387764 #> [194,] -0.38928001  0.020044848 #> [195,] -0.10214638 -0.244750087 #> [196,] -0.25895505 -0.207736216 #> [197,]  0.49090436 -0.364640956 #> [198,] -0.52899202  0.452822300 #> [199,]  0.74025318  0.589504409 #> [200,] -0.29668307 -0.158671087 #> [201,] -0.39554593  0.035132056 #> [202,]  0.32381920 -0.562426369 #> [203,] -0.54321127  0.509109327 #> [204,]  0.55609332 -0.206359164 #> [205,] -0.22095903 -0.242745411 #> [206,] -0.25322617 -0.213956325 #> [207,] -0.22268499 -0.241479106 #> [208,]  0.75571425  0.689874210 #> [209,] -0.50845181  0.375814748 #> [210,]  0.65562502  0.146442876 #> [211,] -0.34723896 -0.071316877 #> [212,] -0.47622592  0.264755847 #> [213,]  0.45491478 -0.431237203 #> [214,] -0.34018333 -0.084980904 #> [215,]  0.55474542 -0.210159919 #> [216,] -0.68736814  1.244202561 #> [217,]  0.37170464 -0.534009535 #> [218,] -0.74652494  1.661227957 #> [219,] -0.72551104  1.502973046 #> [220,] -0.48032046  0.278226622 #> [221,] -0.48523417  0.294634885 #> [222,]  0.30361435 -0.567812804 #> [223,] -0.24794139 -0.219401600 #> [224,] -0.15160669 -0.266029952 #> [225,] -0.39247431  0.027688047 #> [226,] -0.26076148 -0.205706801 #> [227,] -0.28792610 -0.171300248 #> [228,] -0.26360168 -0.202450269 #> [229,] -0.19928784 -0.255922252 #> [230,] -0.40721240  0.064252372 #> [231,] -0.39031313  0.022505928 #> [232,] -0.41573792  0.086386286 #> [233,]  0.63266185  0.051272271 #> [234,] -0.56759791  0.611598019 #> [235,]  0.25394992 -0.564205413 #> [236,]  0.31962163 -0.563868226 #> [237,]  0.52924976 -0.277723389 #> [238,] -0.31391648 -0.131652536 #> [239,] -0.47217013  0.251592225 #> [240,] -0.52223738  0.426946491 #> [241,] -0.36548763 -0.033757718 #> [242,] -0.31066969 -0.136961609 #> [243,] -0.49031965  0.311897631 #> [244,] -0.47341144  0.255602139 #> [245,] -0.27644817 -0.186722924 #> [246,] -0.30636924 -0.143837436 #> [247,] -0.30596844 -0.144469194 #> [248,]  0.55923755 -0.197401520 #> [249,] -0.27324921 -0.190791434 #> [250,]  0.62855486  0.035199335 #> [251,] -0.28429713 -0.176315489 #> [252,] -0.35042070 -0.064998759 #> [253,] -0.43342496  0.134633062 #> [254,]  0.73489465  0.556340101 #> [255,]  0.33138567 -0.559400397 #> [256,] -0.59242521  0.724127417 #> [257,] -0.43466018  0.138121047 #> [258,] -0.48605827  0.297412845 #> [259,] -0.12498879 -0.259080167 #> [260,] -0.50399080  0.359742197 #> [261,]  0.57736781 -0.143192804 #> [262,] -0.54295223  0.508061553 #> [263,] -0.52616695  0.441933272 #> [264,] -0.22534902 -0.239462867 #> [265,]  0.53042433 -0.274787562 #> [266,] -0.42208370  0.103333093 #> [267,]  0.58286987 -0.125857354 #> [268,] -0.35535691 -0.055004221 #> [269,] -0.39034161  0.022573915 #> [270,] -0.53610961  0.480686160 #> [271,] -0.40568818  0.060371377 #> [272,]  0.51506095 -0.311881418 #> [273,]  0.63071263  0.043609165 #> [274,] -0.36262860 -0.039853953 #> [275,] -0.27285122 -0.191290564 #> [276,]  0.48524828 -0.376041440 #> [277,] -0.37132390 -0.021068200 #> [278,]  0.57456501 -0.151862894 #> [279,] -0.13453565 -0.262708237 #> [280,]  0.57424249 -0.152853689 #> [281,] -0.60204920  0.770103871 #> [282,] -0.57319830  0.636239157 #> [283,]  0.49055524 -0.365354955 #> [284,]  0.54341146 -0.241198938 #> [285,] -0.59323253  0.727932284 #> [286,]  0.58911431 -0.105668839 #> [287,] -0.61063756  0.812296691 #> [288,] -0.49028842  0.311790725 #> [289,] -0.45337911  0.192902835 #> [290,]  0.70471404  0.383603722 #> [291,] -0.50200962  0.352677462 #> [292,] -0.26626540 -0.199323247 #> [293,]  0.51518687 -0.311588767 #> [294,] -0.13982851 -0.264161855 #> [295,] -0.55319116  0.550122950 #> [296,]  0.39246739 -0.514808090 #> [297,] -0.09351397 -0.237064475 #> [298,] -0.16823942 -0.265610292 #> [299,]  0.38602672 -0.521213889 #> [300,] -0.63441507  0.935125158 #>  #> $inv_hessian #>          [,1]     [,2] #> [1,] 4.809733 1.142218 #> [2,] 1.142218 5.838868 #>"},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_logistic_est.html","id":null,"dir":"Reference","previous_headings":"","what":"PPI++ Logistic Regression (Point Estimate) â€” ppi_plusplus_logistic_est","title":"PPI++ Logistic Regression (Point Estimate) â€” ppi_plusplus_logistic_est","text":"Helper function PPI++ logistic regression (point estimate)","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_logistic_est.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PPI++ Logistic Regression (Point Estimate) â€” ppi_plusplus_logistic_est","text":"","code":"ppi_plusplus_logistic_est(   X_l,   Y_l,   f_l,   X_u,   f_u,   lhat = NULL,   coord = NULL,   opts = NULL,   w_l = NULL,   w_u = NULL )"},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_logistic_est.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PPI++ Logistic Regression (Point Estimate) â€” ppi_plusplus_logistic_est","text":"X_l (matrix): n x p matrix covariates labeled data. Y_l (vector): n-vector labeled outcomes. f_l (vector): n-vector predictions labeled data. X_u (matrix): N x p matrix covariates unlabeled data. f_u (vector): N-vector predictions unlabeled data. lhat (float, optional): Power-tuning parameter (see https://arxiv.org/abs/2311.01453). default value, NULL, estimate optimal value data. Setting lhat = 1 recovers PPI power tuning, setting lhat = 0 recovers classical point estimate. coord (int, optional): Coordinate optimize lhat = 1. NULL, optimizes total variance coordinates. Must (1, ..., d) d dimension estimand. opts (list, optional): Options pass optimizer. See ?optim details. w_l (ndarray, optional): Sample weights labeled data set. Defaults vector ones. w_u (ndarray, optional): Sample weights unlabeled data set. Defaults vector ones.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_logistic_est.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PPI++ Logistic Regression (Point Estimate) â€” ppi_plusplus_logistic_est","text":"(vector): vector prediction-powered point estimates logistic regression coefficients.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_logistic_est.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PPI++ Logistic Regression (Point Estimate) â€” ppi_plusplus_logistic_est","text":"PPI++: Efficient Prediction Powered Inference (Angelopoulos et al., 2023) https://arxiv.org/abs/2311.01453`","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_logistic_est.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PPI++ Logistic Regression (Point Estimate) â€” ppi_plusplus_logistic_est","text":"","code":"dat <- simdat(model = \"logistic\")  form <- Y - f ~ X1  X_l <- model.matrix(form, data = dat[dat$set_label == \"labeled\", ])  Y_l <- dat[dat$set_label == \"labeled\", all.vars(form)[1]] |>    matrix(ncol = 1)  f_l <- dat[dat$set_label == \"labeled\", all.vars(form)[2]] |>    matrix(ncol = 1)  X_u <- model.matrix(form, data = dat[dat$set_label == \"unlabeled\", ])  f_u <- dat[dat$set_label == \"unlabeled\", all.vars(form)[2]] |>    matrix(ncol = 1)  ppi_plusplus_logistic_est(X_l, Y_l, f_l, X_u, f_u) #>           [,1] #> [1,] 0.5421797 #> [2,] 0.6046117"},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_mean.html","id":null,"dir":"Reference","previous_headings":"","what":"PPI++ Mean Estimation â€” ppi_plusplus_mean","title":"PPI++ Mean Estimation â€” ppi_plusplus_mean","text":"Helper function PPI++ mean estimation","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PPI++ Mean Estimation â€” ppi_plusplus_mean","text":"","code":"ppi_plusplus_mean(   Y_l,   f_l,   f_u,   alpha = 0.05,   alternative = \"two-sided\",   lhat = NULL,   coord = NULL,   w_l = NULL,   w_u = NULL )"},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PPI++ Mean Estimation â€” ppi_plusplus_mean","text":"Y_l (vector): n-vector labeled outcomes. f_l (vector): n-vector predictions labeled data. f_u (vector): N-vector predictions unlabeled data. alpha (scalar): type error rate hypothesis testing - values (0, 1); defaults 0.05. alternative (string): Alternative hypothesis. Must one \"two-sided\", \"less\", \"greater\". lhat (float, optional): Power-tuning parameter (see https://arxiv.org/abs/2311.01453). default value, NULL, estimate optimal value data. Setting lhat = 1 recovers PPI power tuning, setting lhat = 0 recovers classical point estimate. coord (int, optional): Coordinate optimize lhat = 1. NULL, optimizes total variance coordinates. Must (1, ..., d) d dimension estimand. w_l (ndarray, optional): Sample weights labeled data set. Defaults vector ones. w_u (ndarray, optional): Sample weights unlabeled data set. Defaults vector ones.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_mean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PPI++ Mean Estimation â€” ppi_plusplus_mean","text":"tuple: Lower upper bounds prediction-powered confidence interval mean.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_mean.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PPI++ Mean Estimation â€” ppi_plusplus_mean","text":"PPI++: Efficient Prediction Powered Inference (Angelopoulos et al., 2023) https://arxiv.org/abs/2311.01453`","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_mean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PPI++ Mean Estimation â€” ppi_plusplus_mean","text":"","code":"dat <- simdat(model = \"mean\")  form <- Y - f ~ 1  Y_l <- dat[dat$set_label == \"labeled\", all.vars(form)[1]] |>    matrix(ncol = 1)  f_l <- dat[dat$set_label == \"labeled\", all.vars(form)[2]] |>    matrix(ncol = 1)  f_u <- dat[dat$set_label == \"unlabeled\", all.vars(form)[2]] |>    matrix(ncol = 1)  ppi_plusplus_mean(Y_l, f_l, f_u) #>          lower    upper #> [1,] 0.9783136 1.200999"},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_mean_est.html","id":null,"dir":"Reference","previous_headings":"","what":"PPI++ Mean Estimation (Point Estimate) â€” ppi_plusplus_mean_est","title":"PPI++ Mean Estimation (Point Estimate) â€” ppi_plusplus_mean_est","text":"Helper function PPI++ mean estimation (point estimate)","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_mean_est.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PPI++ Mean Estimation (Point Estimate) â€” ppi_plusplus_mean_est","text":"","code":"ppi_plusplus_mean_est(   Y_l,   f_l,   f_u,   lhat = NULL,   coord = NULL,   w_l = NULL,   w_u = NULL )"},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_mean_est.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PPI++ Mean Estimation (Point Estimate) â€” ppi_plusplus_mean_est","text":"Y_l (vector): n-vector labeled outcomes. f_l (vector): n-vector predictions labeled data. f_u (vector): N-vector predictions unlabeled data. lhat (float, optional): Power-tuning parameter (see https://arxiv.org/abs/2311.01453). default value, NULL, estimate optimal value data. Setting lhat = 1 recovers PPI power tuning, setting lhat = 0 recovers classical point estimate. coord (int, optional): Coordinate optimize lhat = 1. NULL, optimizes total variance coordinates. Must (1, ..., d) d dimension estimand. w_l (ndarray, optional): Sample weights labeled data set. Defaults vector ones. w_u (ndarray, optional): Sample weights unlabeled data set. Defaults vector ones.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_mean_est.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PPI++ Mean Estimation (Point Estimate) â€” ppi_plusplus_mean_est","text":"float ndarray: Prediction-powered point estimate mean.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_mean_est.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PPI++ Mean Estimation (Point Estimate) â€” ppi_plusplus_mean_est","text":"PPI++: Efficient Prediction Powered Inference (Angelopoulos et al., 2023) https://arxiv.org/abs/2311.01453","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_mean_est.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PPI++ Mean Estimation (Point Estimate) â€” ppi_plusplus_mean_est","text":"","code":"dat <- simdat(model = \"mean\")  form <- Y - f ~ 1  Y_l <- dat[dat$set_label == \"labeled\", all.vars(form)[1]] |>    matrix(ncol = 1)  f_l <- dat[dat$set_label == \"labeled\", all.vars(form)[2]] |>    matrix(ncol = 1)  f_u <- dat[dat$set_label == \"unlabeled\", all.vars(form)[2]] |>    matrix(ncol = 1)  ppi_plusplus_mean_est(Y_l, f_l, f_u) #> [1] 0.9774971"},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_ols.html","id":null,"dir":"Reference","previous_headings":"","what":"PPI++ OLS â€” ppi_plusplus_ols","title":"PPI++ OLS â€” ppi_plusplus_ols","text":"Helper function PPI++ OLS estimation","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_ols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PPI++ OLS â€” ppi_plusplus_ols","text":"","code":"ppi_plusplus_ols(   X_l,   Y_l,   f_l,   X_u,   f_u,   lhat = NULL,   coord = NULL,   w_l = NULL,   w_u = NULL )"},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_ols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PPI++ OLS â€” ppi_plusplus_ols","text":"X_l (matrix): n x p matrix covariates labeled data. Y_l (vector): n-vector labeled outcomes. f_l (vector): n-vector predictions labeled data. X_u (matrix): N x p matrix covariates unlabeled data. f_u (vector): N-vector predictions unlabeled data. lhat (float, optional): Power-tuning parameter (see https://arxiv.org/abs/2311.01453). default value, NULL, estimate optimal value data. Setting lhat = 1 recovers PPI power tuning, setting lhat = 0 recovers classical point estimate. coord (int, optional): Coordinate optimize lhat = 1. NULL, optimizes total variance coordinates. Must (1, ..., d) d dimension estimand. w_l (ndarray, optional): Sample weights labeled data set. Defaults vector ones. w_u (ndarray, optional): Sample weights unlabeled data set. Defaults vector ones.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_ols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PPI++ OLS â€” ppi_plusplus_ols","text":"(list): list containing following: est (vector): vector PPI++ OLS regression coefficient estimates. se (vector): vector standard errors coefficients. lambda (float): estimated power-tuning parameter. rectifier_est (vector): vector rectifier OLS regression coefficient estimates. var_u (matrix): covariance matrix gradients unlabeled data. var_l (matrix): covariance matrix gradients labeled data. grads (matrix): matrix gradients labeled data. grads_hat_unlabeled (matrix): matrix predicted gradients unlabeled data. grads_hat (matrix): matrix predicted gradients labeled data. inv_hessian (matrix): inverse Hessian matrix.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_ols.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PPI++ OLS â€” ppi_plusplus_ols","text":"PPI++: Efficient Prediction Powered Inference (Angelopoulos et al., 2023) https://arxiv.org/abs/2311.01453`","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_ols.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PPI++ OLS â€” ppi_plusplus_ols","text":"","code":"dat <- simdat(model = \"ols\")  form <- Y - f ~ X1  X_l <- model.matrix(form, data = dat[dat$set_label == \"labeled\", ])  Y_l <- dat[dat$set_label == \"labeled\", all.vars(form)[1]] |>    matrix(ncol = 1)  f_l <- dat[dat$set_label == \"labeled\", all.vars(form)[2]] |>    matrix(ncol = 1)  X_u <- model.matrix(form, data = dat[dat$set_label == \"unlabeled\", ])  f_u <- dat[dat$set_label == \"unlabeled\", all.vars(form)[2]] |>    matrix(ncol = 1)  ppi_plusplus_ols(X_l, Y_l, f_l, X_u, f_u) #> $est #> X(Intercept)          XX1  #>    0.6544417    0.9111490  #>  #> $se #> [1] 0.09422607 0.09331478 #>  #> $lambda #> [1] 0.5148807 #>  #> $rectifier_est #> X(Intercept)          XX1  #>  -0.02792686  -0.12413267  #>  #> $var_u #>            [,1]       [,2] #> [1,]  0.2706170 -0.0613664 #> [2,] -0.0613664  0.3545745 #>  #> $var_l #>           [,1]      [,2] #> [1,] 2.3769054 0.1485426 #> [2,] 0.1485426 2.7148554 #>  #> $grads #>                [,1]          [,2] #>   [1,]  0.379868053 -0.8578402283 #>   [2,] -0.247440619 -0.2555719703 #>   [3,]  1.098087654 -0.3213743264 #>   [4,] -0.832634591 -0.0302422846 #>   [5,]  0.482010050  0.3545457105 #>   [6,] -1.697369132  1.8925094610 #>   [7,]  1.683521846  0.4344736388 #>   [8,] -0.276875655 -0.4146972375 #>   [9,] -1.676266828 -0.9483263109 #>  [10,]  1.615360135  1.0177743507 #>  [11,]  0.535657377 -0.7406377653 #>  [12,]  1.275485727  0.3430037750 #>  [13,] -0.053737786 -0.0405191043 #>  [14,] -0.095195165 -0.1630775571 #>  [15,]  4.469080965 -9.4397634519 #>  [16,]  0.108908919 -0.0752808928 #>  [17,]  1.185625682 -0.1191158265 #>  [18,]  1.258399192  1.5045637398 #>  [19,] -1.250471993  0.4093011194 #>  [20,] -0.766697498 -0.0868170738 #>  [21,]  0.650175534  0.4088765804 #>  [22,]  1.026471362 -1.7288022647 #>  [23,] -0.188502165 -0.0637660404 #>  [24,]  1.189194389 -0.8456633088 #>  [25,] -0.030183721 -0.0174548324 #>  [26,] -1.803833110  0.8124805498 #>  [27,] -0.379359998 -0.0859655935 #>  [28,] -0.047662072 -0.1252966845 #>  [29,]  2.751281185  2.3593842947 #>  [30,]  0.936718201  0.5791464795 #>  [31,]  0.129967890  0.1598360013 #>  [32,]  1.483073477 -2.8050531505 #>  [33,] -1.447952165  0.9192325385 #>  [34,] -1.461022042 -1.0967095429 #>  [35,] -1.360424539  0.5274867603 #>  [36,]  2.985862959  2.4095812862 #>  [37,] -0.572410970 -0.5214373001 #>  [38,]  2.931228586  2.9626238569 #>  [39,] -0.362851664  0.3492626008 #>  [40,]  1.848497203 -2.0165552456 #>  [41,] -0.356204932  0.1827133034 #>  [42,]  0.409298018  0.0319884741 #>  [43,] -1.405381318 -0.2539441194 #>  [44,] -0.814548874  0.2871992728 #>  [45,] -1.646016652  0.9646552248 #>  [46,]  0.137162181 -0.1089119167 #>  [47,] -2.590139377 -6.7558435195 #>  [48,] -3.394286085 -4.6528412916 #>  [49,] -1.018398986 -1.5529330091 #>  [50,]  1.041757619 -0.1997309172 #>  [51,] -0.526170991  0.7207630297 #>  [52,] -2.871811140 -0.1222609453 #>  [53,]  3.150625220  7.7620813721 #>  [54,]  0.370897634 -0.5243634732 #>  [55,]  0.816674627  0.2143042795 #>  [56,]  0.479033955 -0.3290304869 #>  [57,] -0.069625187 -0.0482740192 #>  [58,] -0.587295426 -0.1229168483 #>  [59,] -0.969874083 -1.2597517834 #>  [60,] -1.239664929 -1.0357885005 #>  [61,] -1.291613949  2.3697490855 #>  [62,] -5.366052454 -2.5538996917 #>  [63,] -0.004094896  0.0004328726 #>  [64,]  3.633200455  6.3069639691 #>  [65,] -0.731905691  0.4963351676 #>  [66,] -2.801582709 -1.9046186091 #>  [67,]  0.638237468 -0.1021512846 #>  [68,]  0.056800382  0.0721820777 #>  [69,]  1.659892571 -0.2600714493 #>  [70,]  0.508703917 -0.4747920473 #>  [71,] -0.650254103 -0.2047470439 #>  [72,] -0.403970221 -0.8810034954 #>  [73,] -1.066571672 -0.4225534759 #>  [74,] -0.299042453 -0.1446475301 #>  [75,] -0.753302434  0.8227743819 #>  [76,]  2.163424541 -1.0604217384 #>  [77,] -2.002198031  2.8670148588 #>  [78,]  0.021006878 -0.0023676770 #>  [79,]  1.040523197 -0.1257365151 #>  [80,] -0.112670281  0.0839088844 #>  [81,]  1.792735562 -1.0890736150 #>  [82,]  0.763653521  0.1583078694 #>  [83,]  0.771497212  0.9823834372 #>  [84,]  2.977255537 -2.0230597770 #>  [85,] -1.794756046  0.9051777974 #>  [86,]  0.150735800  0.0802457422 #>  [87,] -2.287740253 -0.6328976136 #>  [88,] -0.756791839  0.4180230853 #>  [89,] -1.266118987 -0.0944397613 #>  [90,]  2.723568755  0.8452315495 #>  [91,]  0.463069788  0.2276029715 #>  [92,] -1.555485976  0.2339515693 #>  [93,] -0.714452286  1.1024993352 #>  [94,]  1.723817047  1.4679573460 #>  [95,]  0.056697408 -0.0137536409 #>  [96,]  1.683263394  0.3989202593 #>  [97,]  1.204343196 -2.0775018868 #>  [98,]  1.773120949 -1.9043203327 #>  [99,]  0.061583525 -0.0139895803 #> [100,] -1.170029077  3.0515005895 #> [101,]  0.990442686 -0.4114379040 #> [102,] -1.105594195  1.5580605477 #> [103,] -0.202765980  0.0067244131 #> [104,]  0.770685894  0.1583927539 #> [105,]  5.584282933  6.9041986828 #> [106,] -2.356572304 -1.7351001061 #> [107,] -2.469005678 -2.5226506376 #> [108,] -2.952117839  2.5802385257 #> [109,]  0.650130366  0.7102491644 #> [110,] -3.083043266 -9.6295099734 #> [111,]  2.339718777 -0.2363766669 #> [112,]  0.205483335 -0.1954353583 #> [113,] -0.130870542  0.0943251610 #> [114,]  3.153692605  0.7396122617 #> [115,]  0.711622704  0.6094816696 #> [116,] -2.182344641  1.3054640978 #> [117,] -2.615959151  1.3990735231 #> [118,]  0.895877712  0.6548668325 #> [119,]  0.683652567 -1.1082945084 #> [120,] -0.413866212 -0.2458835600 #> [121,] -0.918752869  1.2140519772 #> [122,] -3.633182972 -1.4449624373 #> [123,]  0.207331300  0.0206628613 #> [124,]  0.906552710  1.7253037768 #> [125,]  3.927021233 -0.7514045272 #> [126,] -0.702390101 -0.4341252373 #> [127,] -0.373791248 -0.3016043183 #> [128,] -1.997224818 -0.5540765900 #> [129,]  0.358813015  0.1677765628 #> [130,] -1.270120597  1.3932406481 #> [131,] -0.640829769 -0.5941367253 #> [132,] -0.350134767 -0.5808079658 #> [133,]  0.853634981  0.3520312523 #> [134,]  0.078315442  0.1108900956 #> [135,]  2.085483719 -2.9326243417 #> [136,] -0.841035246  0.5690570875 #> [137,] -2.163061307 -4.8219385788 #> [138,]  0.034948057 -0.0163876304 #> [139,] -1.042014854 -0.3926622831 #> [140,]  1.093351120 -0.5821207367 #> [141,] -0.812144781 -0.6016563927 #> [142,] -0.156906088 -0.1567559698 #> [143,] -0.548840822  0.0699086463 #> [144,]  0.803460815 -0.9317074270 #> [145,]  0.044301448 -0.0222029974 #> [146,]  0.853680691  1.0001477976 #> [147,] -0.394606924  0.5007588108 #> [148,]  3.115431876  2.5373379734 #> [149,]  1.093502964 -0.5718515554 #> [150,] -1.635894165  1.2726447784 #> [151,]  0.368596352  0.7958645113 #> [152,] -1.914395627  0.3899563408 #> [153,] -0.447790937  0.8081022036 #> [154,]  2.546802175 -4.1361718115 #> [155,]  2.015175112  1.0609575916 #> [156,] -1.031027064 -0.0248413414 #> [157,]  0.610367058 -0.6936175496 #> [158,] -0.455172512  0.2190857795 #> [159,]  0.296087942  0.3144693626 #> [160,]  1.219722749 -0.5731384371 #> [161,]  2.312551053 -1.8278738131 #> [162,]  0.135876017  0.0531426256 #> [163,]  5.728887565  9.3165843934 #> [164,]  0.116208707  0.1629669625 #> [165,]  1.004154364  1.1010014497 #> [166,] -5.195732898  0.7558618108 #> [167,] -0.044290276 -0.0073771976 #> [168,]  0.163409209  0.1638469169 #> [169,]  1.094208968 -0.5936587080 #> [170,]  0.986967244  2.3845587948 #> [171,]  4.495095759 -1.8358906701 #> [172,] -1.785484990 -3.3696133426 #> [173,] -0.453622366  0.4424508817 #> [174,]  0.450631691  0.3399256762 #> [175,] -0.091145693  0.0704224827 #> [176,] -2.392134313  3.5165958415 #> [177,] -1.356381547 -0.7327037407 #> [178,]  0.803167041 -0.8757466765 #> [179,] -1.856941601  1.0386411142 #> [180,]  1.721382379  0.6782931706 #> [181,]  1.908416548 -1.0098282994 #> [182,] -0.558111405 -0.2584594830 #> [183,]  2.937944782 -2.4258494266 #> [184,]  1.013156726 -0.1705396075 #> [185,] -0.196416881  0.1092233448 #> [186,]  1.233514990 -0.9121702131 #> [187,] -1.670076156  0.0569475290 #> [188,] -1.389085378  1.1158622903 #> [189,]  0.477963088  0.1493941168 #> [190,] -1.875969756 -3.1771842131 #> [191,] -0.135627034  0.1939013701 #> [192,] -1.203572768  2.8248436220 #> [193,]  0.041644967  0.0649559427 #> [194,]  0.003729231 -0.0007100393 #> [195,] -2.922331370 -2.5619983104 #> [196,] -0.010158337 -0.0110338473 #> [197,]  1.320916632 -0.8429989862 #> [198,]  1.520019924 -1.0957875959 #> [199,]  0.989600162 -0.4754438857 #> [200,]  0.123999979  0.0442453839 #> [201,]  0.995994367 -0.5569338864 #> [202,]  1.315955988  2.2040200595 #> [203,]  0.419548860 -0.2026320944 #> [204,] -2.072415314  0.2946345616 #> [205,] -0.305130338 -0.6243533659 #> [206,]  0.046631528 -0.0131668254 #> [207,] -3.161071177  2.4030334494 #> [208,]  3.571124588  3.5801135785 #> [209,]  0.279572412 -0.2399954902 #> [210,] -1.103346490 -0.4780123395 #> [211,] -1.159600614 -3.7864040724 #> [212,]  0.579176631 -0.3195383801 #> [213,] -0.978986746  0.1751548393 #> [214,]  1.211400412  2.2648091377 #> [215,] -1.940936801 -1.2525262267 #> [216,]  0.565604216  0.7040780783 #> [217,]  1.326807464  0.8836519804 #> [218,] -1.404355965  0.8532030162 #> [219,] -0.414296450 -0.2618776923 #> [220,] -3.312654753  0.6479682418 #> [221,] -1.404439286 -1.7863749536 #> [222,] -0.037471166 -0.0252637303 #> [223,] -0.769144693 -1.9542503052 #> [224,] -0.820877204  0.4072500593 #> [225,]  1.409172308  1.3044369357 #> [226,]  1.626803595 -0.4874897912 #> [227,]  0.473848201 -0.5772489205 #> [228,]  0.746095637 -0.5831758435 #> [229,] -0.668016314 -0.0502741067 #> [230,]  0.623046841  0.0948806973 #> [231,]  0.980033073  1.7043085059 #> [232,] -0.171468003 -0.0308058380 #> [233,]  0.351149103 -0.1612242129 #> [234,]  1.131854397 -0.8251913390 #> [235,]  1.006992774 -0.7010010017 #> [236,] -0.341828506 -0.1225670230 #> [237,] -1.923131259  0.3859212105 #> [238,] -5.565484427  0.2215817032 #> [239,]  1.223937781  1.1564606222 #> [240,] -0.402685085 -0.4655516615 #> [241,]  0.064195919  0.0180347783 #> [242,] -0.413204920 -0.1938476223 #> [243,] -0.042329542 -0.0516280547 #> [244,]  2.043960572 -2.2033239485 #> [245,] -1.726774655  1.9994688664 #> [246,] -0.991582891 -0.1069203415 #> [247,] -1.369634574 -1.1233162860 #> [248,]  1.709498840  1.4424068068 #> [249,] -0.756459611  0.3709866138 #> [250,] -2.291185115 -3.3183755772 #> [251,]  0.330182552 -0.3342089569 #> [252,] -0.673354167  0.7667508709 #> [253,]  1.626811854 -0.2412241892 #> [254,]  0.613265643  0.5828391059 #> [255,]  0.041668714  0.0189042125 #> [256,]  1.419648195  1.3571990982 #> [257,] -2.059827738 -4.3525605142 #> [258,]  0.047238290  0.0207549321 #> [259,] -1.263770506 -1.6879306274 #> [260,]  1.183903024  0.1388306582 #> [261,]  1.683962536 -0.1238054913 #> [262,]  1.145420753  1.8095117280 #> [263,] -0.544473794  0.3425930833 #> [264,]  1.029986747 -1.2256676105 #> [265,] -1.346614905 -0.5312215537 #> [266,]  0.698322476 -0.4750619260 #> [267,] -1.345749455 -0.1344520657 #> [268,]  1.346596804  0.8960220614 #> [269,] -0.173173892  0.0189528661 #> [270,] -0.906703990  0.3299221066 #> [271,]  2.458711363  4.4775317383 #> [272,] -0.908167138  0.2611813173 #> [273,]  1.709002724 -1.0788246143 #> [274,]  1.816457098 -3.4832197948 #> [275,] -0.064736257  0.1437904842 #> [276,]  1.223748796  0.2645470238 #> [277,] -1.563878705 -0.4985993841 #> [278,]  0.929231046  1.8258979204 #> [279,]  0.324571883 -0.2859815030 #> [280,] -2.016216269 -3.5532560696 #> [281,]  0.670503503 -1.0159961719 #> [282,]  1.171763731  0.3212482042 #> [283,]  0.697694963 -0.1377215678 #> [284,] -6.672623397 13.0192501186 #> [285,] -0.059812745  0.0523776365 #> [286,]  3.578860759  1.9405211722 #> [287,] -3.259445573  2.7774074288 #> [288,] -1.857966123 -2.1250533688 #> [289,]  3.126634670  0.1903127610 #> [290,] -0.796155137 -0.0239903362 #> [291,] 10.522541876 -5.5854585017 #> [292,] -0.143259110  0.0374545320 #> [293,] -0.726028078  0.3768531716 #> [294,]  0.013337179  0.0134419385 #> [295,]  1.506159314  1.0125537428 #> [296,]  0.620302577  0.7599263569 #> [297,] -1.405620549  3.5230808891 #> [298,] -2.286704856 -0.0778841634 #> [299,] -3.615727792  2.2937944913 #> [300,]  3.019675290 -1.7289470389 #>  #> $grads_hat_unlabeled #>                [,1]          [,2] #>   [1,]  0.183157343  0.1336966511 #>   [2,] -0.840917483 -0.3264281527 #>   [3,]  0.852378483  0.7100090438 #>   [4,] -2.276547082 -2.1045784849 #>   [5,] -0.116942788  0.0442690606 #>   [6,]  0.555681364 -0.4615951381 #>   [7,] -1.070813607 -0.0014801812 #>   [8,]  0.566661862 -1.0068621104 #>   [9,]  0.495801593 -0.1463274333 #>  [10,]  0.845202712  0.3770070061 #>  [11,] -1.971748454  0.6048374105 #>  [12,]  0.080928621  0.0765922751 #>  [13,]  1.817533429  2.2195696232 #>  [14,] -0.216987032  0.0587415867 #>  [15,]  0.657139431  1.1353205272 #>  [16,] -0.596752584  0.4746963634 #>  [17,]  0.662807745 -0.0058994388 #>  [18,] -0.438100986  0.5972101151 #>  [19,]  0.340404340  0.0986944498 #>  [20,]  1.019335796 -0.9689978049 #>  [21,]  0.608947174  0.3494751762 #>  [22,] -1.423596862 -1.0035757237 #>  [23,] -1.139455423  0.3552356769 #>  [24,] -1.273239151 -1.5529942543 #>  [25,]  0.199294893  0.0231694755 #>  [26,] -0.037520002 -0.0164920263 #>  [27,] -0.786796418 -0.4788113692 #>  [28,] -1.190741904  2.0564978447 #>  [29,] -0.576121423 -0.3240397672 #>  [30,]  1.487410002 -2.3311698585 #>  [31,]  0.869239877 -0.7828958867 #>  [32,] -2.460757983  0.9783126714 #>  [33,] -1.459496787 -0.2418011211 #>  [34,] -0.242806380  0.1972581388 #>  [35,] -0.603670059 -0.6618173110 #>  [36,] -0.761513902 -1.4824032256 #>  [37,] -1.346618412 -1.2862982511 #>  [38,]  1.057592843 -1.0458072171 #>  [39,] -1.361496639  0.2633144696 #>  [40,] -1.284973036 -2.3152346912 #>  [41,]  0.212936864 -0.0958479268 #>  [42,]  0.189146197  0.0573557572 #>  [43,]  0.841413629 -0.4866945987 #>  [44,]  0.602131662 -0.2876527285 #>  [45,]  0.137029646 -0.1295255799 #>  [46,] -0.755859119  0.0977946408 #>  [47,] -1.353508797 -3.0815670226 #>  [48,] -0.612820075  0.5847256346 #>  [49,]  0.204722698  0.0704219912 #>  [50,] -1.204010525 -0.2776054358 #>  [51,]  0.038871182 -0.0008558238 #>  [52,] -1.885959131  3.1902301323 #>  [53,] -0.309065380  0.1914323470 #>  [54,] -0.348236855  0.1798824868 #>  [55,] -0.342612734 -0.5699825376 #>  [56,]  0.110650434 -0.0195531612 #>  [57,]  1.376424089 -1.5292410453 #>  [58,] -0.717529329  0.0525965750 #>  [59,]  0.392344910 -0.2187852427 #>  [60,]  0.936827281  1.5103790720 #>  [61,]  1.422933468 -0.4887909774 #>  [62,] -0.480389351 -0.7534409226 #>  [63,] -1.112198872 -1.9688049363 #>  [64,] -0.676923643  1.2946047858 #>  [65,]  0.086490343 -0.1427454360 #>  [66,]  0.406170898  0.1148851358 #>  [67,] -0.715730380 -1.7648413292 #>  [68,] -0.284437829  0.0857614301 #>  [69,]  0.196054794 -0.1003652253 #>  [70,]  1.515461313 -2.2348535171 #>  [71,]  2.097439751 -3.2259576931 #>  [72,] -0.540171773 -0.7211582902 #>  [73,] -0.024528464 -0.0147956717 #>  [74,] -0.751664310 -0.0442345455 #>  [75,] -0.087618123 -0.0440283815 #>  [76,] -0.730311681 -0.6824360480 #>  [77,]  1.646802215 -0.1154836306 #>  [78,]  0.081400181  0.0230210409 #>  [79,] -0.839187366  0.2687343149 #>  [80,] -1.314530644  1.1532588262 #>  [81,]  0.720373416 -0.1876152667 #>  [82,]  1.480035191 -0.4503246811 #>  [83,]  0.978712262  0.9768164760 #>  [84,] -1.185520927 -1.0904368805 #>  [85,]  0.390356845 -0.0679198782 #>  [86,]  0.413413603 -0.2490551224 #>  [87,] -0.740508200 -0.4058216449 #>  [88,]  0.204308042  0.2296672928 #>  [89,] -0.227284643  0.0931479849 #>  [90,] -0.038368413  0.0073610395 #>  [91,]  0.172970180  0.0954560798 #>  [92,] -0.572077895 -0.0968356243 #>  [93,]  1.786234992 -2.1406237810 #>  [94,]  0.448086097  0.1504024466 #>  [95,] -0.526798217 -0.2407084932 #>  [96,] -1.757819073  0.2191334094 #>  [97,]  1.029323262  2.0906191236 #>  [98,] -1.026650668 -0.4127166744 #>  [99,] -0.624693424 -0.7112039927 #> [100,] -1.739754117 -0.1456524420 #> [101,] -0.231701505  0.0335787930 #> [102,]  0.430185572 -0.9604049143 #> [103,] -0.499092738  0.0835262535 #> [104,]  1.009451710  0.1060638889 #> [105,] -1.113472762 -1.0777790492 #> [106,] -0.734609879  0.3072090388 #> [107,]  1.001547251  0.0883912949 #> [108,] -0.823690822  0.8485469715 #> [109,]  0.733619128  0.0720205035 #> [110,]  0.173201198  0.0989259275 #> [111,]  1.681821611  1.0999368354 #> [112,]  0.968324810 -0.7350883176 #> [113,]  1.800198189 -1.5099306469 #> [114,]  0.961552924 -2.5662074048 #> [115,]  1.073656964 -0.9933555899 #> [116,]  0.510043732 -0.0832152312 #> [117,] -0.602415934 -0.3864673491 #> [118,]  0.496101054  0.5232294075 #> [119,] -0.906256605 -0.1326292389 #> [120,] -0.505195254 -0.2854096924 #> [121,] -0.495398021  0.3652018978 #> [122,]  0.396758660  0.1882644767 #> [123,]  0.827571129  0.2435088923 #> [124,]  0.894555518  0.0518535917 #> [125,]  1.131239666  1.3250338465 #> [126,] -0.694611302 -0.4360725617 #> [127,] -1.206967713 -0.5330525609 #> [128,] -0.940543606 -0.4566951846 #> [129,]  0.826986325  0.1479312482 #> [130,] -0.445976232 -0.1585934196 #> [131,] -1.704533009 -0.8213375017 #> [132,] -0.590393677  0.3623558615 #> [133,] -1.165369111 -0.8817123356 #> [134,] -0.498052167  0.7739060188 #> [135,]  0.547191216 -0.6293547724 #> [136,] -0.106645182 -0.1246577065 #> [137,] -1.840553648 -0.0571151591 #> [138,] -0.250640571  0.3422473281 #> [139,] -1.294846380 -1.5294752883 #> [140,]  0.259882371  0.5433762387 #> [141,]  2.481426295 -5.3161070918 #> [142,] -0.646344348  0.8301675231 #> [143,]  0.395956465  0.6659807499 #> [144,]  0.851563115 -0.1229363808 #> [145,] -0.634858553 -1.1675005168 #> [146,] -0.607907108  0.2822787779 #> [147,]  0.269755360  0.0126159773 #> [148,]  0.785307361 -0.3363056928 #> [149,] -0.707825080 -2.0221999704 #> [150,]  0.701694460  0.1343380654 #> [151,] -0.483452954 -0.0839570083 #> [152,] -0.334325424 -0.1911918993 #> [153,] -0.032532714 -0.0069325788 #> [154,] -0.061481678  0.0226659468 #> [155,]  0.241878080  0.2498404087 #> [156,] -0.582158995 -0.4221530417 #> [157,]  0.239495715 -0.0011270883 #> [158,] -0.006305324 -0.0072443939 #> [159,]  0.428708349  0.6573940578 #> [160,]  0.141311705 -0.0063262474 #> [161,] -0.524584988 -0.5622407125 #> [162,]  1.036230055 -1.0766582529 #> [163,] -0.180964802  0.2381260861 #> [164,] -1.263008679  0.5418811393 #> [165,] -1.414988810  0.0794523816 #> [166,] -0.124518934  0.0388088767 #> [167,]  1.610283681 -1.5884573850 #> [168,] -1.104705556 -0.7804455721 #> [169,]  0.204857640  0.1665820694 #> [170,] -0.078258885 -0.1332604927 #> [171,] -0.780999652  0.3496859313 #> [172,] -0.456690492 -0.1308984420 #> [173,]  0.289778026  0.4177058435 #> [174,] -0.086377844 -0.0898095645 #> [175,]  0.608314295 -0.4459250487 #> [176,] -0.578195649  1.3151153598 #> [177,]  0.276027186  0.0593480694 #> [178,]  1.181333546 -0.9049869727 #> [179,]  1.108652910  0.2659837946 #> [180,] -0.851771061 -0.8203631989 #> [181,]  0.598460400  0.1153879915 #> [182,] -1.599690823 -0.4523781141 #> [183,]  0.800839672 -0.3383932932 #> [184,] -0.860295060  0.5314132869 #> [185,] -1.319291477  2.5461687917 #> [186,]  0.852590419 -0.4063705007 #> [187,] -2.611801718 -0.8130863258 #> [188,] -0.190557432 -0.0760335132 #> [189,]  0.347802369  0.2557180928 #> [190,] -1.240529758 -1.0132860580 #> [191,]  2.259540834  2.3844147979 #> [192,] -1.061763528 -0.9023738069 #> [193,] -0.124768516 -0.1963880305 #> [194,]  1.240492265 -0.5581303747 #> [195,] -0.400057348  0.2402342841 #> [196,] -0.644357761  0.4641943544 #> [197,]  0.715266132 -0.1889326417 #> [198,] -0.986718973 -0.6763751164 #> [199,]  0.695494204  0.0116925824 #> [200,]  1.491968314  0.9610875799 #> [201,]  0.801862574 -0.5028251583 #> [202,] -1.744407991  3.4982313830 #> [203,] -1.715979698  2.1809412341 #> [204,]  0.322007000  0.0624815528 #> [205,] -1.071430545  1.4450015700 #> [206,] -1.318764296  2.8298138583 #> [207,]  0.956375066 -1.4909070341 #> [208,]  1.898715808 -4.0025337511 #> [209,] -1.279980267  1.5600911481 #> [210,] -1.092241244 -1.0899966552 #> [211,] -1.374020047 -0.5620167553 #> [212,] -0.450234395 -0.5117264719 #> [213,]  1.268476866 -0.6870347337 #> [214,] -0.591236164  0.8589855420 #> [215,] -0.346921506 -0.1904386159 #> [216,]  0.415972119 -0.0374380335 #> [217,]  0.357424339  0.2574933045 #> [218,] -0.701620424 -0.3782729782 #> [219,] -2.043753334  2.9809504774 #> [220,]  1.117434716 -0.2431978457 #> [221,]  1.186594512 -0.7043854455 #> [222,] -0.182837980  0.0742077438 #> [223,] -0.479187879  0.1107029723 #> [224,] -2.186028012  2.5957661441 #> [225,] -0.604512647 -0.4464631998 #> [226,] -0.681999287 -0.1408686279 #> [227,]  0.679627145 -0.1031038832 #> [228,]  1.208781992 -2.5729795694 #> [229,]  0.869924672 -0.4862823424 #> [230,]  1.299704552 -1.3738773788 #> [231,] -0.140625929 -0.0243617899 #> [232,]  1.077617340  1.1339437172 #> [233,]  0.178700226 -0.0483084824 #> [234,]  0.095084205 -0.0306279432 #> [235,] -0.257137118 -0.4781908119 #> [236,] -1.166779636  1.4247385899 #> [237,] -0.211474646 -0.0777230399 #> [238,] -0.979815542 -1.0111078148 #> [239,]  0.841247249  0.0847631632 #> [240,] -1.678900939 -2.3866625878 #> [241,] -0.308861792 -0.0806195877 #> [242,] -0.656094433  0.6855939204 #> [243,] -0.628496847 -0.0479084855 #> [244,] -0.822474477 -0.7100890398 #> [245,] -1.723123243 -2.1154618103 #> [246,]  1.002150744 -2.0313506290 #> [247,] -0.323546293 -0.6717041920 #> [248,]  1.916327146 -0.1785483636 #> [249,] -0.234019756 -0.2656904929 #> [250,]  1.562086334  1.8269517032 #> [251,]  0.781450698 -0.7906077071 #> [252,] -0.337411631  0.0386211336 #> [253,]  3.048703090 -8.2227290789 #> [254,] -0.551832507  0.6638281866 #> [255,]  1.907657945  1.8256458438 #> [256,] -1.293206984 -0.8644598327 #> [257,] -0.035503240 -0.0467297992 #> [258,] -1.554438046  2.4898572794 #> [259,] -0.076302056 -0.0046271839 #> [260,] -1.709243023 -1.1900378402 #> [261,] -1.544911579  1.6651659521 #> [262,] -2.752111595 -0.4844487926 #> [263,] -0.328369079 -0.1243307025 #> [264,] -0.336742244 -0.1752120761 #> [265,] -0.025203475  0.0450013679 #> [266,] -0.018674984  0.0336146214 #> [267,]  0.259444014 -0.2305589827 #> [268,] -0.750983231  0.8210842647 #> [269,]  1.536253076 -2.1339945960 #> [270,]  1.603867398  0.8422943662 #> [271,]  0.325173764  0.6892817021 #> [272,]  1.575966749 -0.7147329408 #> [273,]  0.747337125 -0.3338090637 #> [274,] -0.866280177  0.9731128084 #> [275,]  0.025765448 -0.0137581928 #> [276,] -0.689083353 -1.0983575351 #> [277,]  1.142311244  0.8528223147 #> [278,]  0.528220048  0.1894524928 #> [279,] -0.728637599 -0.5024216193 #> [280,] -0.546089915 -0.8978908705 #> [281,]  1.221396321  0.1033604479 #> [282,]  1.382183573  1.2836856931 #> [283,]  1.345246054  1.3627240089 #> [284,] -0.265892868 -0.3009428518 #> [285,] -1.716412089  0.0961390995 #> [286,] -0.037718832  0.1021533981 #> [287,]  1.717572176  0.0589552510 #> [288,] -1.609991181  1.9245798469 #> [289,]  1.032767900 -0.0812115868 #> [290,]  0.315957699  0.3943468914 #> [291,] -0.841133287 -1.1213348607 #> [292,]  0.432015144 -0.7269336792 #> [293,]  0.805500753  1.8065400581 #> [294,] -0.962389844 -0.6312531267 #> [295,] -0.178035280 -0.1883119481 #> [296,]  1.126132416  0.7103560493 #> [297,] -0.866825900 -1.2441509602 #> [298,]  1.328341587  0.6272447749 #> [299,]  1.283350304 -2.0190542822 #> [300,] -0.824154534 -0.5573438239 #>  #> $grads_hat #>                [,1]        [,2] #>   [1,] -0.005839403  0.01318688 #>   [2,] -0.897842063 -0.92734680 #>   [3,]  0.622608561 -0.18221715 #>   [4,] -0.560900199 -0.02037257 #>   [5,] -1.174772249 -0.86411157 #>   [6,] -2.140623709  2.38672340 #>   [7,]  0.255418712  0.06591699 #>   [8,] -0.346658000 -0.51921544 #>   [9,] -2.398903625 -1.35714875 #>  [10,] -1.074650175 -0.67709445 #>  [11,]  0.897085899 -1.24037440 #>  [12,] -0.776610834 -0.20884628 #>  [13,] -0.245822801 -0.18535411 #>  [14,]  0.865667526  1.48296340 #>  [15,]  2.834558083 -5.98726181 #>  [16,]  1.688363711 -1.16704425 #>  [17,]  1.981747029 -0.19909946 #>  [18,]  1.151994806  1.37734482 #>  [19,]  0.231845999 -0.07588721 #>  [20,] -0.838352403 -0.09493092 #>  [21,]  1.255349241  0.78945281 #>  [22,] -0.069568687  0.11716888 #>  [23,]  1.275787893  0.43157033 #>  [24,] -1.045239507  0.74329370 #>  [25,] -0.389777806 -0.22540317 #>  [26,] -0.802183338  0.36131855 #>  [27,]  0.227775084  0.05161541 #>  [28,]  0.272444932  0.71621826 #>  [29,] -0.596668821 -0.51167836 #>  [30,] -0.462442089 -0.28591492 #>  [31,] -0.206921818 -0.25447483 #>  [32,] -0.211205313  0.39946917 #>  [33,] -0.335756972  0.21315534 #>  [34,] -0.192113855 -0.14420939 #>  [35,] -1.186788422  0.46016163 #>  [36,]  1.246089778  1.00559023 #>  [37,]  1.073698944  0.97808517 #>  [38,]  2.076449341  2.09868940 #>  [39,]  0.658822113 -0.63414874 #>  [40,]  1.946691173 -2.12367662 #>  [41,]  0.504986276 -0.25902985 #>  [42,] -0.459639100 -0.03592286 #>  [43,]  0.502094723  0.09072556 #>  [44,] -0.516839221  0.18223075 #>  [45,] -0.613798845  0.35971949 #>  [46,] -0.754297244  0.59894031 #>  [47,] -2.520289643 -6.57365492 #>  [48,] -0.520136331 -0.71299582 #>  [49,] -0.353295998 -0.53873288 #>  [50,] -1.155860710  0.22160733 #>  [51,]  1.167800366 -1.59968403 #>  [52,] -1.778918563 -0.07573348 #>  [53,]  0.853773388  2.10341061 #>  [54,]  0.506456452 -0.71601229 #>  [55,]  0.480077408  0.12597752 #>  [56,]  1.160298629 -0.79696568 #>  [57,] -1.035717336 -0.71810563 #>  [58,] -2.122687197 -0.44426367 #>  [59,]  0.139292719  0.18092478 #>  [60,]  1.415664732  1.18284322 #>  [61,]  0.506233299 -0.92879602 #>  [62,]  0.247316888  0.11770711 #>  [63,]  0.773142393 -0.08172910 #>  [64,]  2.042664692  3.54591297 #>  [65,]  0.654787518 -0.44403818 #>  [66,]  0.334875307  0.22766051 #>  [67,]  1.403065385 -0.22456364 #>  [68,]  0.329177031  0.41831906 #>  [69,]  1.366815835 -0.21415228 #>  [70,] -1.300557820  1.21385837 #>  [71,] -0.823919434 -0.25942946 #>  [72,]  0.643566048  1.40352905 #>  [73,] -1.471056669 -0.58280200 #>  [74,] -0.385465242 -0.18645043 #>  [75,]  1.161139411 -1.26822338 #>  [76,]  1.646721264 -0.80715504 #>  [77,] -1.699301635  2.43328730 #>  [78,]  1.148582973 -0.12945634 #>  [79,]  1.521286605 -0.18383182 #>  [80,]  1.133958075 -0.84449206 #>  [81,]  1.757966165 -1.06795146 #>  [82,]  1.573918550  0.32627846 #>  [83,] -0.494262685 -0.62936776 #>  [84,]  1.444216624 -0.98135230 #>  [85,] -1.965119345  0.99109982 #>  [86,]  0.397212091  0.21145991 #>  [87,] -2.402631904 -0.66468210 #>  [88,]  0.360975425 -0.19938912 #>  [89,]  1.081883941  0.08069768 #>  [90,] -0.556622418 -0.17274204 #>  [91,]  0.428646597  0.21068366 #>  [92,] -1.545448193  0.23244184 #>  [93,] -1.425917785  2.20038964 #>  [94,] -0.375676520 -0.31991626 #>  [95,]  1.277025735 -0.30978053 #>  [96,]  0.977453872  0.23164892 #>  [97,]  0.047127933 -0.08129607 #>  [98,]  1.519417211 -1.63184417 #>  [99,] -0.589548177  0.13392432 #> [100,] -0.263773365  0.68793553 #> [101,] -0.926093208  0.38470661 #> [102,] -1.951997865  2.75085640 #> [103,] -0.304933056  0.01011262 #> [104,]  1.051276217  0.21606018 #> [105,]  2.870734471  3.54926879 #> [106,] -0.771632480 -0.56813856 #> [107,] -1.710771053 -1.74794158 #> [108,] -0.972716060  0.85018268 #> [109,]  0.838335439  0.91585792 #> [110,]  0.077250431  0.24128231 #> [111,]  1.731556046 -0.17493532 #> [112,]  0.811598709 -0.77191216 #> [113,]  1.763768675 -1.27123921 #> [114,]  1.577841804  0.37003960 #> [115,]  1.265351330  1.08373220 #> [116,] -0.066540814  0.03980427 #> [117,] -1.844750682  0.98661397 #> [118,]  0.044987250  0.03288469 #> [119,]  2.024920168 -3.28267312 #> [120,]  0.890994077  0.52935173 #> [121,]  0.750608660 -0.99186404 #> [122,] -0.680555618 -0.27066551 #> [123,]  0.176337328  0.01757397 #> [124,] -1.097585682 -2.08886775 #> [125,]  2.068627637 -0.39581558 #> [126,]  0.528303248  0.32652763 #> [127,] -0.389319240 -0.31413353 #> [128,] -2.353910129 -0.65302939 #> [129,] -0.201521791 -0.09422912 #> [130,]  0.586385198 -0.64322687 #> [131,] -0.134241689 -0.12446038 #> [132,]  0.417168271  0.69200399 #> [133,]  0.312992029  0.12907505 #> [134,] -0.506746160 -0.71752299 #> [135,]  0.200225514 -0.28155876 #> [136,]  0.104626904 -0.07079214 #> [137,] -1.480895794 -3.30124187 #> [138,] -0.928941488  0.43559360 #> [139,]  0.470174172  0.17717565 #> [140,]  0.821046590 -0.43714067 #> [141,]  0.548062494  0.40601788 #> [142,]  1.152989470  1.15188636 #> [143,]  0.300468851 -0.03827225 #> [144,]  0.557425626 -0.64640065 #> [145,]  0.711961333 -0.35682074 #> [146,] -0.561863015 -0.65826258 #> [147,]  1.096173125 -1.39105098 #> [148,] -0.811519396 -0.66093533 #> [149,] -0.866002652  0.45287940 #> [150,]  0.353116257 -0.27470699 #> [151,] -0.753820998 -1.62763244 #> [152,] -1.807031433  0.36808659 #> [153,] -0.327336047  0.59072428 #> [154,]  2.500510083 -4.06099045 #> [155,] -0.075609907 -0.03980741 #> [156,]  1.018960767  0.02455062 #> [157,] -0.444224398  0.50481400 #> [158,] -1.150928571  0.55397037 #> [159,] -0.844571504 -0.89700330 #> [160,]  1.526844114 -0.71745243 #> [161,] -1.041019711  0.82283704 #> [162,] -1.181229906 -0.46199219 #> [163,]  2.530082554  4.11453836 #> [164,] -0.578954918 -0.81190581 #> [165,]  0.526648137  0.57744146 #> [166,] -2.516874557  0.36614841 #> [167,]  0.330929996  0.05512126 #> [168,] -0.909966725 -0.91240416 #> [169,] -0.364578501  0.19780061 #> [170,]  1.015069765  2.45245579 #> [171,]  2.286160569 -0.93371556 #> [172,] -2.020057061 -3.81230381 #> [173,] -0.435230332  0.42451179 #> [174,] -0.382645546 -0.28864159 #> [175,] -0.504011227  0.38941743 #> [176,]  0.328330818 -0.48266804 #> [177,] -0.767446408 -0.41456687 #> [178,]  0.968652569 -1.05618660 #> [179,]  0.046849389 -0.02620422 #> [180,]  1.173995471  0.46260094 #> [181,] -0.488488729  0.25848117 #> [182,]  0.189778747  0.08788589 #> [183,]  2.068989230 -1.70835625 #> [184,] -0.518359280  0.08725283 #> [185,] -0.597259851  0.33212379 #> [186,] -0.656290981  0.48531967 #> [187,] -1.222517174  0.04168632 #> [188,]  1.208682939 -0.97094371 #> [189,]  0.282997331  0.08845481 #> [190,]  0.292833623  0.49594956 #> [191,]  0.700641195 -1.00168295 #> [192,] -0.333838092  0.78353418 #> [193,] -0.949697830 -1.48129588 #> [194,] -0.600390533  0.11431334 #> [195,] -0.184540464 -0.16178602 #> [196,]  0.118661113  0.12888809 #> [197,]  0.778987371 -0.49714384 #> [198,] -0.432420235  0.31173324 #> [199,]  1.660123638 -0.79759045 #> [200,] -1.064219976 -0.37973250 #> [201,]  1.929745127 -1.07906278 #> [202,]  1.655902028  2.77337640 #> [203,]  2.290035970 -1.10603276 #> [204,] -2.530500366  0.35976035 #> [205,]  0.357248834  0.73099749 #> [206,] -0.432628207  0.12215641 #> [207,] -1.378704238  1.04808535 #> [208,]  0.065710655  0.06587606 #> [209,]  0.323357781 -0.27758250 #> [210,] -0.136264920 -0.05903523 #> [211,] -1.479778531 -4.83187003 #> [212,]  0.886911857 -0.48931943 #> [213,]  0.080191993 -0.01434750 #> [214,]  1.120094859  2.09410617 #> [215,] -0.917887294 -0.59233145 #> [216,] -1.401795708 -1.74498987 #> [217,]  1.542384331  1.02722588 #> [218,] -1.731174311  1.05175837 #> [219,] -1.815545354 -1.14761019 #> [220,] -1.260613465  0.24658093 #> [221,]  0.223060635  0.28372172 #> [222,] -0.647190331 -0.43634730 #> [223,] -2.015031462 -5.11981150 #> [224,] -1.403543868  0.69632013 #> [225,] -1.373151661 -1.27109349 #> [226,] -0.958983232  0.28736999 #> [227,] -1.492046627  1.81763338 #> [228,] -0.626417924  0.48963133 #> [229,]  0.671047230  0.05050221 #> [230,] -0.570683526 -0.08690655 #> [231,]  0.812890512  1.41364231 #> [232,] -0.726218634 -0.13047200 #> [233,] -0.649857586  0.29837120 #> [234,]  1.141917221 -0.83252776 #> [235,] -0.236639554  0.16473263 #> [236,] -0.470741586 -0.16879047 #> [237,] -0.858407742  0.17225957 #> [238,] -2.797345801  0.11137227 #> [239,] -1.634070017 -1.54398178 #> [240,] -1.299604680 -1.50249696 #> [241,] -1.203314457 -0.33805123 #> [242,] -1.798461697 -0.84371581 #> [243,]  0.637279782  0.77727075 #> [244,] -0.651253826  0.70203074 #> [245,] -0.595053590  0.68902513 #> [246,]  1.026882372  0.11072661 #> [247,]  0.060597112  0.04969919 #> [248,]  1.585049038  1.33740104 #> [249,]  0.525966502 -0.25794706 #> [250,]  0.255070432  0.36942432 #> [251,]  0.488872016 -0.49483356 #> [252,]  1.005478275 -1.14494182 #> [253,]  1.735172223 -0.25729190 #> [254,]  0.468948288  0.44568191 #> [255,] -0.786226306 -0.35669421 #> [256,] -0.188835726 -0.18052901 #> [257,] -1.591738195 -3.36345447 #> [258,]  0.340445932  0.14958061 #> [259,] -0.981822302 -1.31135196 #> [260,]  1.007744322  0.11817337 #> [261,] -1.013328904  0.07450028 #> [262,] -1.350357936 -2.13326720 #> [263,]  0.374712422 -0.23577606 #> [264,]  0.918579178 -1.09309440 #> [265,]  0.085289528  0.03364558 #> [266,]  1.701839206 -1.15774451 #> [267,] -2.197345755 -0.21953394 #> [268,] -0.280466812 -0.18662190 #> [269,] -1.161961726  0.12716989 #> [270,] -1.178943311  0.42898175 #> [271,]  1.744968819  3.17774318 #> [272,] -0.298763644  0.08592194 #> [273,]  0.097435452 -0.06150708 #> [274,]  0.941469214 -1.80535186 #> [275,]  0.541325996 -1.20237917 #> [276,]  0.995166190  0.21513259 #> [277,] -1.595219033 -0.50859138 #> [278,] -0.802784587 -1.57743622 #> [279,] -1.254116187  1.10500647 #> [280,] -2.461351651 -4.33773541 #> [281,]  0.839311560 -1.27178654 #> [282,]  0.698020929  0.19136790 #> [283,] -0.569787930  0.11247335 #> [284,] -2.777488108  5.41927968 #> [285,] -1.428182496  1.25065023 #> [286,]  2.168007820  1.17553192 #> [287,]  0.227948285 -0.19423710 #> [288,] -1.518611758 -1.73691597 #> [289,]  2.112961448  0.12861225 #> [290,]  0.405471488  0.01221797 #> [291,]  3.568261861 -1.89406503 #> [292,]  0.438482072 -0.11463942 #> [293,]  0.648251169 -0.33648218 #> [294,]  1.108711549  1.11742014 #> [295,]  0.952876371  0.64059527 #> [296,] -0.935534786 -1.14611412 #> [297,] -0.604457270  1.51502613 #> [298,]  1.496227557  0.05096085 #> [299,] -2.160024317  1.37030556 #> [300,]  1.800437180 -1.03085936 #>  #> $inv_hessian #>             [,1]        [,2] #> [1,]  1.00312675 -0.05371302 #> [2,] -0.05371302  0.92271068 #>"},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_ols_est.html","id":null,"dir":"Reference","previous_headings":"","what":"PPI++ OLS (Point Estimate) â€” ppi_plusplus_ols_est","title":"PPI++ OLS (Point Estimate) â€” ppi_plusplus_ols_est","text":"Helper function PPI++ OLS estimation (point estimate)","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_ols_est.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PPI++ OLS (Point Estimate) â€” ppi_plusplus_ols_est","text":"","code":"ppi_plusplus_ols_est(   X_l,   Y_l,   f_l,   X_u,   f_u,   lhat = NULL,   coord = NULL,   w_l = NULL,   w_u = NULL )"},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_ols_est.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PPI++ OLS (Point Estimate) â€” ppi_plusplus_ols_est","text":"X_l (matrix): n x p matrix covariates labeled data. Y_l (vector): n-vector labeled outcomes. f_l (vector): n-vector predictions labeled data. X_u (matrix): N x p matrix covariates unlabeled data. f_u (vector): N-vector predictions unlabeled data. lhat (float, optional): Power-tuning parameter (see https://arxiv.org/abs/2311.01453). default value, NULL, estimate optimal value data. Setting lhat = 1 recovers PPI power tuning, setting lhat = 0 recovers classical point estimate. coord (int, optional): Coordinate optimize lhat = 1. NULL, optimizes total variance coordinates. Must (1, ..., d) d dimension estimand. w_l (ndarray, optional): Sample weights labeled data set. Defaults vector ones. w_u (ndarray, optional): Sample weights unlabeled data set. Defaults vector ones.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_ols_est.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PPI++ OLS (Point Estimate) â€” ppi_plusplus_ols_est","text":"(vector): vector prediction-powered point estimates OLS coefficients.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_ols_est.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PPI++ OLS (Point Estimate) â€” ppi_plusplus_ols_est","text":"PPI++: Efficient Prediction Powered Inference (Angelopoulos et al., 2023) https://arxiv.org/abs/2311.01453","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_ols_est.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PPI++ OLS (Point Estimate) â€” ppi_plusplus_ols_est","text":"","code":"dat <- simdat(model = \"ols\")  form <- Y - f ~ X1  X_l <- model.matrix(form, data = dat[dat$set_label == \"labeled\", ])  Y_l <- dat[dat$set_label == \"labeled\", all.vars(form)[1]] |>    matrix(ncol = 1)  f_l <- dat[dat$set_label == \"labeled\", all.vars(form)[2]] |>    matrix(ncol = 1)  X_u <- model.matrix(form, data = dat[dat$set_label == \"unlabeled\", ])  f_u <- dat[dat$set_label == \"unlabeled\", all.vars(form)[2]] |>    matrix(ncol = 1)  ppi_plusplus_ols_est(X_l, Y_l, f_l, X_u, f_u) #> X(Intercept)          XX1  #>    0.9014085    0.9711672"},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_quantile.html","id":null,"dir":"Reference","previous_headings":"","what":"PPI++ Quantile Estimation â€” ppi_plusplus_quantile","title":"PPI++ Quantile Estimation â€” ppi_plusplus_quantile","text":"Helper function PPI++ quantile estimation","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_quantile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PPI++ Quantile Estimation â€” ppi_plusplus_quantile","text":"","code":"ppi_plusplus_quantile(   Y_l,   f_l,   f_u,   q,   alpha = 0.05,   exact_grid = FALSE,   w_l = NULL,   w_u = NULL )"},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_quantile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PPI++ Quantile Estimation â€” ppi_plusplus_quantile","text":"Y_l (vector): n-vector labeled outcomes. f_l (vector): n-vector predictions labeled data. f_u (vector): N-vector predictions unlabeled data. q (float): Quantile estimate. Must range (0, 1). alpha (scalar): type error rate hypothesis testing - values (0, 1); defaults 0.05. exact_grid (bool, optional): Whether compute exact solution (TRUE) approximate solution based linearly spaced grid 5000 values (FALSE). w_l (ndarray, optional): Sample weights labeled data set. Defaults vector ones. w_u (ndarray, optional): Sample weights unlabeled data set. Defaults vector ones.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_quantile.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PPI++ Quantile Estimation â€” ppi_plusplus_quantile","text":"tuple: Lower upper bounds prediction-powered confidence interval quantile.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_quantile.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PPI++ Quantile Estimation â€” ppi_plusplus_quantile","text":"PPI++: Efficient Prediction Powered Inference (Angelopoulos et al., 2023) https://arxiv.org/abs/2311.01453","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_quantile.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PPI++ Quantile Estimation â€” ppi_plusplus_quantile","text":"","code":"dat <- simdat(model = \"quantile\")  form <- Y - f ~ X1  Y_l <- dat[dat$set_label == \"labeled\", all.vars(form)[1]] |>    matrix(ncol = 1)  f_l <- dat[dat$set_label == \"labeled\", all.vars(form)[2]] |>    matrix(ncol = 1)  f_u <- dat[dat$set_label == \"unlabeled\", all.vars(form)[2]] |>    matrix(ncol = 1)  ppi_plusplus_quantile(Y_l, f_l, f_u, q = 0.5) #> [1] 0.6078383 1.2821842"},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_quantile_est.html","id":null,"dir":"Reference","previous_headings":"","what":"PPI++ Quantile Estimation (Point Estimate) â€” ppi_plusplus_quantile_est","title":"PPI++ Quantile Estimation (Point Estimate) â€” ppi_plusplus_quantile_est","text":"Helper function PPI++ quantile estimation (point estimate)","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_quantile_est.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PPI++ Quantile Estimation (Point Estimate) â€” ppi_plusplus_quantile_est","text":"","code":"ppi_plusplus_quantile_est(   Y_l,   f_l,   f_u,   q,   exact_grid = FALSE,   w_l = NULL,   w_u = NULL )"},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_quantile_est.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PPI++ Quantile Estimation (Point Estimate) â€” ppi_plusplus_quantile_est","text":"Y_l (vector): n-vector labeled outcomes. f_l (vector): n-vector predictions labeled data. f_u (vector): N-vector predictions unlabeled data. q (float): Quantile estimate. Must range (0, 1). exact_grid (bool, optional): Whether compute exact solution (TRUE) approximate solution based linearly spaced grid 5000 values (FALSE). w_l (ndarray, optional): Sample weights labeled data set. Defaults vector ones. w_u (ndarray, optional): Sample weights unlabeled data set. Defaults vector ones.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_quantile_est.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PPI++ Quantile Estimation (Point Estimate) â€” ppi_plusplus_quantile_est","text":"(float): Prediction-powered point estimate quantile.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_quantile_est.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PPI++ Quantile Estimation (Point Estimate) â€” ppi_plusplus_quantile_est","text":"PPI++: Efficient Prediction Powered Inference (Angelopoulos et al., 2023) https://arxiv.org/abs/2311.01453`","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_plusplus_quantile_est.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PPI++ Quantile Estimation (Point Estimate) â€” ppi_plusplus_quantile_est","text":"","code":"dat <- simdat(model = \"quantile\")  form <- Y - f ~ 1  Y_l <- dat[dat$set_label == \"labeled\", all.vars(form)[1]] |>    matrix(ncol = 1)  f_l <- dat[dat$set_label == \"labeled\", all.vars(form)[2]] |>    matrix(ncol = 1)  f_u <- dat[dat$set_label == \"unlabeled\", all.vars(form)[2]] |>    matrix(ncol = 1)  ppi_plusplus_quantile_est(Y_l, f_l, f_u, q = 0.5) #> [1] 0.9985379"},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_quantile.html","id":null,"dir":"Reference","previous_headings":"","what":"PPI Quantile Estimation â€” ppi_quantile","title":"PPI Quantile Estimation â€” ppi_quantile","text":"Helper function PPI quantile estimation","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_quantile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PPI Quantile Estimation â€” ppi_quantile","text":"","code":"ppi_quantile(Y_l, f_l, f_u, q, alpha = 0.05, exact_grid = FALSE)"},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_quantile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PPI Quantile Estimation â€” ppi_quantile","text":"Y_l (vector): n-vector labeled outcomes. f_l (vector): n-vector predictions labeled data. f_u (vector): N-vector predictions unlabeled data. q (float): Quantile estimate. Must range (0, 1). alpha (scalar): type error rate hypothesis testing - values (0, 1); defaults 0.05. exact_grid (bool, optional): Whether compute exact solution (TRUE) approximate solution based linearly spaced grid 5000 values (FALSE).","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_quantile.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PPI Quantile Estimation â€” ppi_quantile","text":"tuple: Lower upper bounds prediction-powered confidence interval quantile.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_quantile.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PPI Quantile Estimation â€” ppi_quantile","text":"Prediction Powered Inference (Angelopoulos et al., 2023) https://www.science.org/doi/10.1126/science.adi6000","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/ppi_quantile.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PPI Quantile Estimation â€” ppi_quantile","text":"","code":"dat <- simdat(model = \"quantile\")  form <- Y - f ~ X1  Y_l <- dat[dat$set_label == \"labeled\", all.vars(form)[1]] |>    matrix(ncol = 1)  f_l <- dat[dat$set_label == \"labeled\", all.vars(form)[2]] |>    matrix(ncol = 1)  f_u <- dat[dat$set_label == \"unlabeled\", all.vars(form)[2]] |>    matrix(ncol = 1)  ppi_quantile(Y_l, f_l, f_u, q = 0.5) #> [1] 0.7252995 1.1266162"},{"path":"https://ipd-tools.github.io/ipd/reference/print.ipd.html","id":null,"dir":"Reference","previous_headings":"","what":"Print ipd fit â€” print.ipd","title":"Print ipd fit â€” print.ipd","text":"Print ipd fit","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/print.ipd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print ipd fit â€” print.ipd","text":"","code":"# S3 method for class 'ipd' print(x, ...)"},{"path":"https://ipd-tools.github.io/ipd/reference/print.ipd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print ipd fit â€” print.ipd","text":"x object class ipd. ... Ignored.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/print.ipd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print ipd fit â€” print.ipd","text":"Invisibly returns x.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/print.summary.ipd.html","id":null,"dir":"Reference","previous_headings":"","what":"Print summary.ipd â€” print.summary.ipd","title":"Print summary.ipd â€” print.summary.ipd","text":"Print summary.ipd","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/print.summary.ipd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print summary.ipd â€” print.summary.ipd","text":"","code":"# S3 method for class 'summary.ipd' print(x, ...)"},{"path":"https://ipd-tools.github.io/ipd/reference/print.summary.ipd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print summary.ipd â€” print.summary.ipd","text":"x object class summary.ipd. ... Ignored.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/print.summary.ipd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print summary.ipd â€” print.summary.ipd","text":"Invisibly returns x.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/psi.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimating equation â€” psi","title":"Estimating equation â€” psi","text":"psi function estimating equation","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/psi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimating equation â€” psi","text":"","code":"psi(   X,   Y,   theta,   quant = NA,   method = c(\"ols\", \"quantile\", \"mean\", \"logistic\", \"poisson\") )"},{"path":"https://ipd-tools.github.io/ipd/reference/psi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimating equation â€” psi","text":"X Array data.frame containing covariates Y Array data.frame outcomes theta parameter theta quant quantile quantile estimation method indicates method used M-estimation. Options include \"mean\", \"quantile\", \"ols\", \"logistic\", \"poisson\".","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/psi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimating equation â€” psi","text":"estimating equation","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_logistic.html","id":null,"dir":"Reference","previous_headings":"","what":"PSPA Logistic Regression â€” pspa_logistic","title":"PSPA Logistic Regression â€” pspa_logistic","text":"Helper function PSPA logistic regression","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_logistic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PSPA Logistic Regression â€” pspa_logistic","text":"","code":"pspa_logistic(X_l, Y_l, f_l, X_u, f_u, weights = NA, alpha = 0.05)"},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_logistic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PSPA Logistic Regression â€” pspa_logistic","text":"X_l (matrix): n x p matrix covariates labeled data. Y_l (vector): n-vector binary labeled outcomes. f_l (vector): n-vector binary predictions labeled data. X_u (matrix): N x p matrix covariates unlabeled data. f_u (vector): N-vector binary predictions unlabeled data. weights (array): p-dimensional array weights vector variance reduction. PSPA estimate weights specified. alpha (scalar): type error rate hypothesis testing - values (0, 1); defaults 0.05","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_logistic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PSPA Logistic Regression â€” pspa_logistic","text":"list outputs: estimate inference model parameters corresponding standard error.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_logistic.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PSPA Logistic Regression â€” pspa_logistic","text":"Post-prediction adaptive inference (Miao et al. 2023) https://arxiv.org/abs/2311.14220","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_logistic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PSPA Logistic Regression â€” pspa_logistic","text":"","code":"dat <- simdat(model = \"logistic\")  form <- Y - f ~ X1  X_l <- model.matrix(form, data = dat[dat$set_label == \"labeled\", ])  Y_l <- dat[dat$set_label == \"labeled\", all.vars(form)[1]] |>   matrix(ncol = 1)  f_l <- dat[dat$set_label == \"labeled\", all.vars(form)[2]] |>   matrix(ncol = 1)  X_u <- model.matrix(form, data = dat[dat$set_label == \"unlabeled\", ])  f_u <- dat[dat$set_label == \"unlabeled\", all.vars(form)[2]] |>   matrix(ncol = 1)  pspa_logistic(X_l, Y_l, f_l, X_u, f_u) #> $est #> [1] 0.4424567 0.7136920 #>  #> $se #> [1] 0.1246229 0.1374400 #>"},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_mean.html","id":null,"dir":"Reference","previous_headings":"","what":"PSPA Mean Estimation â€” pspa_mean","title":"PSPA Mean Estimation â€” pspa_mean","text":"Helper function PSPA mean estimation","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PSPA Mean Estimation â€” pspa_mean","text":"","code":"pspa_mean(Y_l, f_l, f_u, weights = NA, alpha = 0.05)"},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PSPA Mean Estimation â€” pspa_mean","text":"Y_l (vector): n-vector labeled outcomes. f_l (vector): n-vector predictions labeled data. f_u (vector): N-vector predictions unlabeled data. weights (array): 1-dimensional array weights vector variance reduction. PSPA estimate weights specified. alpha (scalar): type error rate hypothesis testing - values (0, 1); defaults 0.05.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_mean.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PSPA Mean Estimation â€” pspa_mean","text":"list outputs: estimate inference model parameters corresponding standard error.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_mean.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PSPA Mean Estimation â€” pspa_mean","text":"Post-prediction adaptive inference (Miao et al., 2023) https://arxiv.org/abs/2311.14220","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_mean.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PSPA Mean Estimation â€” pspa_mean","text":"","code":"dat <- simdat(model = \"mean\")  form <- Y - f ~ 1  Y_l <- dat[dat$set_label == \"labeled\", all.vars(form)[1]] |>   matrix(ncol = 1)  f_l <- dat[dat$set_label == \"labeled\", all.vars(form)[2]] |>   matrix(ncol = 1)  f_u <- dat[dat$set_label == \"unlabeled\", all.vars(form)[2]] |>   matrix(ncol = 1)  pspa_mean(Y_l = Y_l, f_l = f_l, f_u = f_u) #> $est #> [1] 1.099869 #>  #> $se #> [1] 0.05573693 #>"},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_ols.html","id":null,"dir":"Reference","previous_headings":"","what":"PSPA OLS Estimation â€” pspa_ols","title":"PSPA OLS Estimation â€” pspa_ols","text":"Helper function PSPA OLS linear regression","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_ols.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PSPA OLS Estimation â€” pspa_ols","text":"","code":"pspa_ols(X_l, Y_l, f_l, X_u, f_u, weights = NA, alpha = 0.05)"},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_ols.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PSPA OLS Estimation â€” pspa_ols","text":"X_l (matrix): n x p matrix covariates labeled data. Y_l (vector): n-vector labeled outcomes. f_l (vector): n-vector predictions labeled data. X_u (matrix): N x p matrix covariates unlabeled data. f_u (vector): N-vector predictions unlabeled data. weights (array): p-dimensional array weights vector variance reduction. PSPA estimate weights specified. alpha (scalar): type error rate hypothesis testing - values (0, 1); defaults 0.05.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_ols.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PSPA OLS Estimation â€” pspa_ols","text":"list outputs: estimate inference model parameters corresponding standard error.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_ols.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PSPA OLS Estimation â€” pspa_ols","text":"Post-prediction adaptive inference (Miao et al. 2023) https://arxiv.org/abs/2311.14220","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_ols.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PSPA OLS Estimation â€” pspa_ols","text":"","code":"dat <- simdat(model = \"ols\")  form <- Y - f ~ X1  X_l <- model.matrix(form, data = dat[dat$set_label == \"labeled\", ])  Y_l <- dat[dat$set_label == \"labeled\", all.vars(form)[1]] |>   matrix(ncol = 1)  f_l <- dat[dat$set_label == \"labeled\", all.vars(form)[2]] |>   matrix(ncol = 1)  X_u <- model.matrix(form, data = dat[dat$set_label == \"unlabeled\", ])  f_u <- dat[dat$set_label == \"unlabeled\", all.vars(form)[2]] |>   matrix(ncol = 1)  pspa_ols(X_l, Y_l, f_l, X_u, f_u) #> $est #> [1] 0.7172598 1.0653516 #>  #> $se #> [1] 0.10001012 0.09052033 #>"},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_poisson.html","id":null,"dir":"Reference","previous_headings":"","what":"PSPA Poisson Regression â€” pspa_poisson","title":"PSPA Poisson Regression â€” pspa_poisson","text":"Helper function PSPA Poisson regression","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_poisson.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PSPA Poisson Regression â€” pspa_poisson","text":"","code":"pspa_poisson(X_l, Y_l, f_l, X_u, f_u, weights = NA, alpha = 0.05)"},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_poisson.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PSPA Poisson Regression â€” pspa_poisson","text":"X_l (matrix): n x p matrix covariates labeled data. Y_l (vector): n-vector count labeled outcomes. f_l (vector): n-vector binary predictions labeled data. X_u (matrix): N x p matrix covariates unlabeled data. f_u (vector): N-vector binary predictions unlabeled data. weights (array): p-dimensional array weights vector variance reduction. PSPA estimate weights specified. alpha (scalar): type error rate hypothesis testing - values (0, 1); defaults 0.05","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_poisson.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PSPA Poisson Regression â€” pspa_poisson","text":"list outputs: estimate inference model parameters corresponding standard error.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_poisson.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PSPA Poisson Regression â€” pspa_poisson","text":"Post-prediction adaptive inference (Miao et al. 2023) https://arxiv.org/abs/2311.14220","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_poisson.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PSPA Poisson Regression â€” pspa_poisson","text":"","code":"dat <- simdat(model = \"poisson\")  form <- Y - f ~ X1  X_l <- model.matrix(form, data = dat[dat$set_label == \"labeled\", ])  Y_l <- dat[dat$set_label == \"labeled\", all.vars(form)[1]] |>   matrix(ncol = 1)  f_l <- dat[dat$set_label == \"labeled\", all.vars(form)[2]] |>   matrix(ncol = 1)  X_u <- model.matrix(form, data = dat[dat$set_label == \"unlabeled\", ])  f_u <- dat[dat$set_label == \"unlabeled\", all.vars(form)[2]] |>   matrix(ncol = 1)  pspa_poisson(X_l, Y_l, f_l, X_u, f_u) #> $est #> [1]  5.615595 -1.092599 #>  #> $se #> [1] 0.9034740 0.1161087 #>"},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_quantile.html","id":null,"dir":"Reference","previous_headings":"","what":"PSPA Quantile Estimation â€” pspa_quantile","title":"PSPA Quantile Estimation â€” pspa_quantile","text":"Helper function PSPA quantile estimation","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_quantile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PSPA Quantile Estimation â€” pspa_quantile","text":"","code":"pspa_quantile(Y_l, f_l, f_u, q, weights = NA, alpha = 0.05)"},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_quantile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PSPA Quantile Estimation â€” pspa_quantile","text":"Y_l (vector): n-vector labeled outcomes. f_l (vector): n-vector predictions labeled data. f_u (vector): N-vector predictions unlabeled data. q (float): Quantile estimate. Must range (0, 1). weights (array): 1-dimensional array weights vector variance reduction. PSPA estimate weights specified. alpha (scalar): type error rate hypothesis testing - values (0, 1); defaults 0.05.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_quantile.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PSPA Quantile Estimation â€” pspa_quantile","text":"list outputs: estimate inference model parameters corresponding standard error.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_quantile.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"PSPA Quantile Estimation â€” pspa_quantile","text":"Post-prediction adaptive inference (Miao et al. 2023) https://arxiv.org/abs/2311.14220","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_quantile.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"PSPA Quantile Estimation â€” pspa_quantile","text":"","code":"dat <- simdat(model = \"quantile\")  form <- Y - f ~ 1  Y_l <- dat[dat$set_label == \"labeled\", all.vars(form)[1]] |> matrix(ncol = 1)  f_l <- dat[dat$set_label == \"labeled\", all.vars(form)[2]] |> matrix(ncol = 1)  f_u <- dat[dat$set_label == \"unlabeled\", all.vars(form)[2]] |>   matrix(ncol = 1)  pspa_quantile(Y_l = Y_l, f_l = f_l, f_u = f_u, q = 0.5) #> $est #> [1] 1.112428 #>  #> $se #> [1] 0.07551225 #>"},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_y.html","id":null,"dir":"Reference","previous_headings":"","what":"PSPA M-Estimation for ML-predicted labels â€” pspa_y","title":"PSPA M-Estimation for ML-predicted labels â€” pspa_y","text":"pspa_y function conducts post-prediction M-Estimation.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_y.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"PSPA M-Estimation for ML-predicted labels â€” pspa_y","text":"","code":"pspa_y(   X_l = NA,   X_u = NA,   Y_l,   f_l,   f_u,   alpha = 0.05,   weights = NA,   quant = NA,   intercept = FALSE,   method )"},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_y.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"PSPA M-Estimation for ML-predicted labels â€” pspa_y","text":"X_l Array data.frame containing observed covariates labeled data. X_u Array data.frame containing observed predicted covariates unlabeled data. Y_l Array data.frame observed outcomes labeled data. f_l Array data.frame predicted outcomes labeled data. f_u Array data.frame predicted outcomes unlabeled data. alpha Specifies confidence level 1 - alpha confidence intervals. weights weights vector PSPA linear regression (d-dimensional, d equals number covariates). quant quantile quantile estimation intercept Boolean indicating input covariates' data contains intercept (TRUE input data contains) method indicates method used M-estimation. Options include \"mean\", \"quantile\", \"ols\", \"logistic\", \"poisson\".","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/pspa_y.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"PSPA M-Estimation for ML-predicted labels â€” pspa_y","text":"summary table presenting point estimates, standard error, confidence intervals (1 - alpha), P-values, weights.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/rectified_cdf.html","id":null,"dir":"Reference","previous_headings":"","what":"Rectified CDF â€” rectified_cdf","title":"Rectified CDF â€” rectified_cdf","text":"Computes rectified CDF data.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/rectified_cdf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rectified CDF â€” rectified_cdf","text":"","code":"rectified_cdf(Y_l, f_l, f_u, grid, w_l = NULL, w_u = NULL)"},{"path":"https://ipd-tools.github.io/ipd/reference/rectified_cdf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rectified CDF â€” rectified_cdf","text":"Y_l (vector): Gold-standard labels. f_l (vector): Predictions corresponding gold-standard labels. f_u (vector): Predictions corresponding unlabeled data. grid (vector): Grid values compute CDF . w_l (vector, optional): Sample weights labeled data set. w_u (vector, optional): Sample weights unlabeled data set.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/rectified_cdf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rectified CDF â€” rectified_cdf","text":"(vector): Rectified CDF data specified grid points.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/rectified_p_value.html","id":null,"dir":"Reference","previous_headings":"","what":"Rectified P-Value â€” rectified_p_value","title":"Rectified P-Value â€” rectified_p_value","text":"Computes rectified p-value.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/rectified_p_value.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Rectified P-Value â€” rectified_p_value","text":"","code":"rectified_p_value(   rectifier,   rectifier_std,   imputed_mean,   imputed_std,   null = 0,   alternative = \"two-sided\" )"},{"path":"https://ipd-tools.github.io/ipd/reference/rectified_p_value.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Rectified P-Value â€” rectified_p_value","text":"rectifier (float vector): Rectifier value. rectifier_std (float vector): Rectifier standard deviation. imputed_mean (float vector): Imputed mean. imputed_std (float vector): Imputed standard deviation. null (float, optional): Value null hypothesis tested. Defaults 0. alternative (str, optional): Alternative hypothesis, either 'two-sided', 'larger' 'smaller'.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/rectified_p_value.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Rectified P-Value â€” rectified_p_value","text":"(float vector): rectified p-value.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"tidy re-exported from generics packages â€” reexports","title":"tidy re-exported from generics packages â€” reexports","text":"objects imported packages. Follow links see documentation. generics augment, glance, tidy","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/reexports.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"tidy re-exported from generics packages â€” reexports","text":"wrapper tidy generic. See tidy details. wrapper glance generic. See glance details. wrapper augment generic. See augment details.","code":""},{"path":[]},{"path":"https://ipd-tools.github.io/ipd/reference/reexports.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"tidy re-exported from generics packages â€” reexports","text":"","code":"dat <- simdat()  fit <- ipd(Y - f ~ X1, method = \"pspa\", model = \"ols\",      data = dat, label = \"set_label\")  tidy(fit) #> # A tibble: 2 Ã— 5 #>   term        estimate std.error conf.low conf.high #>   <chr>          <dbl>     <dbl>    <dbl>     <dbl> #> 1 (Intercept)    0.763    0.0821    0.602     0.924 #> 2 X1             1.12     0.100     0.922     1.32    dat <- simdat()  fit <- ipd(Y - f ~ X1, method = \"pspa\", model = \"ols\",      data = dat, label = \"set_label\")  glance(fit) #> # A tibble: 1 Ã— 6 #>   method model intercept nobs_labeled nobs_unlabeled call       #>   <chr>  <chr> <lgl>            <int>          <int> <chr>      #> 1 pspa   ols   TRUE               300            300 Y - f ~ X1   dat <- simdat()  fit <- ipd(Y - f ~ X1, method = \"pspa\", model = \"ols\",      data = dat, label = \"set_label\")  augmented_df <- augment(fit)  head(augmented_df) #>             X1         X2         X3         X4          Y          f set_label #> 601  1.3164889 -1.0993390 -0.5295127 -0.7249570 -0.4174530  1.5464069 unlabeled #> 602  0.5958371  0.3428818 -0.8154374  0.3836561  0.5659813  0.3366378 unlabeled #> 603 -1.2790635  0.8285632  0.2284483 -0.8493983  0.2843101 -0.1063543 unlabeled #> 604 -0.1964645  0.4604912  0.8713296 -0.3425420  0.6854845  1.8174122 unlabeled #> 605  1.2241738  1.6993407  0.2550743 -0.5637982  1.8367730  2.3756328 unlabeled #> 606  0.1897695 -2.4095399  0.7053563  0.8163529  1.3784036  2.0424280 unlabeled #>        .fitted     .resid #> 601  2.0426373 -2.4600903 #> 602  1.2758116 -0.7098303 #> 603 -0.7192182  1.0035283 #> 604  0.4327454  0.2527391 #> 605  1.9444073 -0.1076343 #> 606  0.8437263  0.5346773"},{"path":"https://ipd-tools.github.io/ipd/reference/show-ipd-method.html","id":null,"dir":"Reference","previous_headings":"","what":"Show an ipd object â€” show,ipd-method","title":"Show an ipd object â€” show,ipd-method","text":"Display concise summary ipd S4 object, including method, model, formula, glm-style coefficient table.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/show-ipd-method.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Show an ipd object â€” show,ipd-method","text":"","code":"# S4 method for class 'ipd' show(object)"},{"path":"https://ipd-tools.github.io/ipd/reference/show-ipd-method.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Show an ipd object â€” show,ipd-method","text":"object object S4 class ipd.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/show-ipd-method.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Show an ipd object â€” show,ipd-method","text":"Invisibly returns object printing.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/sim_data_y.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate the data for testing the functions â€” sim_data_y","title":"Simulate the data for testing the functions â€” sim_data_y","text":"sim_data_y simulation ML-predicted Y","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/sim_data_y.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate the data for testing the functions â€” sim_data_y","text":"","code":"sim_data_y(r = 0.9, binary = FALSE)"},{"path":"https://ipd-tools.github.io/ipd/reference/sim_data_y.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate the data for testing the functions â€” sim_data_y","text":"r imputation correlation binary simulate binary outcome ","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/sim_data_y.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate the data for testing the functions â€” sim_data_y","text":"simulated data","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/simdat.html","id":null,"dir":"Reference","previous_headings":"","what":"Data generation function for various underlying models â€” simdat","title":"Data generation function for various underlying models â€” simdat","text":"Data generation function various underlying models","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/simdat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data generation function for various underlying models â€” simdat","text":"","code":"simdat(   n = c(300, 300, 300),   effect = 1,   sigma_Y = 1,   model = \"ols\",   shift = 0,   scale = 1 )"},{"path":"https://ipd-tools.github.io/ipd/reference/simdat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Data generation function for various underlying models â€” simdat","text":"n Integer vector size 3 indicating sample sizes training, labeled, unlabeled data sets, respectively effect Regression coefficient first variable interest inference. Defaults 1. sigma_Y Residual variance generated outcome. Defaults 1. model type model generated. Must one \"mean\", \"quantile\", \"ols\", \"logistic\", \"poisson\". Default \"ols\". shift Scalar shift predictions continuous outcomes (.e., \"mean\", \"quantile\", \"ols\"). Defaults 0. scale Scaling factor predictions continuous outcomes (.e., \"mean\", \"quantile\", \"ols\"). Defaults 1.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/simdat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Data generation function for various underlying models â€” simdat","text":"data.frame containing n rows columns corresponding labeled outcome (Y), predicted outcome (f), character variable (set_label) indicating data set observation belongs (training, labeled, unlabeled), four independent, normally distributed predictors (X1, X2, X3, X4), applicable.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/simdat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Data generation function for various underlying models â€” simdat","text":"simdat function generates three datasets consisting independent realizations \\(Y\\) (model = \"mean\" \"quantile\"), \\(\\{Y, \\boldsymbol{X}\\}\\) (model = \"ols\", \"logistic\", \"poisson\"): training dataset size \\(n_t\\), labeled dataset size \\(n_l\\), unlabeled dataset size \\(n_u\\). sizes specified argument n. NOTE: unlabeled data subset, outcome data still generated facilitate benchmark comparison \"oracle\" model uses true \\(Y^{\\mathcal{U}}\\) values estimation inference. Generating Data \"mean\" \"quantile\", simulate continuous outcome, \\(Y \\\\mathbb{R}\\), mean given effect argument error variance given sigma_y argument. \"ols\", \"logistic\", \"poisson\" models, predictor data, \\(\\boldsymbol{X} \\\\mathbb{R}^4\\) simulated \\(\\)th observation follows standard multivariate normal distribution zero mean vector identity covariance matrix: $$   \\boldsymbol{X_i} = (X_{i1}, X_{i2}, X_{i3}, X_{i4}) \\sim   \\mathcal{N}_4(\\boldsymbol{0}, \\boldsymbol{}). $$ \"ols\", continuous outcome \\(Y \\\\mathbb{R}\\) simulated depend \\(X_1\\) linear term effect size specified effect argument, predictors, \\(\\boldsymbol{X} \\setminus X_1\\), nonlinear effects: $$   Y_i = effect \\times Z_{i1} + \\frac{1}{2} Z_{i2}^2 + \\frac{1}{3} Z_{i3}^3 +   \\frac{1}{4} Z_{i4}^2 + \\varepsilon_y, $$ \\(\\varepsilon_y \\sim \\mathcal{N}(0, sigma_y)\\), sigma_y argument specifies error variance. \"logistic\", simulate: $$   \\Pr(Y_i = 1 \\mid \\boldsymbol{X}) = logit^{-1}(effect \\times Z_{i1} +   \\frac{1}{2} Z_{i2}^2 + \\frac{1}{3} Z_{i3}^3 + \\frac{1}{4} Z_{i4}^2 +   \\varepsilon_y) $$ generate: $$   Y_i \\sim Bern[1, \\Pr(Y_i = 1 \\mid \\boldsymbol{X})] $$ \\(\\varepsilon_y \\sim \\mathcal{N}(0, sigma\\_y)\\). \"poisson\", simulate: $$   \\lambda_Y = exp(effect \\times Z_{i1} + \\frac{1}{2} Z_{i2}^2 +   \\frac{1}{3} Z_{i3}^3 + \\frac{1}{4} Z_{i4}^2 + \\varepsilon_y) $$ generate: $$   Y_i \\sim Poisson(\\lambda_Y) $$ Generating Predictions generate predicted outcomes \"mean\" \"quantile\", simulate continuous variable mean given empirical mean training data error variance given sigma_y argument. \"ols\", fit generalized additive model (GAM) simulated training dataset calculate predictions labeled unlabeled datasets deterministic functions \\(\\boldsymbol{X}\\). Specifically, fit following GAM: $$   Y^{\\mathcal{T}} = s_0 + s_1(X_1^{\\mathcal{T}}) + s_2(X_2^{\\mathcal{T}}) +   s_3(X_3^{\\mathcal{T}}) + s_4(X_4^{\\mathcal{T}}) + \\varepsilon_p, $$ \\(\\mathcal{T}\\) denotes training dataset, \\(s_0\\) intercept term, \\(s_1(\\cdot)\\), \\(s_2(\\cdot)\\), \\(s_3(\\cdot)\\), \\(s_4(\\cdot)\\) smoothing spline functions \\(X_1\\), \\(X_2\\), \\(X_3\\), \\(X_4\\), respectively, three target equivalent degrees freedom. Residual error modeled \\(\\varepsilon_p\\). Predictions labeled unlabeled datasets calculated : $$  f(\\boldsymbol{X}^{\\mathcal{L}\\cup\\mathcal{U}}) =  \\hat{s}_0 + \\hat{s}_1(X_1^{\\mathcal{L}\\cup\\mathcal{U}}) + \\hat{s}_2(X_2^{\\mathcal{L}\\cup\\mathcal{U}}) + \\hat{s}_3(X_3^{\\mathcal{L}\\cup\\mathcal{U}}) + \\hat{s}_4(X_4^{\\mathcal{L}\\cup\\mathcal{U}}), $$ \\(\\hat{s}_0, \\hat{s}_1, \\hat{s}_2, \\hat{s}_3\\), \\(\\hat{s}_4\\) estimates \\(s_0, s_1, s_2, s_3\\), \\(s_4\\), respectively. NOTE: continuous outcomes, provide optional arguments shift scale apply location shift scaling factor, respectively, predicted outcomes. default shift = 0 scale = 1, .e., location shift scaling. \"logistic\", train k-nearest neighbors (k-NN) classifiers simulated training dataset values \\(k\\) ranging 1 10. optimal \\(k\\) chosen via cross-validation, minimizing misclassification error validation folds. Predictions labeled unlabeled datasets obtained applying k-NN classifier optimal \\(k\\) \\(\\boldsymbol{X}\\). Specifically, observation labeled unlabeled datasets: $$   \\hat{Y} = \\operatorname{argmax}_c \\sum_{\\\\mathcal{N}_k} (Y_i = c), $$ \\(\\mathcal{N}_k\\) represents set \\(k\\) nearest neighbors training dataset, \\(c\\) indexes possible classes (0 1), \\((\\cdot)\\) indicator function. \"poisson\", fit generalized linear model (GLM) log link function simulated training dataset. model form: $$   \\log(\\mu^{\\mathcal{T}}) = \\gamma_0 + \\gamma_1 X_1^{\\mathcal{T}} +   \\gamma_2 X_2^{\\mathcal{T}} + \\gamma_3 X_3^{\\mathcal{T}} +   \\gamma_4 X_4^{\\mathcal{T}}, $$ \\(\\mu^{\\mathcal{T}}\\) expected count response variable training dataset, \\(\\gamma_0\\) intercept, \\(\\gamma_1\\), \\(\\gamma_2\\), \\(\\gamma_3\\), \\(\\gamma_4\\) regression coefficients predictors \\(X_1\\), \\(X_2\\), \\(X_3\\), \\(X_4\\), respectively. Predictions labeled unlabeled datasets calculated : $$   \\hat{\\mu}^{\\mathcal{L} \\cup \\mathcal{U}} = \\exp(\\hat{\\gamma}_0 +   \\hat{\\gamma}_1 X_1^{\\mathcal{L} \\cup \\mathcal{U}} +   \\hat{\\gamma}_2 X_2^{\\mathcal{L} \\cup \\mathcal{U}} +   \\hat{\\gamma}_3 X_3^{\\mathcal{L} \\cup \\mathcal{U}} +   \\hat{\\gamma}_4 X_4^{\\mathcal{L} \\cup \\mathcal{U}}), $$ \\(\\hat{\\gamma}_0\\), \\(\\hat{\\gamma}_1\\), \\(\\hat{\\gamma}_2\\), \\(\\hat{\\gamma}_3\\), \\(\\hat{\\gamma}_4\\) estimated coefficients.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/simdat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Data generation function for various underlying models â€” simdat","text":"","code":"#-- Mean  dat_mean <- simdat(c(100, 100, 100),   effect = 1, sigma_Y = 1,   model = \"mean\" )  head(dat_mean) #>           Y  f set_label #> 1 2.3123025 NA  training #> 2 1.6797212 NA  training #> 3 0.8057629 NA  training #> 4 0.9426763 NA  training #> 5 2.2976721 NA  training #> 6 1.5641992 NA  training  #-- Linear Regression  dat_ols <- simdat(c(100, 100, 100),   effect = 1, sigma_Y = 1,   model = \"ols\" )  head(dat_ols) #>          X1          X2          X3         X4        Y  f set_label #> 1 1.4766580  0.94761022 -0.18564137  0.8637002 1.628462 NA  training #> 2 0.1396610 -1.78438490  0.23590410 -1.6363443 2.287123 NA  training #> 3 0.7469694  0.86713095  0.06843502  0.6707585 1.794597 NA  training #> 4 1.0065186 -0.93285366  0.56852152  0.2254238 1.819812 NA  training #> 5 0.8157331 -0.01941014  0.59448236 -1.8430057 1.222568 NA  training #> 6 1.9256205  1.44902178 -0.32900314 -0.9556044 4.428360 NA  training"},{"path":"https://ipd-tools.github.io/ipd/reference/summary.ipd.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarize ipd fit â€” summary.ipd","title":"Summarize ipd fit â€” summary.ipd","text":"Summarize ipd fit","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/summary.ipd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarize ipd fit â€” summary.ipd","text":"","code":"# S3 method for class 'ipd' summary(object, ...)"},{"path":"https://ipd-tools.github.io/ipd/reference/summary.ipd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarize ipd fit â€” summary.ipd","text":"object object class ipd. ... Ignored.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/summary.ipd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarize ipd fit â€” summary.ipd","text":"object class summary.ipd containing: call model formula. coefficients glm-style table estimates, SE, z, p. method IPD method used. model downstream model fitted. intercept Logical; whether intercept included.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/tidy.ipd.html","id":null,"dir":"Reference","previous_headings":"","what":"Tidy an ipd fit â€” tidy.ipd","title":"Tidy an ipd fit â€” tidy.ipd","text":"Tidy ipd fit","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/tidy.ipd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Tidy an ipd fit â€” tidy.ipd","text":"","code":"# S3 method for class 'ipd' tidy(x, ...)"},{"path":"https://ipd-tools.github.io/ipd/reference/tidy.ipd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Tidy an ipd fit â€” tidy.ipd","text":"x object class ipd. ... Ignored.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/tidy.ipd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Tidy an ipd fit â€” tidy.ipd","text":"tibble columns term, estimate, std.error, conf.low, conf.high.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/tidy.ipd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Tidy an ipd fit â€” tidy.ipd","text":"","code":"dat <- simdat()  fit <- ipd(Y - f ~ X1, method = \"pspa\", model = \"ols\",      data = dat, label = \"set_label\")  tidy(fit) #> # A tibble: 2 Ã— 5 #>   term        estimate std.error conf.low conf.high #>   <chr>          <dbl>     <dbl>    <dbl>     <dbl> #> 1 (Intercept)    0.798    0.0997    0.602     0.993 #> 2 X1             0.822    0.0869    0.651     0.992"},{"path":"https://ipd-tools.github.io/ipd/reference/wls.html","id":null,"dir":"Reference","previous_headings":"","what":"Weighted Least Squares â€” wls","title":"Weighted Least Squares â€” wls","text":"Computes weighted least squares estimate coefficients.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/wls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Weighted Least Squares â€” wls","text":"","code":"wls(X, Y, w = NULL, return_se = FALSE)"},{"path":"https://ipd-tools.github.io/ipd/reference/wls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Weighted Least Squares â€” wls","text":"X (matrix): n x p matrix covariates. Y (vector): p-vector outcome values. w (vector, optional): n-vector sample weights. return_se (bool, optional): Whether return standard errors coefficients.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/wls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Weighted Least Squares â€” wls","text":"(list): list containing following: theta (vector): p-vector weighted least squares estimates coefficients. se (vector): return_se == TRUE, return p-vector standard errors coefficients.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/zconfint_generic.html","id":null,"dir":"Reference","previous_headings":"","what":"Normal Confidence Intervals â€” zconfint_generic","title":"Normal Confidence Intervals â€” zconfint_generic","text":"Calculates normal confidence intervals given alternative given significance level.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/zconfint_generic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normal Confidence Intervals â€” zconfint_generic","text":"","code":"zconfint_generic(mean, std_mean, alpha, alternative)"},{"path":"https://ipd-tools.github.io/ipd/reference/zconfint_generic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normal Confidence Intervals â€” zconfint_generic","text":"mean (float): Estimated normal mean. std_mean (float): Estimated standard error mean. alpha (float): Significance level [0,1] alternative (string): Alternative hypothesis, either 'two-sided', 'larger' 'smaller'.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/zconfint_generic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normal Confidence Intervals â€” zconfint_generic","text":"(vector): Lower upper (1 - alpha) * 100% confidence limits.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/zstat_generic.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute Z-Statistic and P-Value â€” zstat_generic","title":"Compute Z-Statistic and P-Value â€” zstat_generic","text":"Computes z-statistic corresponding p-value given test.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/zstat_generic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute Z-Statistic and P-Value â€” zstat_generic","text":"","code":"zstat_generic(value1, value2, std_diff, alternative, diff = 0)"},{"path":"https://ipd-tools.github.io/ipd/reference/zstat_generic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute Z-Statistic and P-Value â€” zstat_generic","text":"value1 (numeric): first value sample mean. value2 (numeric): second value sample mean. std_diff (numeric): standard error difference two values. alternative (character): alternative hypothesis. Can one \"two-sided\" (\"2-sided\", \"2s\"), \"larger\" (\"l\"), \"smaller\" (\"s\"). diff (numeric, optional): hypothesized difference two values. Default 0.","code":""},{"path":"https://ipd-tools.github.io/ipd/reference/zstat_generic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute Z-Statistic and P-Value â€” zstat_generic","text":"(list): list containing following: zstat (numeric): computed z-statistic. pvalue (numeric): corresponding p-value test.","code":""},{"path":"https://ipd-tools.github.io/ipd/news/index.html","id":"ipd-013","dir":"Changelog","previous_headings":"","what":"ipd 0.1.3","title":"ipd 0.1.3","text":"CRAN release: 2024-12-03 Added NEWS.md file track changes package. Added pkgdown site package. ipd() now allows regression origin intercept = FALSE argument. ipd() now takes additional argument, na_action, handle missing covariate data. Currently supports \"na.fail\" \"na.omit\". Defaults na.fail. Provides informative error message lists covariates missing observations. ipd() now takes additional argument, n_t, denotes (optional) size training set used generate prediction rule. Defaults Inf necessary postpi_X methods n_t < n, N, number labeled unlabeled observations, respectively, data analyzed.","code":""},{"path":"https://ipd-tools.github.io/ipd/news/index.html","id":"ipd-014","dir":"Changelog","previous_headings":"","what":"ipd 0.1.4","title":"ipd 0.1.4","text":"CRAN release: 2025-01-07 Added help topic package (man/ipd-package.Rd) via R/ipd-package.R roxygen2 Updated documentation ipd(): Provided explicit description model argument, meant specify downstream inferential model parameter estimated. Clarified columns data used prediction unless explicitly referenced formula argument label argument data passed one stacked data frame. Updated documentation simdat() include thorough explanation simulate data function. simdat() now outputs data.frame column named \"set_label\" instead \"set\" denote labeled/unlabeled observation indicator.","code":""},{"path":[]},{"path":"https://ipd-tools.github.io/ipd/news/index.html","id":"summary-0-99-0","dir":"Changelog","previous_headings":"","what":"Summary:","title":"ipd 0.99.0","text":"Preparations archive CRAN move Bioconductor. Slight formatting changes conform styler lintr suggestions. Added PPIa, Chen Chen methods Gronsbell et al.Â (2025) â€œAnother look inference prediction.â€","code":""},{"path":"https://ipd-tools.github.io/ipd/news/index.html","id":"specific-changes-0-99-0","dir":"Changelog","previous_headings":"","what":"Specific Changes:","title":"ipd 0.99.0","text":"Preâ€‘release version set 0.99.0 Bioconductor devel. Depends: R (>= 4.4.0) Added biocViews: Software Added Suggests: BiocStyle, BiocManager Converted existing R Markdown vignettes Bioconductor style BiocStyle::html_document proper VignetteIndexEntry headers. Added examples Chen Chen, PPI â€œâ€ methods. Added NEWS.md entry (file) CITATION file package citation metadata. Passed BiocCheck errors warnings. Updated testthat suite needed Bioc compliance. Added GitHub Actions via usethis::use_github_action(\"bioc-workflow\") run Bioconductor checks Linux, macOS, Windows. Installation instructions updated : Replaced CRAN build badge : ppi_a_ols() â€” implements PPIa estimator predictionâ€‘powered inference. chen_ols() â€” implements Chen & Chen estimator inference predicted data. .parse_inputs() - helper validate split input data. .drop_unused_levels() - helper drop unused factor levels report removed. .warn_differing_levels() - helper warn differing factor levels labeled unlabeled data. .build_design() - helper build design matrices outcome vectors. show() - implements S4 method ipd class. ipd() - registered new methods wrapper. ipd() - helper functions parsing inputs additional warnings users parsing formulas. methods.R - Updated new S4 class ipd. Branch created, tag v0.99.0 applied. request CRAN archiving CRAN version upon successful Bioconductor acceptance.","code":"if (!requireNamespace(\"BiocManager\", quietly=TRUE))   install.packages(\"BiocManager\") BiocManager::install(\"ipd\") [![Bioc build status](https://bioconductor.org/shields/build/release/bioc/ipd.svg)](https://bioconductor.org/packages/ipd)"}]
